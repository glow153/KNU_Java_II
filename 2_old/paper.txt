Deep learning in neural networks: An overview
JurgenSchmidhuber
Abstract
In recent years, deep artificial neural networks (including recurrent ones) have won numerous contests in pattern recognition and machine learning. This historical survey compactly summarizes relevant work, much of it from the previous millennium. Shallow and Deep Learners are distinguished by the depth of their credit assignment paths, which are chains of possibly learnable, causal links between actions and effects. I review deep supervised learning (also recapitulating the history of backpropagation), unsupervised learning, reinforcement learning & evolutionary computation, and indirect search for short programs encoding deep and large networks.
Keywords
Deep learningSupervised learningUnsupervised learningReinforcement learningEvolutionary computation
Abbreviations in alphabetical order
AE:
Autoencoder

AI:
Artificial Intelligence

ANN:
Artificial Neural Network

BFGS:
Broyden?Fletcher?Goldfarb?Shanno

BNN:
Biological Neural Network

BM:
Boltzmann Machine

BP:
Backpropagation

BRNN:
Bi-directional Recurrent Neural Network

CAP:
Credit Assignment Path

CEC:
Constant Error Carousel

CFL:
Context Free Language

CMA-ES:
Covariance Matrix Estimation ES

CNN:
Convolutional Neural Network

CoSyNE:
Co-Synaptic Neuro-Evolution

CSL:
Context Sensitive Language

CTC:
Connectionist Temporal Classification

DBN:
Deep Belief Network

DCT:
Discrete Cosine Transform

DL:
Deep Learning

DP:
Dynamic Programming

DS:
Direct Policy Search

EA:
Evolutionary Algorithm

EM:
Expectation Maximization

ES:
Evolution Strategy

FMS:
Flat Minimum Search

FNN:
Feedforward Neural Network

FSA:
Finite State Automaton

GMDH:
Group Method of Data Handling

GOFAI:
Good Old-Fashioned AI

GP:
Genetic Programming

GPU:
Graphics Processing Unit

GPU-MPCNN:
GPU-Based MPCNN

HMM:
Hidden Markov Model

HRL:
Hierarchical Reinforcement Learning

HTM:
Hierarchical Temporal Memory

HMAX:
Hierarchical Model ¡°and X¡±

LSTM:
Long Short-Term Memory (RNN)

MDL:
Minimum Description Length

MDP:
Markov Decision Process

MNIST:
Mixed National Institute of Standards and Technology Database

MP:
Max-Pooling

MPCNN:
Max-Pooling CNN

NE:
NeuroEvolution

NEAT:
NE of Augmenting Topologies

NES:
Natural Evolution Strategies

NFQ:
Neural Fitted Q-Learning

NN:
Neural Network

OCR:
Optical Character Recognition

PCC:
Potential Causal Connection

PDCC:
Potential Direct Causal Connection

PM:
Predictability Minimization

POMDP:
Partially Observable MDP

RAAM:
Recursive Auto-Associative Memory

RBM:
Restricted Boltzmann Machine

ReLU:
Rectified Linear Unit

RL:
Reinforcement Learning

RNN:
Recurrent Neural Network

R-prop:
Resilient Backpropagation

SL:
Supervised Learning

SLIM NN:
Self-Delimiting Neural Network

SOTA:
Self-Organizing Tree Algorithm

SVM:
Support Vector Machine

TDNN:
Time-Delay Neural Network

TIMIT:
TI/SRI/MIT Acoustic-Phonetic Continuous Speech Corpus

UL:
Unsupervised Learning

WTA:
Winner-Take-All

Preface
This is the preprint of an invited Deep Learning (DL) overview. One of its goals is to assign credit to those who contributed to the present state of the art. I acknowledge the limitations of attempting to achieve this goal. The DL research community itself may be viewed as a continually evolving, deep network of scientists who have influenced each other in complex ways. Starting from recent DL results, I tried to trace back the origins of relevant ideas through the past half century and beyond, sometimes using ¡°local search¡± to follow citations of citations backwards in time. Since not all DL publications properly acknowledge earlier relevant work, additional global search strategies were employed, aided by consulting numerous neural network experts. As a result, the present preprint mostly consists of references. Nevertheless, through an expert selection bias I may have missed important work. A related bias was surely introduced by my special familiarity with the work of my own DL research group in the past quarter-century. For these reasons, this work should be viewed as merely a snapshot of an ongoing credit assignment process. To help improve it, please do not hesitate to send corrections and suggestions to juergen@idsia.ch.

1. Introduction to Deep Learning (DL) in Neural Networks (NNs)
Which modifiable components of a learning system are responsible for its success or failure? What changes to them improve performance? This has been called the fundamental credit assignment problem (Minsky, 1963). There are general credit assignment methods for universal problem solvers that are time-optimal in various theoretical senses (Section  6.8). The present survey, however, will focus on the narrower, but now commercially important, subfield of Deep Learning (DL) in Artificial Neural Networks (NNs).

A standard neural network (NN) consists of many simple, connected processors called neurons, each producing a sequence of real-valued activations. Input neurons get activated through sensors perceiving the environment, other neurons get activated through weighted connections from previously active neurons (details in Section  2). Some neurons may influence the environment by triggering actions. Learning or credit assignment is about finding weights that make the NN exhibit desired behavior, such as driving a car. Depending on the problem and how the neurons are connected, such behavior may require long causal chains of computational stages (Section  3), where each stage transforms (often in a non-linear way) the aggregate activation of the network. Deep Learning is about accurately assigning credit across many such stages.

Shallow NN-like models with few such stages have been around for many decades if not centuries (Section  5.1). Models with several successive nonlinear layers of neurons date back at least to the 1960s (Section  5.3) and 1970s (Section  5.5). An efficient gradient descent method for teacher-based Supervised Learning (SL) in discrete, differentiable networks of arbitrary depth called backpropagation (BP) was developed in the 1960s and 1970s, and applied to NNs in 1981 (Section  5.5). BP-based training of deep NNs with many layers, however, had been found to be difficult in practice by the late 1980s (Section  5.6), and had become an explicit research subject by the early 1990s (Section  5.9). DL became practically feasible to some extent through the help of Unsupervised Learning (UL), e.g., Section  5.10 (1991), Section  5.15 (2006). The 1990s and 2000s also saw many improvements of purely supervised DL (Section  5). In the new millennium, deep NNs have finally attracted wide-spread attention, mainly by outperforming alternative machine learning methods such as kernel machines (Scholkopf et al., 1998, Vapnik, 1995) in numerous important applications. In fact, since 2009, supervised deep NNs have won many official international pattern recognition competitions (e.g., Sections  5.17 2009: first official competitions won by RNNs, and with MPCNNs, 5.19 2011: MPCNNs on GPU achieve superhuman vision performance, 5.21 2012: first contests won on ImageNet, object detection, segmentation, 5.22 2013-: more contests and benchmark records), achieving the first superhuman visual pattern recognition results in limited domains (Section  5.19, 2011). Deep NNs also have become relevant for the more general field of Reinforcement Learning (RL) where there is no supervising teacher (Section  6).

Both feedforward (acyclic) NNs (FNNs) and recurrent (cyclic) NNs (RNNs) have won contests (Sections 5.12, 5.14, 5.17, 5.19, 5.21, 5.22). In a sense, RNNs are the deepest of all NNs (Section  3)?they are general computers more powerful than FNNs, and can in principle create and process memories of arbitrary sequences of input patterns (e.g.,  Schmidhuber, 1990a, Siegelmann and Sontag, 1991). Unlike traditional methods for automatic sequential program synthesis (e.g.,  Balzer, 1985, Deville and Lau, 1994, Soloway, 1986, Waldinger and Lee, 1969), RNNs can learn programs that mix sequential and parallel information processing in a natural and efficient way, exploiting the massive parallelism viewed as crucial for sustaining the rapid decline of computation cost observed over the past 75 years.

The rest of this paper is structured as follows. Section  2 introduces a compact, event-oriented notation that is simple yet general enough to accommodate both FNNs and RNNs. Section  3 introduces the concept of Credit Assignment Paths (CAPs) to measure whether learning in a given NN application is of the deep or shallow type. Section  4 lists recurring themes of DL in SL, UL, and RL. Section  5 focuses on SL and UL, and on how UL can facilitate SL, although pure SL has become dominant in recent competitions (Sections  5.17 2009: first official competitions won by RNNs, and with MPCNNs, 5.18 2010: plain backprop (+ distortions) on GPU breaks MNIST record, 5.19 2011: MPCNNs on GPU achieve superhuman vision performance, 5.20 2011: Hessian-free optimization for RNNs, 5.21 2012: first contests won on ImageNet, object detection, segmentation, 5.22 2013-: more contests and benchmark records, 5.23 Currently successful techniques: LSTM RNNs and GPU-MPCNNs). Section  5 is arranged in a historical timeline format with subsections on important inspirations and technical contributions. Section  6 on deep RL discusses traditional Dynamic Programming (DP)-based RL combined with gradient-based search techniques for SL or UL in deep NNs, as well as general methods for direct and indirect search in the weight space of deep FNNs and RNNs, including successful policy gradient and evolutionary methods.

2. Event-oriented notation for activation spreading in NNs
Throughout this paper, let  denote positive integer variables assuming ranges implicit in the given contexts. Let  denote positive integer constants.

An NN¡¯s topology may change over time (e.g., Sections 5.3, 5.6.3). At any given moment, it can be described as a finite subset of units (or nodes or neurons)  and a finite set  of directed edges or connections between nodes. FNNs are acyclic graphs, RNNs cyclic. The first (input) layer is the set of input units, a subset of . In FNNs, the th layer () is the set of all nodes  such that there is an edge path of length  (but no longer path) between some input unit and . There may be shortcut connections between distant layers. In sequence-processing, fully connected RNNs, all units have connections to all non-input units.

The NN¡¯s behavior or program is determined by a set of real-valued, possibly modifiable, parameters or weights . We now focus on a single finite episode or epoch of information processing and activation spreading, without learning through weight changes. The following slightly unconventional notation is designed to compactly describe what is happening during the runtime of the system.

During an episode, there is a partially causal sequence of real values that I call events. Each  is either an input set by the environment, or the activation of a unit that may directly depend on other  through a current NN topology-dependent set  of indices  representing incoming causal connections or links. Let the function  encode topology information and map such event index pairs  to weight indices. For example, in the non-input case we may have  with real-valued (additive case) or  (multiplicative case), where  is a typically nonlinear real-valued activation function such as . In many recent competition-winning NNs (Sections 5.19, 5.21, 5.22) there also are events of the type ; some network types may also use complex polynomial activation functions (Section  5.3).  may directly affect certain  through outgoing connections or links represented through a current set  of indices  with . Some of the non-input events are called output events.

Note that many of the  may refer to different, time-varying activations of the same unit in sequence-processing RNNs (e.g., Williams, 1989 ¡°unfolding in time¡±), or also in FNNs sequentially exposed to time-varying input patterns of a large training set encoded as input events. During an episode, the same weight may get reused over and over again in topology-dependent ways, e.g., in RNNs, or in convolutional NNs (Sections  5.4 1979: convolution + weight replication + subsampling (Neocognitron), 5.8 1989: BP for convolutional NNs (CNNs, Section ). I call this weight sharing across space and/or time. Weight sharing may greatly reduce the NN¡¯s descriptive complexity, which is the number of bits of information required to describe the NN (Section  4.4).

In Supervised Learning (SL), certain NN output events  may be associated with teacher-given, real-valued labels or targets  yielding errors , e.g., . A typical goal of supervised NN training is to find weights that yield episodes with small total error , the sum of all such . The hope is that the NN will generalize well in later episodes, causing only small errors on previously unseen sequences of input events. Many alternative error functions for SL and UL are possible.

SL assumes that input events are independent of earlier output events (which may affect the environment through actions causing subsequent perceptions). This assumption does not hold in the broader fields of Sequential Decision Making and Reinforcement Learning (RL) (Hutter, 2005, Kaelbling et al., 1996, Sutton and Barto, 1998, Wiering and van Otterlo, 2012) (Section  6). In RL, some of the input events may encode real-valued reward signals given by the environment, and a typical goal is to find weights that yield episodes with a high sum of reward signals, through sequences of appropriate output actions.

Section  5.5 will use the notation above to compactly describe a central algorithm of DL, namely, backpropagation (BP) for supervised weight-sharing FNNs and RNNs. (FNNs may be viewed as RNNs with certain fixed zero weights.) Section  6 will address the more general RL case.

3. Depth of Credit Assignment Paths (CAPs) and of problems
To measure whether credit assignment in a given NN application is of the deep or shallow type, I introduce the concept of Credit Assignment Paths or CAPs, which are chains of possibly causal links between the events of Section  2, e.g., from input through hidden to output layers in FNNs, or through transformations over time in RNNs.

Let us first focus on SL. Consider two events  and . Depending on the application, they may have a Potential Direct Causal Connection (PDCC) expressed by the Boolean predicate , which is true if and only if . Then the 2-element list  is defined to be a CAP (a minimal one) from  to . A learning algorithm may be allowed to change  to improve performance in future episodes.

More general, possibly indirect, Potential Causal Connections (PCC) are expressed by the recursively defined Boolean predicate , which in the SL case is true only if , or if  for some  and . In the latter case, appending  to any CAP from  to  yields a CAP from  to  (this is a recursive definition, too). The set of such CAPs may be large but is finite. Note that the same weight may affect many different PDCCs between successive events listed by a given CAP, e.g., in the case of RNNs, or weight-sharing FNNs.

Suppose a CAP has the form , where  and (possibly ) are the first successive elements with modifiable. Then the length of the suffix list  is called the CAP¡¯s depth (which is 0 if there are no modifiable links at all). This depth limits how far backwards credit assignment can move down the causal chain to find a modifiable weight.1

Suppose an episode and its event sequence  satisfy a computable criterion used to decide whether a given problem has been solved (e.g., total error  below some threshold). Then the set of used weights is called a solution to the problem, and the depth of the deepest CAP within the sequence is called the solution depth. There may be other solutions (yielding different event sequences) with different depths. Given some fixed NN topology, the smallest depth of any solution is called the problem depth.

Sometimes we also speak of the depth of an architecture: SL FNNs with fixed topology imply a problem-independent maximal problem depth bounded by the number of non-input layers. Certain SL RNNs with fixed weights for all connections except those to output units (Jaeger, 2001, Jaeger, 2004, Maass et al., 2002, Schrauwen et al., 2007) have a maximal problem depth of 1, because only the final links in the corresponding CAPs are modifiable. In general, however, RNNs may learn to solve problems of potentially unlimited depth.

Note that the definitions above are solely based on the depths of causal chains, and agnostic to the temporal distance between events. For example, shallow FNNs perceiving large ¡°time windows¡± of input events may correctly classify long input sequences through appropriate output events, and thus solve shallow problems involving long time lags between relevant events.

At which problem depth does Shallow Learning end, and Deep Learning begin? Discussions with DL experts have not yet yielded a conclusive response to this question. Instead of committing myself to a precise answer, let me just define for the purposes of this overview: problems of depth  require Very Deep Learning.

The difficulty of a problem may have little to do with its depth. Some NNs can quickly learn to solve certain deep problems, e.g., through random weight guessing (Section  5.9) or other types of direct search (Section  6.6) or indirect search (Section  6.7) in weight space, or through training an NN first on shallow problems whose solutions may then generalize to deep problems, or through collapsing sequences of (non)linear operations into a single (non)linear operation (but see an analysis of non-trivial aspects of deep linear networks,  Baldi & Hornik, 1995, Section B). In general, however, finding an NN that precisely models a given training set is an NP-complete problem (Blum and Rivest, 1992, Judd, 1990), also in the case of deep NNs (de Souto et al., 1999, Sima, 1994, Windisch, 2005); compare a survey of negative results (Sima, 2002, Section 1).

Above we have focused on SL. In the more general case of RL in unknown environments,  is also true if  is an output event and  any later input event?any action may affect the environment and thus any later perception. (In the real world, the environment may even influence non-input events computed on a physical hardware entangled with the entire universe, but this is ignored here.) It is possible to model and replace such unmodifiable environmental PCCs through a part of the NN that has already learned to predict (through some of its units) input events (including reward signals) from former input events and actions (Section  6.1). Its weights are frozen, but can help to assign credit to other, still modifiable weights used to compute actions (Section  6.1). This approach may lead to very deep CAPs though.

Some DL research is about automatically rephrasing problems such that their depth is reduced (Section  4). In particular, sometimes UL is used to make SL problems less deep, e.g., Section  5.10. Often Dynamic Programming (Section  4.1) is used to facilitate certain traditional RL problems, e.g., Section  6.2. Section  5 focuses on CAPs for SL, Section  6 on the more complex case of RL.

4. Recurring themes of Deep Learning
4.1. Dynamic programming for Supervised/Reinforcement Learning (SL/RL)
One recurring theme of DL is Dynamic Programming (DP) (Bellman, 1957), which can help to facilitate credit assignment under certain assumptions. For example, in SL NNs, backpropagation itself can be viewed as a DP-derived method (Section  5.5). In traditional RL based on strong Markovian assumptions, DP-derived methods can help to greatly reduce problem depth (Section  6.2). DP algorithms are also essential for systems that combine concepts of NNs and graphical models, such as Hidden Markov Models (HMMs) (Baum and Petrie, 1966, Stratonovich, 1960) and Expectation Maximization (EM) (Dempster et al., 1977, Friedman et al., 2001), e.g., Baldi and Chauvin (1996), Bengio (1991), Bishop (2006), Bottou (1991), Bourlard and Morgan (1994), Dahl, Yu, Deng, and Acero (2012), Hastie, Tibshirani, and Friedman (2009), Hinton, Deng, et al. (2012), Jordan and Sejnowski (2001), Poon and Domingos (2011) and Wu and Shao (2014).

4.2. Unsupervised Learning (UL) facilitating SL and RL
Another recurring theme is how UL can facilitate both SL (Section  5) and RL (Section  6). UL (Section  5.6.4) is normally used to encode raw incoming data such as video or speech streams in a form that is more convenient for subsequent goal-directed learning. In particular, codes that describe the original data in a less redundant or more compact way can be fed into SL (Sections 5.10, 5.15) or RL machines (Section  6.4), whose search spaces may thus become smaller (and whose CAPs shallower) than those necessary for dealing with the raw data. UL is closely connected to the topics of regularization and compression (Sections 4.4, 5.6.3).

4.3. Learning hierarchical representations through deep SL, UL, RL
Many methods of Good Old-Fashioned Artificial Intelligence (GOFAI) (Nilsson, 1980) as well as more recent approaches to AI (Russell, Norvig, Canny, Malik, & Edwards, 1995) and Machine Learning (Mitchell, 1997) learn hierarchies of more and more abstract data representations. For example, certain methods of syntactic pattern recognition (Fu, 1977) such as grammar induction discover hierarchies of formal rules to model observations. The partially (un)supervised Automated Mathematician/EURISKO (Lenat, 1983, Lenat and Brown, 1984) continually learns concepts by combining previously learnt concepts. Such hierarchical representation learning (Bengio et al., 2013, Deng and Yu, 2014, Ring, 1994) is also a recurring theme of DL NNs for SL (Section  5), UL-aided SL (Sections 5.7, 5.10, 5.15), and hierarchical RL (Section  6.5). Often, abstract hierarchical representations are natural by-products of data compression (Section  4.4), e.g., Section  5.10.

4.4. Occam¡¯s razor: compression and Minimum Description Length (MDL)
Occam¡¯s razor favors simple solutions over complex ones. Given some programming language, the principle of Minimum Description Length (MDL) can be used to measure the complexity of a solution candidate by the length of the shortest program that computes it (e.g.,  Blumer et al., 1987, Chaitin, 1966, Grunwald et al., 2005, Kolmogorov, 1965b, Levin, 1973a, Li and Vitanyi, 1997, Rissanen, 1986, Solomonoff, 1964, Solomonoff, 1978, Wallace and Boulton, 1968). Some methods explicitly take into account program runtime (Allender, 1992, Schmidhuber, 1997, Schmidhuber, 2002, Watanabe, 1992); many consider only programs with constant runtime, written in non-universal programming languages (e.g.,  Hinton and van Camp, 1993, Rissanen, 1986). In the NN case, the MDL principle suggests that low NN weight complexity corresponds to high NN probability in the Bayesian view (e.g.,  Buntine and Weigend, 1991, De Freitas, 2003, MacKay, 1992, Neal, 1995), and to high generalization performance (e.g.,  Baum & Haussler, 1989), without overfitting the training data. Many methods have been proposed for regularizing NNs, that is, searching for solution-computing but simple, low-complexity SL NNs (Section  5.6.3) and RL NNs (Section  6.7). This is closely related to certain UL methods (Sections 4.2, 5.6.4).

4.5. Fast Graphics Processing Units (GPUs) for DL in NNs
While the previous millennium saw several attempts at creating fast NN-specific hardware (e.g.,  Faggin, 1992, Heemskerk, 1995, Jackel et al., 1990, Korkin et al., 1997, Ramacher et al., 1993, Urlbe, 1999, Widrow et al., 1994), and at exploiting standard hardware (e.g.,  Anguita and Gomes, 1996, Anguita et al., 1994, Muller et al., 1995), the new millennium brought a DL breakthrough in form of cheap, multi-processor graphics cards or GPUs. GPUs are widely used for video games, a huge and competitive market that has driven down hardware prices. GPUs excel at the fast matrix and vector multiplications required not only for convincing virtual realities but also for NN training, where they can speed up learning by a factor of 50 and more. Some of the GPU-based FNN implementations (Sections  5.16 2006/7: improved CNNs/GPU-CNNs/BP for MPCNNs/LSTM stacks, 5.17 2009: first official competitions won by RNNs, and with MPCNNs, 5.18 2010: plain backprop (+ distortions) on GPU breaks MNIST record, 5.19 2011: MPCNNs on GPU achieve superhuman vision performance) have greatly contributed to recent successes in contests for pattern recognition (Sections  5.19 2011: MPCNNs on GPU achieve superhuman vision performance, 5.20 2011: Hessian-free optimization for RNNs, 5.21 2012: first contests won on ImageNet, object detection, segmentation, 5.22 2013-: more contests and benchmark records), image segmentation (Section  5.21), and object detection (Sections 5.21?5.22).

5. Supervised NNs, some helped by unsupervised NNs
The main focus of current practical applications is on Supervised Learning (SL), which has dominated recent pattern recognition contests (Sections  5.17 2009: first official competitions won by RNNs, and with MPCNNs, 5.18 2010: plain backprop (+ distortions) on GPU breaks MNIST record, 5.19 2011: MPCNNs on GPU achieve superhuman vision performance, 5.20 2011: Hessian-free optimization for RNNs, 5.21 2012: first contests won on ImageNet, object detection, segmentation, 5.22 2013-: more contests and benchmark records, 5.23 Currently successful techniques: LSTM RNNs and GPU-MPCNNs). Several methods, however, use additional Unsupervised Learning (UL) to facilitate SL (Sections 5.7, 5.10, 5.15). It does make sense to treat SL and UL in the same section: often gradient-based methods, such as BP (Section  5.5.1), are used to optimize objective functions of both UL and SL, and the boundary between SL and UL may blur, for example, when it comes to time series prediction and sequence classification, e.g., Sections 5.10, 5.12.

A historical timeline format will help to arrange subsections on important inspirations and technical contributions (although such a subsection may span a time interval of many years). Section  5.1 briefly mentions early, shallow NN models since the 1940s (and 1800s), Section  5.2 additional early neurobiological inspiration relevant for modern Deep Learning (DL). Section  5.3 is about GMDH networks (since 1965), to my knowledge the first (feedforward) DL systems. Section  5.4 is about the relatively deep Neocognitron NN (1979) which is very similar to certain modern deep FNN architectures, as it combines convolutional NNs (CNNs), weight pattern replication, and subsampling mechanisms. Section  5.5 uses the notation of Section  2 to compactly describe a central algorithm of DL, namely, backpropagation (BP) for supervised weight-sharing FNNs and RNNs. It also summarizes the history of BP 1960?1981 and beyond. Section  5.6 describes problems encountered in the late 1980s with BP for deep NNs, and mentions several ideas from the previous millennium to overcome them. Section  5.7 discusses a first hierarchical stack (1987) of coupled UL-based Autoencoders (AEs)?this concept resurfaced in the new millennium (Section  5.15). Section  5.8 is about applying BP to CNNs (1989), which is important for today¡¯s DL applications. Section  5.9 explains BP¡¯s Fundamental DL Problem (of vanishing/exploding gradients) discovered in 1991. Section  5.10 explains how a deep RNN stack of 1991 (the History Compressor) pre-trained by UL helped to solve previously unlearnable DL benchmarks requiring Credit Assignment Paths (CAPs, Section  3) of depth 1000 and more. Section  5.11 discusses a particular winner-take-all (WTA) method called Max-Pooling (MP, 1992) widely used in today¡¯s deep FNNs. Section  5.12 mentions a first important contest won by SL NNs in 1994. Section  5.13 describes a purely supervised DL RNN (Long Short-Term Memory, LSTM, 1995) for problems of depth 1000 and more. Section  5.14 mentions an early contest of 2003 won by an ensemble of shallow FNNs, as well as good pattern recognition results with CNNs and deep FNNs and LSTM RNNs (2003). Section  5.15 is mostly about Deep Belief Networks (DBNs, 2006) and related stacks of Autoencoders (AEs, Section  5.7), both pre-trained by UL to facilitate subsequent BP-based SL (compare Sections 5.6.1, 5.10). Section  5.16 mentions the first SL-based GPU-CNNs (2006), BP-trained MPCNNs (2007), and LSTM stacks (2007). Sections  5.17 2009: first official competitions won by RNNs, and with MPCNNs, 5.18 2010: plain backprop (+ distortions) on GPU breaks MNIST record, 5.19 2011: MPCNNs on GPU achieve superhuman vision performance, 5.20 2011: Hessian-free optimization for RNNs, 5.21 2012: first contests won on ImageNet, object detection, segmentation, 5.22 2013-: more contests and benchmark records focus on official competitions with secret test sets won by (mostly purely supervised) deep NNs since 2009, in sequence recognition, image classification, image segmentation, and object detection. Many RNN results depended on LSTM (Section  5.13); many FNN results depended on GPU-based FNN code developed since 2004 (Sections  5.16 2006/7: improved CNNs/GPU-CNNs/BP for MPCNNs/LSTM stacks, 5.17 2009: first official competitions won by RNNs, and with MPCNNs, 5.18 2010: plain backprop (+ distortions) on GPU breaks MNIST record, 5.19 2011: MPCNNs on GPU achieve superhuman vision performance), in particular, GPU-MPCNNs (Section  5.19). Section  5.24 mentions recent tricks for improving DL in NNs, many of them closely related to earlier tricks from the previous millennium (e.g., Sections 5.6.2, 5.6.3). Section  5.25 discusses how artificial NNs can help to understand biological NNs; Section  5.26 addresses the possibility of DL in NNs with spiking neurons.

5.1. Early NNs since the 1940s (and the 1800s)
Early NN architectures (McCulloch & Pitts, 1943) did not learn. The first ideas about UL were published a few years later (Hebb, 1949). The following decades brought simple NNs trained by SL (e.g.,  Narendra and Thathatchar, 1974, Rosenblatt, 1958, Rosenblatt, 1962, Widrow and Hoff, 1962) and UL (e.g.,  Grossberg, 1969, Kohonen, 1972, von der Malsburg, 1973, Willshaw and von der Malsburg, 1976), as well as closely related associative memories (e.g.,  Hopfield, 1982, Palm, 1980).

In a sense NNs have been around even longer, since early supervised NNs were essentially variants of linear regression methods going back at least to the early 1800s (e.g.,  Gauss, 1809, Gauss, 1821, Legendre, 1805); Gauss also refers to his work of 1795. Early NNs had a maximal CAP depth of 1 (Section  3).

5.2. Around 1960: visual cortex provides inspiration for DL (Sections 5.4, 5.11)
Simple cells and complex cells were found in the cat¡¯s visual cortex (e.g.,  Hubel and Wiesel, 1962, Wiesel and Hubel, 1959). These cells fire in response to certain properties of visual sensory inputs, such as the orientation of edges. Complex cells exhibit more spatial invariance than simple cells. This inspired later deep NN architectures (Sections 5.4, 5.11) used in certain modern award-winning Deep Learners (Sections  5.19 2011: MPCNNs on GPU achieve superhuman vision performance, 5.20 2011: Hessian-free optimization for RNNs, 5.21 2012: first contests won on ImageNet, object detection, segmentation, 5.22 2013-: more contests and benchmark records).

5.3. 1965: deep networks based on the Group Method of Data Handling
Networks trained by the Group Method of Data Handling (GMDH) (Ivakhnenko, 1968, Ivakhnenko, 1971, Ivakhnenko and Lapa, 1965, Ivakhnenko et al., 1967) were perhaps the first DL systems of the Feedforward Multilayer Perceptron type, although there was earlier work on NNs with a single hidden layer (e.g.,  Joseph, 1961, Viglione, 1970). The units of GMDH nets may have polynomial activation functions implementing Kolmogorov?Gabor polynomials (more general than other widely used NN activation functions, Section  2). Given a training set, layers are incrementally grown and trained by regression analysis (e.g.,  Gauss, 1809, Gauss, 1821, Legendre, 1805) (Section  5.1), then pruned with the help of a separate validation set (using today¡¯s terminology), where Decision Regularization is used to weed out superfluous units (compare Section  5.6.3). The numbers of layers and units per layer can be learned in problem-dependent fashion. To my knowledge, this was the first example of open-ended, hierarchical representation learning in NNs (Section  4.3). A paper of 1971 already described a deep GMDH network with 8 layers (Ivakhnenko, 1971). There have been numerous applications of GMDH-style nets, e.g. Farlow (1984), Ikeda, Ochiai, and Sawaragi (1976), Ivakhnenko (1995), Kondo (1998), Kondo and Ueno (2008), Kordik, Naplava, Snorek, and Genyk-Berezovskyj (2003), Madala and Ivakhnenko (1994) and Witczak, Korbicz, Mrugalski, and Patton (2006).

5.4. 1979: convolution + weight replication + subsampling (Neocognitron)
Apart from deep GMDH networks (Section  5.3), the Neocognitron (Fukushima, 1979, Fukushima, 1980, Fukushima, 2013a) was perhaps the first artificial NN that deserved the attribute deep, and the first to incorporate the neurophysiological insights of Section  5.2. It introduced convolutional NNs (today often called CNNs or convnets), where the (typically rectangular) receptive field of a convolutional unit with given weight vector (a filter) is shifted step by step across a 2-dimensional array of input values, such as the pixels of an image (usually there are several such filters). The resulting 2D array of subsequent activation events of this unit can then provide inputs to higher-level units, and so on. Due to massive weight replication (Section  2), relatively few parameters (Section  4.4) may be necessary to describe the behavior of such a convolutional layer.

Subsampling or downsampling layers consist of units whose fixed-weight connections originate from physical neighbors in the convolutional layers below. Subsampling units become active if at least one of their inputs is active; their responses are insensitive to certain small image shifts (compare Section  5.2).

The Neocognitron is very similar to the architecture of modern, contest-winning, purely supervised, feedforward, gradient-based Deep Learners with alternating convolutional and downsampling layers (e.g., Sections  5.19 2011: MPCNNs on GPU achieve superhuman vision performance, 5.20 2011: Hessian-free optimization for RNNs, 5.21 2012: first contests won on ImageNet, object detection, segmentation, 5.22 2013-: more contests and benchmark records). Fukushima, however, did not set the weights by supervised backpropagation (Sections 5.5, 5.8), but by local, WTA-based unsupervised learning rules (e.g.,  Fukushima, 2013b), or by pre-wiring. In that sense he did not care for the DL problem (Section  5.9), although his architecture was comparatively deep indeed. For downsampling purposes he used Spatial Averaging (Fukushima, 1980, Fukushima, 2011) instead of Max-Pooling (MP, Section  5.11), currently a particularly convenient and popular WTA mechanism. Today¡¯s DL combinations of CNNs and MP and BP also profit a lot from later work (e.g., Sections 5.8, 5.16, 5.19).

5.5. 1960?1981 and beyond: development of backpropagation (BP) for NNs
The minimization of errors through gradient descent (Hadamard, 1908) in the parameter space of complex, nonlinear, differentiable (Leibniz, 1684), multi-stage, NN-related systems has been discussed at least since the early 1960s (e.g.,  Amari, 1967, Bryson, 1961, Bryson and Denham, 1961, Bryson and Ho, 1969, Director and Rohrer, 1969, Dreyfus, 1962, Kelley, 1960, Pontryagin et al., 1961, Wilkinson, 1965), initially within the framework of Euler?Lagrange equations in the Calculus of Variations (e.g.,  Euler, 1744).

Steepest descent in the weight space of such systems can be performed (Bryson, 1961, Bryson and Ho, 1969, Kelley, 1960) by iterating the chain rule (Leibniz, 1676, L¡¯Hopital, 1696) a la Dynamic Programming (DP) (Bellman, 1957). A simplified derivation of this backpropagation method uses the chain rule only (Dreyfus, 1962).

The systems of the 1960s were already efficient in the DP sense. However, they backpropagated derivative information through standard Jacobian matrix calculations from one ¡°layer¡± to the previous one, without explicitly addressing either direct links across several layers or potential additional efficiency gains due to network sparsity (but perhaps such enhancements seemed obvious to the authors). Given all the prior work on learning in multilayer NN-like systems (see also Section  5.3 on deep nonlinear nets since 1965), it seems surprising in hindsight that a book (Minsky & Papert, 1969) on the limitations of simple linear perceptrons with a single layer (Section  5.1) discouraged some researchers from further studying NNs.

Explicit, efficient error backpropagation (BP) in arbitrary, discrete, possibly sparsely connected, NN-like networks apparently was first described in a 1970 master¡¯s thesis (Linnainmaa, 1970, Linnainmaa, 1976), albeit without reference to NNs. BP is also known as the reverse mode of automatic differentiation (Griewank, 2012), where the costs of forward activation spreading essentially equal the costs of backward derivative calculation. See early FORTRAN code (Linnainmaa, 1970) and closely related work (Ostrovskii, Volin, & Borisov, 1971).

Efficient BP was soon explicitly used to minimize cost functions by adapting control parameters (weights) (Dreyfus, 1973). Compare some preliminary, NN-specific discussion (Werbos, 1974, Section 5.5.1), a method for multilayer threshold NNs (Bobrowski, 1978), and a computer program for automatically deriving and implementing BP for given differentiable systems (Speelpenning, 1980).

To my knowledge, the first NN-specific application of efficient BP as above was described in 1981 (Werbos, 1981, Werbos, 2006). Related work was published several years later (LeCun, 1985, LeCun, 1988, Parker, 1985). A paper of 1986 significantly contributed to the popularization of BP for NNs (Rumelhart, Hinton, & Williams, 1986), experimentally demonstrating the emergence of useful internal representations in hidden layers. See generalizations for sequence-processing recurrent NNs (e.g.,  Atiya and Parlos, 2000, Baldi, 1995, Gherrity, 1989, Kremer and Kolen, 2001, Pearlmutter, 1989, Pearlmutter, 1995, Robinson and Fallside, 1987, Rohwer, 1989, Schmidhuber, 1992a, Werbos, 1988, Williams, 1989, Williams and Peng, 1990, Williams and Zipser, 1988, Williams and Zipser, 1989a, Williams and Zipser, 1989b), also for equilibrium RNNs (Almeida, 1987, Pineda, 1987) with stationary inputs.

5.5.1. BP for weight-sharing feedforward NNs (FNNs) and recurrent NNs (RNNs)
Using the notation of Section  2 for weight-sharing FNNs or RNNs, after an episode of activation spreading through differentiable , a single iteration of gradient descent through BP computes changes of all  in proportion to  as in Algorithm 5.5.1 (for the additive case), where each weight  is associated with a real-valued variable  initialized by 0.


Download full-size image

The computational costs of the backward (BP) pass are essentially those of the forward pass (Section  2). Forward and backward passes are re-iterated until sufficient performance is reached.

As of 2014, this simple BP method is still the central learning algorithm for FNNs and RNNs. Notably, most contest-winning NNs up to 2014 (Sections 5.12, 5.14, 5.17, 5.19, 5.21, 5.22) did not augment supervised BP by some sort of unsupervised learning as discussed in Sections 5.7, 5.10, 5.15.

5.6. Late 1980s?2000 and beyond: numerous improvements of NNs
By the late 1980s it seemed clear that BP by itself (Section  5.5) was no panacea. Most FNN applications focused on FNNs with few hidden layers. Additional hidden layers often did not seem to offer empirical benefits. Many practitioners found solace in a theorem (Hecht-Nielsen, 1989, Hornik et al., 1989, Kolmogorov, 1965a) stating that an NN with a single layer of enough hidden units can approximate any multivariate continuous function with arbitrary accuracy.

Likewise, most RNN applications did not require backpropagating errors far. Many researchers helped their RNNs by first training them on shallow problems (Section  3) whose solutions then generalized to deeper problems. In fact, some popular RNN algorithms restricted credit assignment to a single step backwards (Elman, 1990, Jordan, 1986, Jordan, 1997), also in more recent studies (Jaeger, 2001, Jaeger, 2004, Maass et al., 2002).

Generally speaking, although BP allows for deep problems in principle, it seemed to work only for shallow problems. The late 1980s and early 1990s saw a few ideas with a potential to overcome this problem, which was fully understood only in 1991 (Section  5.9).

5.6.1. Ideas for dealing with long time lags and deep CAPs
To deal with long time lags between relevant events, several sequence processing methods were proposed, including Focused BP based on decay factors for activations of units in RNNs (Mozer, 1989, Mozer, 1992), Time-Delay Neural Networks (TDNNs) (Lang, Waibel, & Hinton, 1990) and their adaptive extension (Bodenhausen & Waibel, 1991), Nonlinear AutoRegressive with eXogenous inputs (NARX) RNNs (Lin, Horne, Tino, & Giles, 1996), certain hierarchical RNNs (Hihi & Bengio, 1996) (compare Section  5.10, 1991), RL economies in RNNs with WTA units and local learning rules (Schmidhuber, 1989b), and other methods (e.g.,  Bengio et al., 1994, de Vries and Principe, 1991, Plate, 1993, Ring, 1993, Ring, 1994, Sun, Chen, et al., 1993). However, these algorithms either worked for shallow CAPs only, could not generalize to unseen CAP depths, had problems with greatly varying time lags between relevant events, needed external fine tuning of delay constants, or suffered from other problems. In fact, it turned out that certain simple but deep benchmark problems used to evaluate such methods are more quickly solved by randomly guessing RNN weights until a solution is found (Hochreiter & Schmidhuber, 1996).

While the RNN methods above were designed for DL of temporal sequences, the Neural Heat Exchanger (Schmidhuber, 1990c) consists of two parallel deep FNNs with opposite flow directions. Input patterns enter the first FNN and are propagated ¡°up¡±. Desired outputs (targets) enter the ¡°opposite¡± FNN and are propagated ¡°down¡±. Using a local learning rule, each layer in each net tries to be similar (in information content) to the preceding layer and to the adjacent layer of the other net. The input entering the first net slowly ¡°heats up¡± to become the target. The target entering the opposite net slowly ¡°cools down¡± to become the input. The Helmholtz Machine (Dayan and Hinton, 1996, Dayan et al., 1995) may be viewed as an unsupervised (Section  5.6.4) variant thereof (Peter Dayan, personal communication, 1994).

A hybrid approach (Shavlik and Towell, 1989, Towell and Shavlik, 1994) initializes a potentially deep FNN through a domain theory in propositional logic, which may be acquired through explanation-based learning (DeJong and Mooney, 1986, Minton et al., 1989, Mitchell et al., 1986). The NN is then fine-tuned through BP (Section  5.5). The NN¡¯s depth reflects the longest chain of reasoning in the original set of logical rules. An extension of this approach (Maclin and Shavlik, 1993, Shavlik, 1994) initializes an RNN by domain knowledge expressed as a Finite State Automaton (FSA). BP-based fine-tuning has become important for later DL systems pre-trained by UL, e.g., Sections 5.10, 5.15.

5.6.2. Better BP through advanced gradient descent (compare Section  5.24)
Numerous improvements of steepest descent through BP (Section  5.5) have been proposed. Least-squares methods (Gauss?Newton, Levenberg?Marquardt) (Gauss, 1809, Levenberg, 1944, Marquardt, 1963, Newton, 1687, Schaback and Werner, 1992) and quasi-Newton methods (Broyden?Fletcher?Goldfarb?Shanno, BFGS) (Broyden et al., 1965, Fletcher and Powell, 1963, Goldfarb, 1970, Shanno, 1970) are computationally too expensive for large NNs. Partial BFGS (Battiti, 1992, Saito and Nakano, 1997) and conjugate gradient (Hestenes and Stiefel, 1952, M©ªller, 1993) as well as other methods (Cauwenberghs, 1993, Schmidhuber, 1989a, Solla, 1988) provide sometimes useful fast alternatives. BP can be treated as a linear least-squares problem (Biegler-Konig & Barmann, 1993), where second-order gradient information is passed back to preceding layers.

To speed up BP, momentum was introduced (Rumelhart et al., 1986), ad-hoc constants were added to the slope of the linearized activation function (Fahlman, 1988), or the nonlinearity of the slope was exaggerated (West & Saad, 1995).

Only the signs of the error derivatives are taken into account by the successful and widely used BP variant R-prop (Riedmiller & Braun, 1993) and the robust variation iRprop+ (Igel & Husken, 2003), which was also successfully applied to RNNs.

The local gradient can be normalized based on the NN architecture (Schraudolph & Sejnowski, 1996), through a diagonalized Hessian approach (Becker & Le Cun, 1989), or related efficient methods (Schraudolph, 2002).

Some algorithms for controlling BP step size adapt a global learning rate (Battiti, 1989, Lapedes and Farber, 1986, LeCun et al., 1993, Vogl et al., 1988, Yu et al., 1995), while others compute individual learning rates for each weight (Jacobs, 1988, Silva and Almeida, 1990). In online learning, where BP is applied after each pattern presentation, the vario- algorithm (Neuneier & Zimmermann, 1996) sets each weight¡¯s learning rate inversely proportional to the empirical standard deviation of its local gradient, thus normalizing the stochastic weight fluctuations. Compare a local online step size adaptation method for nonlinear NNs (Almeida, Almeida, Langlois, Amaral, & Redol, 1997).

Many additional tricks for improving NNs have been described (e.g.,  Montavon et al., 2012, Orr and Muller, 1998). Compare Section  5.6.3 and recent developments mentioned in Section  5.24.

5.6.3. Searching for simple, low-complexity, problem-solving NNs (Section  5.24)
Many researchers used BP-like methods to search for ¡°simple¡±, low-complexity NNs (Section  4.4) with high generalization capability. Most approaches address the bias/variance dilemma (Geman, Bienenstock, & Doursat, 1992) through strong prior assumptions. For example, weight decay (Hanson and Pratt, 1989, Krogh and Hertz, 1992, Weigend et al., 1991) encourages near-zero weights, by penalizing large weights. In a Bayesian framework (Bayes, 1763), weight decay can be derived (Hinton & van Camp, 1993) from Gaussian or Laplacian weight priors (Gauss, 1809, Laplace, 1774); see also Murray and Edwards (1993). An extension of this approach postulates that a distribution of networks with many similar weights generated by Gaussian mixtures is ¡°better¡± a priori (Nowlan & Hinton, 1992).

Often weight priors are implicit in additional penalty terms (MacKay, 1992) or in methods based on validation sets (Craven and Wahba, 1979, Eubank, 1988, Golub et al., 1979, Hastie and Tibshirani, 1990, Mosteller and Tukey, 1968, Stone, 1974), Akaike¡¯s information criterion and final prediction error (Akaike, 1970, Akaike, 1973, Akaike, 1974), or generalized prediction error (Moody, 1992, Moody and Utans, 1994). See also Amari and Murata (1993), Guyon, Vapnik, Boser, Bottou, and Solla (1992), Holden (1994), Vapnik (1992), Wang, Venkatesh, and Judd (1994) and Wolpert (1994). Similar priors (or biases towards simplicity) are implicit in constructive and pruning algorithms, e.g., layer-by-layer sequential network construction (e.g.,  Ash, 1989, Burgess, 1994, Fahlman, 1991, Fritzke, 1994, Gallant, 1988, Honavar and Uhr, 1988, Honavar and Uhr, 1993, Ivakhnenko, 1968, Ivakhnenko, 1971, Moody, 1989, Parekh et al., 2000, Ring, 1991, Utgoff and Stracuzzi, 2002, Weng et al., 1992) (see also Sections 5.3, 5.11), input pruning (Moody, 1992, Refenes et al., 1994), unit pruning (e.g.,  Ivakhnenko, 1968, Ivakhnenko, 1971, Levin et al., 1994, Mozer and Smolensky, 1989, White, 1989), weight pruning, e.g., optimal brain damage (LeCun, Denker, & Solla, 1990), and optimal brain surgeon (Hassibi & Stork, 1993).

A very general but not always practical approach for discovering low-complexity SL NNs or RL NNs searches among weight matrix-computing programs written in a universal programming language, with a bias towards fast and short programs (Schmidhuber, 1997) (Section  6.7).

Flat Minimum Search (FMS) (Hochreiter and Schmidhuber, 1997a, Hochreiter and Schmidhuber, 1999) searches for a ¡°flat¡± minimum of the error function: a large connected region in weight space where error is low and remains approximately constant, that is, few bits of information are required to describe low-precision weights with high variance. Compare perturbation tolerance conditions (Bishop, 1993, Carter et al., 1990, Hanson, 1990, Kerlirzin and Vallet, 1993, Matsuoka, 1992, Minai and Williams, 1994, Murray and Edwards, 1993, Neti et al., 1992). An MDL-based, Bayesian argument suggests that flat minima correspond to ¡°simple¡± NNs and low expected overfitting. Compare Section  5.6.4 and more recent developments mentioned in Section  5.24.

5.6.4. Potential benefits of UL for SL (compare Sections 5.7, 5.10, 5.15)
The notation of Section  2 introduced teacher-given labels . Many papers of the previous millennium, however, were about unsupervised learning (UL) without a teacher (e.g.,  Atick et al., 1992, Baldi and Hornik, 1989, Barlow et al., 1989, Barrow, 1987, Deco and Parra, 1997, Field, 1987, Foldiak, 1990, Foldiak and Young, 1995, Grossberg, 1976a, Grossberg, 1976b, Hebb, 1949, Kohonen, 1972, Kohonen, 1982, Kohonen, 1988, Kosko, 1990, Martinetz et al., 1990, Miller, 1994, Mozer, 1991, Oja, 1989, Palm, 1992, Pearlmutter and Hinton, 1986, Ritter and Kohonen, 1989, Rubner and Schulten, 1990, Sanger, 1989, Saund, 1994, von der Malsburg, 1973, Watanabe, 1985, Willshaw and von der Malsburg, 1976); see also post-2000 work (e.g.,  Carreira-Perpinan, 2001, Franzius et al., 2007, Waydo and Koch, 2008, Wiskott and Sejnowski, 2002).

Many UL methods are designed to maximize entropy-related, information-theoretic (Boltzmann, 1909, Kullback and Leibler, 1951, Shannon, 1948) objectives (e.g.,  Amari et al., 1996, Barlow et al., 1989, Dayan and Zemel, 1995, Deco and Parra, 1997, Field, 1994, Hinton et al., 1995, Linsker, 1988, MacKay and Miller, 1990, Plumbley, 1991, Redlich, 1993, Schmidhuber, 1992b, Schmidhuber, 1992c, Schraudolph and Sejnowski, 1993, Zemel, 1993, Zemel and Hinton, 1994).

Many do this to uncover and disentangle hidden underlying sources of signals (e.g.,  Andrade et al., 1993, Bell and Sejnowski, 1995, Belouchrani et al., 1997, Cardoso, 1994, Comon, 1994, Hyvarinen et al., 2001, Jutten and Herault, 1991, Karhunen and Joutsensalo, 1995, Molgedey and Schuster, 1994, Schuster, 1992, Shan and Cottrell, 2014, Shan et al., 2007, Szabo et al., 2006).

Many UL methods automatically and robustly generate distributed, sparse representations of input patterns (Falconbridge et al., 2006, Foldiak, 1990, Hinton and Ghahramani, 1997, Hochreiter and Schmidhuber, 1999, Hyvarinen et al., 1999, Lewicki and Olshausen, 1998) through well-known feature detectors (e.g.,  Olshausen and Field, 1996, Schmidhuber et al., 1996), such as off-center-on-surround-like structures, as well as orientation sensitive edge detectors and Gabor filters (Gabor, 1946). They extract simple features related to those observed in early visual pre-processing stages of biological systems (e.g.,  De Valois et al., 1982, Jones and Palmer, 1987).

UL can also serve to extract invariant features from different data items (e.g.,  Becker, 1991) through coupled NNs observing two different inputs (Schmidhuber & Prelinger, 1992), also called Siamese NNs (e.g.,  Bromley et al., 1993, Chen and Salman, 2011, Hadsell et al., 2006, Taylor et al., 2011).

UL can help to encode input data in a form advantageous for further processing. In the context of DL, one important goal of UL is redundancy reduction. Ideally, given an ensemble of input patterns, redundancy reduction through a deep NN will create a factorial code (a code with statistically independent components) of the ensemble (Barlow, 1989, Barlow et al., 1989), to disentangle the unknown factors of variation (compare  Bengio et al., 2013). Such codes may be sparse and can be advantageous for (1) data compression, (2) speeding up subsequent BP (Becker, 1991), (3) trivializing the task of subsequent naive yet optimal Bayes classifiers (Schmidhuber et al., 1996).

Most early UL FNNs had a single layer. Methods for deeper UL FNNs include hierarchical (Section  4.3) self-organizing Kohonen maps (e.g.,  Dittenbach et al., 2000, Koikkalainen and Oja, 1990, Lampinen and Oja, 1992, Rauber et al., 2002, Versino and Gambardella, 1996), hierarchical Gaussian potential function networks (Lee & Kil, 1991), layer-wise UL of feature hierarchies fed into SL classifiers (Behnke, 1999, Behnke, 2003a), the Self-Organizing Tree Algorithm (SOTA) (Herrero, Valencia, & Dopazo, 2001), and nonlinear Autoencoders (AEs) with more than 3 (e.g., 5) layers (DeMers and Cottrell, 1993, Kramer, 1991, Oja, 1991). Such AE NNs (Rumelhart et al., 1986) can be trained to map input patterns to themselves, for example, by compactly encoding them through activations of units of a narrow bottleneck hidden layer. Certain nonlinear AEs suffer from certain limitations (Baldi, 2012).

Lococode (Hochreiter & Schmidhuber, 1999) uses FMS (Section  5.6.3) to find low-complexity AEs with low-precision weights describable by few bits of information, often producing sparse or factorial codes. Predictability Minimization (PM) (Schmidhuber, 1992c) searches for factorial codes through nonlinear feature detectors that fight nonlinear predictors, trying to become both as informative and as unpredictable as possible. PM-based UL was applied not only to FNNs but also to RNNs (e.g.,  Lindstadt, 1993, Schmidhuber, 1993b). Compare Section  5.10 on UL-based RNN stacks (1991), as well as later UL RNNs (e.g.,  Klapper-Rybicka et al., 2001, Steil, 2007).

5.7. 1987: UL through Autoencoder (AE) hierarchies (compare Section  5.15)
Perhaps the first work to study potential benefits of UL-based pre-training was published in 1987. It proposed unsupervised AE hierarchies (Ballard, 1987), closely related to certain post-2000 feedforward Deep Learners based on UL (Section  5.15). The lowest-level AE NN with a single hidden layer is trained to map input patterns to themselves. Its hidden layer codes are then fed into a higher-level AE of the same type, and so on. The hope is that the codes in the hidden AE layers have properties that facilitate subsequent learning. In one experiment, a particular AE-specific learning algorithm (different from traditional BP of Section  5.5.1) was used to learn a mapping in an AE stack pre-trained by this type of UL (Ballard, 1987). This was faster than learning an equivalent mapping by BP through a single deeper AE without pre-training. On the other hand, the task did not really require a deep AE, that is, the benefits of UL were not that obvious from this experiment. Compare an early survey (Hinton, 1989) and the somewhat related Recursive Auto-Associative Memory (RAAM) (Melnik et al., 2000, Pollack, 1988, Pollack, 1990), originally used to encode sequential linguistic structures of arbitrary size through a fixed number of hidden units. More recently, RAAMs were also used as unsupervised pre-processors to facilitate deep credit assignment for RL (Gisslen, Luciw, Graziano, & Schmidhuber, 2011) (Section  6.4).

In principle, many UL methods (Section  5.6.4) could be stacked like the AEs above, the history-compressing RNNs of Section  5.10, the Restricted Boltzmann Machines (RBMs) of Section  5.15, or hierarchical Kohonen nets (Section  5.6.4), to facilitate subsequent SL. Compare Stacked Generalization (Ting and Witten, 1997, Wolpert, 1992), and FNNs that profit from pre-training by competitive UL (e.g.,  Rumelhart & Zipser, 1986) prior to BP-based fine-tuning (Maclin & Shavlik, 1995). See also more recent methods using UL to improve subsequent SL (e.g.,  Behnke, 1999, Behnke, 2003a, Escalante-B and Wiskott, 2013).

5.8. 1989: BP for convolutional NNs (CNNs, Section  5.4)
In 1989, backpropagation (Section  5.5) was applied (LeCun et al., 1989, LeCun, Boser, et al., 1990, LeCun et al., 1998) to Neocognitron-like, weight-sharing, convolutional neural layers (Section  5.4) with adaptive connections. This combination, augmented by Max-Pooling (MP, Sections 5.11, 5.16), and sped up on graphics cards (Section  5.19), has become an essential ingredient of many modern, competition-winning, feedforward, visual Deep Learners (Sections  5.19 2011: MPCNNs on GPU achieve superhuman vision performance, 5.20 2011: Hessian-free optimization for RNNs, 5.21 2012: first contests won on ImageNet, object detection, segmentation, 5.22 2013-: more contests and benchmark records, 5.23 Currently successful techniques: LSTM RNNs and GPU-MPCNNs). This work also introduced the MNIST data set of handwritten digits (LeCun et al., 1989), which over time has become perhaps the most famous benchmark of Machine Learning. CNNs helped to achieve good performance on MNIST (LeCun, Boser, et al., 1990) (CAP depth 5) and on fingerprint recognition (Baldi & Chauvin, 1993); similar CNNs were used commercially in the 1990s.

5.9. 1991: Fundamental Deep Learning Problem of gradient descent
A diploma thesis (Hochreiter, 1991) represented a milestone of explicit DL research. As mentioned in Section  5.6, by the late 1980s, experiments had indicated that traditional deep feedforward or recurrent networks are hard to train by backpropagation (BP) (Section  5.5). Hochreiter¡¯s work formally identified a major reason: Typical deep NNs suffer from the now famous problem of vanishing or exploding gradients. With standard activation functions (Section  1), cumulative backpropagated error signals (Section  5.5.1) either shrink rapidly, or grow out of bounds. In fact, they decay exponentially in the number of layers or CAP depth (Section  3), or they explode. This is also known as the long time lag problem. Much subsequent DL research of the 1990s and 2000s was motivated by this insight. Later work (Bengio et al., 1994) also studied basins of attraction and their stability under noise from a dynamical systems point of view: either the dynamics are not robust to noise, or the gradients vanish. See also Hochreiter, Bengio, Frasconi, and Schmidhuber (2001) and Ti?o and Hammer (2004). Over the years, several ways of partially overcoming the Fundamental Deep Learning Problem were explored:
I.
A Very Deep Learner of 1991 (the History Compressor, Section  5.10) alleviates the problem through unsupervised pre-training for a hierarchy of RNNs. This greatly facilitates subsequent supervised credit assignment through BP (Section  5.5). In the FNN case, similar effects can be achieved through conceptually related AE stacks (Sections 5.7, 5.15) and Deep Belief Networks (DBNs, Section  5.15).

II.
LSTM-like networks (Sections 5.13, 5.16, 5.17, 5.21 2012: first contests won on ImageNet, object detection, segmentation, 5.22 2013-: more contests and benchmark records, 5.23 Currently successful techniques: LSTM RNNs and GPU-MPCNNs) alleviate the problem through a special architecture unaffected by it.

III.
Today¡¯s GPU-based computers have a million times the computational power of desktop machines of the early 1990s. This allows for propagating errors a few layers further down within reasonable time, even in traditional NNs (Section  5.18). That is basically what is winning many of the image recognition competitions now (Sections 5.19, 5.21, 5.22). (Although this does not really overcome the problem in a fundamental way.)

IV.
Hessian-free optimization (Section  5.6.2) can alleviate the problem for FNNs (Martens, 2010, M©ªller, 1993, Pearlmutter, 1994, Schraudolph, 2002) (Section  5.6.2) and RNNs (Martens & Sutskever, 2011) (Section  5.20).

V.
The space of NN weight matrices can also be searched without relying on error gradients, thus avoiding the Fundamental Deep Learning Problem altogether. Random weight guessing sometimes works better than more sophisticated methods (Hochreiter & Schmidhuber, 1996). Certain more complex problems are better solved by using Universal Search (Levin, 1973b) for weight matrix-computing programs written in a universal programming language (Schmidhuber, 1997). Some are better solved by using linear methods to obtain optimal weights for connections to output events (Section  2), and evolving weights of connections to other events?this is called Evolino (Schmidhuber, Wierstra, Gagliolo, & Gomez, 2007). Compare also related RNNs pre-trained by certain UL rules (Steil, 2007), also in the case of spiking neurons (Klampfl and Maass, 2013, Yin et al., 2012) (Section  5.26). Direct search methods are relevant not only for SL but also for more general RL, and are discussed in more detail in Section  6.6.


5.10. 1991: UL-based history compression through a deep stack of RNNs
A working Very Deep Learner (Section  3) of 1991 (Schmidhuber, 1992b, Schmidhuber, 2013a) could perform credit assignment across hundreds of nonlinear operators or neural layers, by using unsupervised pre-training for a hierarchy of RNNs.

The basic idea is still relevant today. Each RNN is trained for a while in unsupervised fashion to predict its next input (e.g.,  Connor et al., 1994, Dorffner, 1996). From then on, only unexpected inputs (errors) convey new information and get fed to the next higher RNN which thus ticks on a slower, self-organizing time scale. It can easily be shown that no information gets lost. It just gets compressed (much of machine learning is essentially about compression, e.g., Sections 4.4, 5.6.3, 6.7). For each individual input sequence, we get a series of less and less redundant encodings in deeper and deeper levels of this History Compressor orNeural Sequence Chunker, which can compress data in both space (like feedforward NNs) and time. This is another good example of hierarchical representation learning (Section  4.3). There also is a continuous variant of the history compressor (Schmidhuber, Mozer, & Prelinger, 1993).

The RNN stack is essentially a deep generative model of the data, which can be reconstructed from its compressed form. Adding another RNN to the stack improves a bound on the data¡¯s description length?equivalent to the negative logarithm of its probability (Huffman, 1952, Shannon, 1948)?as long as there is remaining local learnable predictability in the data representation on the corresponding level of the hierarchy. Compare a similar observation for feedforward Deep Belief Networks (DBNs, 2006, Section  5.15).

The system was able to learn many previously unlearnable DL tasks. One ancient illustrative DL experiment (Schmidhuber, 1993b) required CAPs (Section  3) of depth 1200. The top level code of the initially unsupervised RNN stack, however, got so compact that (previously infeasible) sequence classification through additional BP-based SL became possible. Essentially the system used UL to greatly reduce problem depth. Compare earlier BP-based fine-tuning of NNs initialized by rules of propositional logic (Shavlik & Towell, 1989) (Section  5.6.1).

There is a way of compressing higher levels down into lower levels, thus fully or partially collapsing the RNN stack. The trick is to retrain a lower-level RNN to continually imitate (predict) the hidden units of an already trained, slower, higher-level RNN (the ¡°conscious¡± chunker), through additional predictive output neurons (Schmidhuber, 1992b). This helps the lower RNN (the automatizer) to develop appropriate, rarely changing memories that may bridge very long time lags. Again, this procedure can greatly reduce the required depth of the BP process.

The 1991 system was a working Deep Learner in the modern post-2000 sense, and also a first Neural Hierarchical Temporal Memory (HTM). It is conceptually similar to earlier AE hierarchies (1987, Section  5.7) and later Deep Belief Networks (2006, Section  5.15), but more general in the sense that it uses sequence-processing RNNs instead of FNNs with unchanging inputs. More recently, well-known entrepreneurs (Hawkins and George, 2006, Kurzweil, 2012) also got interested in HTMs; compare also hierarchical HMMs (e.g.,  Fine, Singer, & Tishby, 1998), as well as later UL-based recurrent systems (Klampfl and Maass, 2013, Klapper-Rybicka et al., 2001, Steil, 2007, Young et al., 2014). Clockwork RNNs (Koutnik, Greff, Gomez, & Schmidhuber, 2014) also consist of interacting RNN modules with different clock rates, but do not use UL to set those rates. Stacks of RNNs were used in later work on SL with great success, e.g., Sections 5.13, 5.16, 5.17, 5.22.

5.11. 1992: Max-Pooling (MP): towards MPCNNs (compare Sections 5.16, 5.19)
The Neocognitron (Section  5.4) inspired the Cresceptron (Weng et al., 1992), which adapts its topology during training (Section  5.6.3); compare the incrementally growing and shrinking GMDH networks (1965, Section  5.3).

Instead of using alternative local subsampling or WTA methods (e.g.,  Fukushima, 1980, Fukushima, 2013a, Maass, 2000, Schmidhuber, 1989b), the Cresceptron uses Max-Pooling (MP) layers. Here a 2-dimensional layer or array of unit activations is partitioned into smaller rectangular arrays. Each is replaced in a downsampling layer by the activation of its maximally active unit. A later, more complex version of the Cresceptron (Weng, Ahuja, & Huang, 1997) also included ¡°blurring¡± layers to improve object location tolerance.

The neurophysiologically plausible topology of the feedforward HMAX model (Riesenhuber & Poggio, 1999) is very similar to the one of the 1992 Cresceptron (and thus to the 1979 Neocognitron). HMAX does not learn though. Its units have hand-crafted weights; biologically plausible learning rules were later proposed for similar models (e.g.,  Serre et al., 2002, Teichmann et al., 2012).

When CNNs or convnets (Sections 5.4, 5.8) are combined with MP, they become Cresceptron-like or HMAX-like MPCNNs with alternating convolutional and max-pooling layers. Unlike Cresceptron and HMAX, however, MPCNNs are trained by BP (Sections 5.5, 5.16) (Ranzato, Huang, Boureau, & LeCun, 2007). Advantages of doing this were pointed out subsequently (Scherer, Muller, & Behnke, 2010). BP-trained MPCNNs have become central to many modern, competition-winning, feedforward, visual Deep Learners (Sections 5.17, 5.19 2011: MPCNNs on GPU achieve superhuman vision performance, 5.20 2011: Hessian-free optimization for RNNs, 5.21 2012: first contests won on ImageNet, object detection, segmentation, 5.22 2013-: more contests and benchmark records, 5.23 Currently successful techniques: LSTM RNNs and GPU-MPCNNs).

5.12. 1994: early contest-winning NNs
Back in the 1990s, certain NNs already won certain controlled pattern recognition contests with secret test sets. Notably, an NN with internal delay lines won the Santa Fe time-series competition on chaotic intensity pulsations of an NH3 laser (Wan, 1994, Weigend and Gershenfeld, 1993). No very deep CAPs (Section  3) were needed though.

5.13. 1995: supervised recurrent very Deep Learner (LSTM RNN)
Supervised Long Short-Term Memory (LSTM) RNNs (Gers et al., 2000, Hochreiter and Schmidhuber, 1997b, Perez-Ortiz et al., 2003) could eventually perform similar feats as the deep RNN hierarchy of 1991 (Section  5.10), overcoming the Fundamental Deep Learning Problem (Section  5.9) without any unsupervised pre-training. LSTM could also learn DL tasks without local sequence predictability (and thus unlearnable by the partially unsupervised 1991 History Compressor, Section  5.10), dealing with very deep problems (Section  3) (e.g.,  Gers, Schraudolph, & Schmidhuber, 2002).

The basic LSTM idea is very simple. Some of the units are called Constant Error Carousels (CECs). Each CEC uses as an activation function , the identity function, and has a connection to itself with fixed weight of 1.0. Due to ¡¯s constant derivative of 1.0, errors backpropagated through a CEC cannot vanish or explode (Section  5.9) but stay as they are (unless they ¡°flow out¡± of the CEC to other, typically adaptive parts of the NN). CECs are connected to several nonlinear adaptive units (some with multiplicative activation functions) needed for learning nonlinear behavior. Weight changes of these units often profit from error signals propagated far back in time through CECs. CECs are the main reason why LSTM nets can learn to discover the importance of (and memorize) events that happened thousands of discrete time steps ago, while previous RNNs already failed in case of minimal time lags of 10 steps.

Many different LSTM variants and topologies are allowed. It is possible to evolve good problem-specific topologies (Bayer, Wierstra, Togelius, & Schmidhuber, 2009). Some LSTM variants also use modifiable self-connections of CECs (Gers & Schmidhuber, 2001).

To a certain extent, LSTM is biologically plausible (O¡¯Reilly, 2003). LSTM learned to solve many previously unlearnable DL tasks involving: Recognition of the temporal order of widely separated events in noisy input streams; Robust storage of high-precision real numbers across extended time intervals; Arithmetic operations on continuous input streams; Extraction of information conveyed by the temporal distance between events; Recognition of temporally extended patterns in noisy input sequences (Gers et al., 2000, Hochreiter and Schmidhuber, 1997b); Stable generation of precisely timed rhythms, as well as smooth and non-smooth periodic trajectories (Gers & Schmidhuber, 2000). LSTM clearly outperformed previous RNNs on tasks that require learning the rules of regular languages describable by deterministic Finite State Automata (FSAs) (Blair and Pollack, 1997, Casey, 1996, Kalinke and Lehmann, 1998, Manolios and Fanelli, 1994, Omlin and Giles, 1996, Siegelmann, 1992, Vahed and Omlin, 2004, Watrous and Kuhn, 1992, Zeng et al., 1994), both in terms of reliability and speed.

LSTM also worked on tasks involving context free languages (CFLs) that cannot be represented by HMMs or similar FSAs discussed in the RNN literature (Andrews et al., 1995, Rodriguez and Wiles, 1998, Rodriguez et al., 1999, Steijvers and Grunwald, 1996, Sun, Giles, et al., 1993, Tonkes and Wiles, 1997, Wiles and Elman, 1995). CFL recognition (Lee, 1996) requires the functional equivalent of a runtime stack. Some previous RNNs failed to learn small CFL training sets (Rodriguez & Wiles, 1998). Those that did not (Boden and Wiles, 2000, Rodriguez et al., 1999) failed to extract the general rules, and did not generalize well on substantially larger test sets. Similar for context-sensitive languages (CSLs) (e.g.,  Chalup & Blair, 2003). LSTM generalized well though, requiring only the 30 shortest exemplars () of the CSL  to correctly predict the possible continuations of sequence prefixes for  up to 1000 and more. A combination of a decoupled extended Kalman filter (Feldkamp et al., 1998, Feldkamp et al., 2003, Haykin, 2001, Kalman, 1960, Puskorius and Feldkamp, 1994, Williams, 1992b) and an LSTM RNN (Perez-Ortiz et al., 2003) learned to deal correctly with values of  up to 10 million and more. That is, after training the network was able to read sequences of 30,000,000 symbols and more, one symbol at a time, and finally detect the subtle differences between legal strings such as  and very similar but illegal strings such as . Compare also more recent RNN algorithms able to deal with long time lags (Koutnik et al., 2014, Martens and Sutskever, 2011, Schafer et al., 2006, Zimmermann et al., 2012).

Bi-directional RNNs (BRNNs) (Schuster, 1999, Schuster and Paliwal, 1997) are designed for input sequences whose starts and ends are known in advance, such as spoken sentences to be labeled by their phonemes; compare Fukada, Schuster, and Sagisaka (1999). To take both past and future context of each sequence element into account, one RNN processes the sequence from start to end, the other backwards from end to start. At each time step their combined outputs predict the corresponding label (if there is any). BRNNs were successfully applied to secondary protein structure prediction (Baldi, Brunak, Frasconi, Pollastri, & Soda, 1999). DAG-RNNs (Baldi and Pollastri, 2003, Wu and Baldi, 2008) generalize BRNNs to multiple dimensions. They learned to predict properties of small organic molecules (Lusci, Pollastri, & Baldi, 2013) as well as protein contact maps (Tegge, Wang, Eickholt, & Cheng, 2009), also in conjunction with a growing deep FNN (Di Lena, Nagata, & Baldi, 2012) (Section  5.21). BRNNs and DAG-RNNs unfold their full potential when combined with the LSTM concept (Graves et al., 2009, Graves and Schmidhuber, 2005, Graves and Schmidhuber, 2009).

Particularly successful in recent competitions are stacks (Section  5.10) of LSTM RNNs (Fernandez et al., 2007b, Graves and Schmidhuber, 2009) trained by Connectionist Temporal Classification (CTC) (Graves, Fernandez, Gomez, & Schmidhuber, 2006), a gradient-based method for finding RNN weights that maximize the probability of teacher-given label sequences, given (typically much longer and more high-dimensional) streams of real-valued input vectors. CTC-LSTM performs simultaneous segmentation (alignment) and recognition (Section  5.22).

In the early 2000s, speech recognition was dominated by HMMs combined with FNNs (e.g.,  Bourlard & Morgan, 1994). Nevertheless, when trained from scratch on utterances from the TIDIGITS speech database, in 2003 LSTM already obtained results comparable to those of HMM-based systems (Beringer et al., 2005, Graves et al., 2003, Graves et al., 2006). In 2007, LSTM outperformed HMMs in keyword spotting tasks (Fernandez, Graves, & Schmidhuber, 2007a); compare recent improvements (Indermuhle et al., 2011, Wollmer et al., 2013). By 2013, LSTM also achieved best known results on the famous TIMIT phoneme recognition benchmark (Graves, Mohamed, & Hinton, 2013) (Section  5.22). Recently, LSTM RNN/HMM hybrids obtained best known performance on medium-vocabulary (Geiger, Zhang, Weninger, Schuller, & Rigoll, 2014) and large-vocabulary speech recognition (Sak, Senior, & Beaufays, 2014).

LSTM is also applicable to robot localization (Forster, Graves, & Schmidhuber, 2007), robot control (Mayer et al., 2008), online driver distraction detection (Wollmer et al., 2011), and many other tasks. For example, it helped to improve the state of the art in diverse applications such as protein analysis (Hochreiter & Obermayer, 2005), handwriting recognition (Bluche et al., 2014, Graves et al., 2008, Graves et al., 2009, Graves and Schmidhuber, 2009), voice activity detection (Eyben, Weninger, Squartini, & Schuller, 2013), optical character recognition (Breuel, Ul-Hasan, Al-Azawi, & Shafait, 2013), language identification (Gonzalez-Dominguez, Lopez-Moreno, Sak, Gonzalez-Rodriguez, & Moreno, 2014), prosody contour prediction (Fernandez, Rendel, Ramabhadran, & Hoory, 2014), audio onset detection (Marchi et al., 2014), text-to-speech synthesis (Fan, Qian, Xie, & Soong, 2014), social signal classification (Brueckner & Schulter, 2014), machine translation (Sutskever, Vinyals, & Le, 2014), and others.

RNNs can also be used for metalearning (Prokhorov et al., 2002, Schaul and Schmidhuber, 2010, Schmidhuber, 1987), because they can in principle learn to run their own weight change algorithm (Schmidhuber, 1993a). A successful metalearner (Hochreiter, Younger, & Conwell, 2001) used an LSTM RNN to quickly learn a learning algorithm for quadratic functions (compare Section  6.8).

Recently, LSTM RNNs won several international pattern recognition competitions and set numerous benchmark records on large and complex data sets, e.g., Sections 5.17, 5.21, 5.22. Gradient-based LSTM is no panacea though?other methods sometimes outperformed it at least on certain tasks (Jaeger, 2004, Koutnik et al., 2014, Martens and Sutskever, 2011, Pascanu, Mikolov, et al., 2013, Schmidhuber et al., 2007); compare Section  5.20.

5.14. 2003: more contest-winning/record-setting NNs; successful deep NNs
In the decade around 2000, many practical and commercial pattern recognition applications were dominated by non-neural machine learning methods such as Support Vector Machines (SVMs) (Scholkopf et al., 1998, Vapnik, 1995). Nevertheless, at least in certain domains, NNs outperformed other techniques.

A Bayes NN (Neal, 2006) based on an ensemble (Breiman, 1996, Dietterich, 2000a, Hashem and Schmeiser, 1992, Schapire, 1990, Ueda, 2000, Wolpert, 1992) of NNs won the NIPS 2003 Feature Selection Challenge with secret test set (Neal & Zhang, 2006). The NN was not very deep though?it had two hidden layers and thus rather shallow CAPs (Section  3) of depth 3.

Important for many present competition-winning pattern recognizers (Sections 5.19, 5.21, 5.22) were developments in the CNN department. A BP-trained (LeCun et al., 1989) CNN (Sections 5.4, 5.8) set a new MNIST record of 0.4% (Simard, Steinkraus, & Platt, 2003), using training pattern deformations (Baird, 1990) but no unsupervised pre-training (Sections 5.7, 5.10, 5.15). A standard BP net achieved 0.7% (Simard et al., 2003). Again, the corresponding CAP depth was low. Compare further improvements in Sections 5.16, 5.18, 5.19.

Good image interpretation results (Behnke, 2003b) were achieved with rather deep NNs trained by the BP variant R-prop (Riedmiller & Braun, 1993) (Section  5.6.2); here feedback through recurrent connections helped to improve image interpretation. FNNs with CAP depth up to 6 were used to successfully classify high-dimensional data (Vieira & Barradas, 2003).

Deep LSTM RNNs started to obtain certain first speech recognition results comparable to those of HMM-based systems (Graves et al., 2003); compare Sections 5.13, 5.16, 5.21, 5.22.

5.15. 2006/7: UL for deep belief networks/AE stacks fine-tuned by BP
While learning networks with numerous non-linear layers date back at least to 1965 (Section  5.3), and explicit DL research results have been published at least since 1991 (Sections 5.9, 5.10), the expression Deep Learning was actually coined around 2006, when unsupervised pre-training of deep FNNs helped to accelerate subsequent SL through BP (Hinton et al., 2006, Hinton and Salakhutdinov, 2006). Compare earlier terminology on loading deep networks (Sima, 1994, Windisch, 2005) and learning deep memories (Gomez & Schmidhuber, 2005). Compare also BP-based (Section  5.5) fine-tuning (Section  5.6.1) of (not so deep) FNNs pre-trained by competitive UL (Maclin & Shavlik, 1995).

The Deep Belief Network (DBN) is a stack of Restricted Boltzmann Machines (RBMs) (Smolensky, 1986), which in turn are Boltzmann Machines (BMs) (Hinton & Sejnowski, 1986) with a single layer of feature-detecting units; compare also Higher-Order BMs (Memisevic & Hinton, 2010). Each RBM perceives pattern representations from the level below and learns to encode them in unsupervised fashion. At least in theory under certain assumptions, adding more layers improves a bound on the data¡¯s negative log probability (Hinton et al., 2006) (equivalent to the data¡¯s description length?compare the corresponding observation for RNN stacks, Section  5.10). There are extensions for Temporal RBMs (Sutskever, Hinton, & Taylor, 2008).

Without any training pattern deformations (Section  5.14), a DBN fine-tuned by BP achieved 1.2% error rate (Hinton & Salakhutdinov, 2006) on the MNIST handwritten digits (Sections 5.8, 5.14). This result helped to arouse interest in DBNs. DBNs also achieved good results on phoneme recognition, with an error rate of 26.7% on the TIMIT core test set (Mohamed & Hinton, 2010); compare further improvements through FNNs (Deng and Yu, 2014, Hinton, Deng, et al., 2012) and LSTM RNNs (Section  5.22).

A DBN-based technique called Semantic Hashing (Salakhutdinov & Hinton, 2009) maps semantically similar documents (of variable size) to nearby addresses in a space of document representations. It outperformed previous searchers for similar documents, such as Locality Sensitive Hashing (Buhler, 2001, Datar et al., 2004). See the RBM/DBN tutorial (Fischer & Igel, 2014).

Autoencoder (AE) stacks (Ballard, 1987) (Section  5.7) became a popular alternative way of pre-training deep FNNs in unsupervised fashion, before fine-tuning (Section  5.6.1) them through BP (Section  5.5) (Bengio et al., 2007, Erhan et al., 2010, Vincent et al., 2008). Sparse coding (Section  5.6.4) was formulated as a combination of convex optimization problems (Lee, Battle, Raina, & Ng, 2007). Recent surveys of stacked RBM and AE methods focus on post-2006 developments (Arel et al., 2010, Bengio, 2009). Unsupervised DBNs and AE stacks are conceptually similar to, but in a certain sense less general than, the unsupervised RNN stack-based History Compressor of 1991 (Section  5.10), which can process and re-encode not only stationary input patterns, but entire pattern sequences.

5.16. 2006/7: improved CNNs/GPU-CNNs/BP for MPCNNs/LSTM stacks
Also in 2006, a BP-trained (LeCun et al., 1989) CNN (Sections 5.4, 5.8) set a new MNIST record of 0.39% (Ranzato, Poultney, Chopra, & LeCun, 2006), using training pattern deformations (Section  5.14) but no unsupervised pre-training. Compare further improvements in Sections 5.18, 5.19. Similar CNNs were used for off-road obstacle avoidance (LeCun, Muller, Cosatto, & Flepp, 2006). A combination of CNNs and TDNNs later learned to map fixed-size representations of variable-size sentences to features relevant for language processing, using a combination of SL and UL (Collobert & Weston, 2008).

2006 also saw an early GPU-based CNN implementation (Chellapilla, Puri, & Simard, 2006) up to 4 times faster than CPU-CNNs; compare also earlier GPU implementations of standard FNNs with a reported speed-up factor of 20 (Oh & Jung, 2004). GPUs or graphics cards have become more and more important for DL in subsequent years (Sections  5.18 2010: plain backprop (+ distortions) on GPU breaks MNIST record, 5.19 2011: MPCNNs on GPU achieve superhuman vision performance, 5.20 2011: Hessian-free optimization for RNNs, 5.21 2012: first contests won on ImageNet, object detection, segmentation, 5.22 2013-: more contests and benchmark records).

In 2007, BP (Section  5.5) was applied for the first time (Ranzato et al., 2007) to Neocognitron-inspired (Section  5.4), Cresceptron-like (or HMAX-like) MPCNNs (Section  5.11) with alternating convolutional and max-pooling layers. BP-trained MPCNNs have become an essential ingredient of many modern, competition-winning, feedforward, visual Deep Learners (Sections 5.17, 5.19 2011: MPCNNs on GPU achieve superhuman vision performance, 5.20 2011: Hessian-free optimization for RNNs, 5.21 2012: first contests won on ImageNet, object detection, segmentation, 5.22 2013-: more contests and benchmark records, 5.23 Currently successful techniques: LSTM RNNs and GPU-MPCNNs).

Also in 2007, hierarchical stacks of LSTM RNNs were introduced (Fernandez et al., 2007b). They can be trained by hierarchical Connectionist Temporal Classification (CTC) (Graves et al., 2006). For tasks of sequence labeling, every LSTM RNN level (Section  5.13) predicts a sequence of labels fed to the next level. Error signals at every level are back-propagated through all the lower levels. On spoken digit recognition, LSTM stacks outperformed HMMs, despite making fewer assumptions about the domain. LSTM stacks do not necessarily require unsupervised pre-training like the earlier UL-based RNN stacks (Schmidhuber, 1992b) of Section  5.10.

5.17. 2009: first official competitions won by RNNs, and with MPCNNs
Stacks of LSTM RNNs trained by CTC (Sections 5.13, 5.16) became the first RNNs to win official international pattern recognition contests (with secret test sets known only to the organizers). More precisely, three connected handwriting competitions at ICDAR 2009 in three different languages (French, Arab, Farsi) were won by deep LSTM RNNs without any a priori linguistic knowledge, performing simultaneous segmentation and recognition. Compare Graves and Jaitly (2014), Graves and Schmidhuber (2005), Graves et al. (2009), Graves et al. (2013) and Schmidhuber, Ciresan, Meier, Masci, and Graves (2011) (Section  5.22).

To detect human actions in surveillance videos, a 3-dimensional CNN (e.g.,  Jain and Seung, 2009, Prokhorov, 2010), combined with SVMs, was part of a larger system (Yang et al., 2009) using a bag of features approach (Nowak, Jurie, & Triggs, 2006) to extract regions of interest. The system won three 2009 TRECVID competitions. These were possibly the first official international contests won with the help of (MP)CNNs (Section  5.16). An improved version of the method was published later (Ji, Xu, Yang, & Yu, 2013).

2009 also saw a GPU-DBN implementation (Raina, Madhavan, & Ng, 2009) orders of magnitudes faster than previous CPU-DBNs (see Section  5.15); see also Coates et al. (2013). The Convolutional DBN (Lee, Grosse, Ranganath, & Ng, 2009) (with a probabilistic variant of MP, Section  5.11) combines ideas from CNNs and DBNs, and was successfully applied to audio classification (Lee, Pham, Largman, & Ng, 2009).

5.18. 2010: plain backprop (+ distortions) on GPU breaks MNIST record
In 2010, a new MNIST (Section  5.8) record of 0.35% error rate was set by good old BP (Section  5.5) in deep but otherwise standard NNs (Ciresan, Meier, Gambardella, & Schmidhuber, 2010), using neither unsupervised pre-training (e.g., Sections 5.7, 5.10, 5.15) nor convolution (e.g., Sections 5.4, 5.8, 5.14, 5.16). However, training pattern deformations (e.g., Section  5.14) were important to generate a big training set and avoid overfitting. This success was made possible mainly through a GPU implementation of BP that was up to 50 times faster than standard CPU versions. A good value of 0.95% was obtained without distortions except for small saccadic eye movement-like translations?compare Section  5.15.

Since BP was 3?5 decades old by then (Section  5.5), and pattern deformations 2 decades (Baird, 1990) (Section  5.14), these results seemed to suggest that advances in exploiting modern computing hardware were more important than advances in algorithms.

5.19. 2011: MPCNNs on GPU achieve superhuman vision performance
In 2011, a flexible GPU-implementation (Ciresan, Meier, Masci, Gambardella, & Schmidhuber, 2011) of Max-Pooling (MP) CNNs or Convnets was described (a GPU-MPCNN), building on earlier MP work (Weng et al., 1992) (Section  5.11) CNNs (Fukushima, 1979, LeCun et al., 1989) (Sections 5.4, 5.8, 5.16), and on early GPU-based CNNs without MP (Chellapilla et al., 2006) (Section  5.16); compare early GPU-NNs (Oh & Jung, 2004) and GPU-DBNs (Raina et al., 2009) (Section  5.17). MPCNNs have alternating convolutional layers (Section  5.4) and max-pooling layers (MP, Section  5.11) topped by standard fully connected layers. All weights are trained by BP (Sections 5.5, 5.8, 5.16) (Ranzato et al., 2007, Scherer et al., 2010). GPU-MPCNNs have become essential for many contest-winning FNNs (Sections 5.21, 5.22).

Multi-Column GPU-MPCNNs (Ciresan, Meier, Masci, & Schmidhuber, 2011) are committees (Breiman, 1996, Dietterich, 2000a, Hashem and Schmeiser, 1992, Schapire, 1990, Ueda, 2000, Wolpert, 1992) of GPU-MPCNNs with simple democratic output averaging. Several MPCNNs see the same input; their output vectors are used to assign probabilities to the various possible classes. The class with the on average highest probability is chosen as the system¡¯s classification of the present input. Compare earlier, more sophisticated ensemble methods (Schapire, 1990), the contest-winning ensemble Bayes-NN (Neal, 2006) of Section  5.14, and recent related work (Shao, Wu, & Li, 2014).

An ensemble of GPU-MPCNNs was the first system to achieve superhuman visual pattern recognition (Ciresan, Meier, Masci, Schmidhuber, 2011, Ciresan, Meier, et al., 2012) in a controlled competition, namely, the IJCNN 2011 traffic sign recognition contest in San Jose (CA) (Stallkamp et al., 2011, Stallkamp et al., 2012). This is of interest for fully autonomous, self-driving cars in traffic (e.g.,  Dickmanns et al., 1994). The GPU-MPCNN ensemble obtained 0.56% error rate and was twice better than human test subjects, three times better than the closest artificial NN competitor (Sermanet & LeCun, 2011), and six times better than the best non-neural method.

A few months earlier, the qualifying round was won in a 1st stage online competition, albeit by a much smaller margin: 1.02% (Ciresan, Meier, Masci, Schmidhuber, 2011) vs 1.03% for second place (Sermanet & LeCun, 2011). After the deadline, the organizers revealed that human performance on the test set was 1.19%. That is, the best methods already seemed human-competitive. However, during the qualifying it was possible to incrementally gain information about the test set by probing it through repeated submissions. This is illustrated by better and better results obtained by various teams over time (Stallkamp et al., 2012) (the organizers eventually imposed a limit of 10 resubmissions). In the final competition this was not possible.

This illustrates a general problem with benchmarks whose test sets are public, or at least can be probed to some extent: competing teams tend to overfit on the test set even when it cannot be directly used for training, only for evaluation.

In 1997 many thought it a big deal that human chess world champion Kasparov was beaten by an IBM computer. But back then computers could not at all compete with little kids in visual pattern recognition, which seems much harder than chess from a computational perspective. Of course, the traffic sign domain is highly restricted, and kids are still much better general pattern recognizers. Nevertheless, by 2011, deep NNs could already learn to rival them in important limited visual domains.

An ensemble of GPU-MPCNNs was also the first method to achieve human-competitive performance (around 0.2%) on MNIST (Ciresan, Meier, & Schmidhuber, 2012a). This represented a dramatic improvement, since by then the MNIST record had hovered around 0.4% for almost a decade (Sections 5.14, 5.16, 5.18).

Given all the prior work on (MP)CNNs (Sections 5.4, 5.8, 5.11, 5.16) and GPU-CNNs (Section  5.16), GPU-MPCNNs are not a breakthrough in the scientific sense. But they are a commercially relevant breakthrough in efficient coding that has made a difference in several contests since 2011. Today, most feedforward competition-winning deep NNs are (ensembles of) GPU-MPCNNs (Sections  5.21 2012: first contests won on ImageNet, object detection, segmentation, 5.22 2013-: more contests and benchmark records, 5.23 Currently successful techniques: LSTM RNNs and GPU-MPCNNs).

5.20. 2011: Hessian-free optimization for RNNs
Also in 2011 it was shown (Martens & Sutskever, 2011) that Hessian-free optimization (e.g.,  M©ªller, 1993, Pearlmutter, 1994, Schraudolph, 2002) (Section  5.6.2) can alleviate the Fundamental Deep Learning Problem (Section  5.9) in RNNs, outperforming standard gradient-based LSTM RNNs (Section  5.13) on several tasks. Compare other RNN algorithms (Jaeger, 2004, Koutnik et al., 2014, Pascanu, Mikolov, et al., 2013, Schmidhuber et al., 2007) that also at least sometimes yield better results than steepest descent for LSTM RNNs.

5.21. 2012: first contests won on ImageNet, object detection, segmentation
In 2012, an ensemble of GPU-MPCNNs (Section  5.19) achieved best results on the ImageNet classification benchmark (Krizhevsky, Sutskever, & Hinton, 2012), which is popular in the computer vision community. Here relatively large image sizes of 256 ¡¿ 256 pixels were necessary, as opposed to only 48 ¡¿ 48 pixels for the 2011 traffic sign competition (Section  5.19). See further improvements in Section  5.22.

Also in 2012, the biggest NN so far (109 free parameters) was trained in unsupervised mode (Sections 5.7, 5.15) on unlabeled data (Le et al., 2012), then applied to ImageNet. The codes across its top layer were used to train a simple supervised classifier, which achieved best results so far on 20,000 classes. Instead of relying on efficient GPU programming, this was done by brute force on 1000 standard machines with 16,000 cores.

So by 2011/2012, excellent results had been achieved by Deep Learners in image recognition and classification (Sections 5.19, 5.21). The computer vision community, however, is especially interested in object detection in large images, for applications such as image-based search engines, or for biomedical diagnosis where the goal may be to automatically detect tumors etc. in images of human tissue. Object detection presents additional challenges. One natural approach is to train a deep NN classifier on patches of big images, then use it as a feature detector to be shifted across unknown visual scenes, using various rotations and zoom factors. Image parts that yield highly active output units are likely to contain objects similar to those the NN was trained on.

2012 finally saw the first DL system (an ensemble of GPU-MPCNNs, Section  5.19) to win a contest on visual object detection (Ciresan, Giusti, Gambardella, & Schmidhuber, 2013) in large images of several million pixels (ICPR, 2012, Roux et al., 2013). Such biomedical applications may turn out to be among the most important applications of DL. The world spends over 10% of GDP on healthcare ( trillion USD per year), much of it on medical diagnosis through expensive experts. Partial automation of this could not only save lots of money, but also make expert diagnostics accessible to many who currently cannot afford it. It is gratifying to observe that today deep NNs may actually help to improve healthcare and perhaps save human lives.

2012 also saw the first pure image segmentation contest won by DL (Ciresan, Giusti, Gambardella, & Schmidhuber, 2012), again through an GPU-MPCNN ensemble (Segmentation of Neuronal Structures in EM Stacks Challenge, 2012).2 EM stacks are relevant for the recently approved huge brain projects in Europe and the US (e.g.,  Markram, 2012). Given electron microscopy images of stacks of thin slices of animal brains, the goal is to build a detailed 3D model of the brain¡¯s neurons and dendrites. But human experts need many hours and days and weeks to annotate the images: Which parts depict neuronal membranes? Which parts are irrelevant background? This needs to be automated (e.g.,  Turaga et al., 2010). Deep Multi-Column GPU-MPCNNs learned to solve this task through experience with many training images, and won the contest on all three evaluation metrics by a large margin, with superhuman performance in terms of pixel error.

Both object detection (Ciresan et al., 2013) and image segmentation (Ciresan, Giusti, et al., 2012) profit from fast MPCNN-based image scans that avoid redundant computations. Recent MPCNN scanners speed up naive implementations by up to three orders of magnitude (Giusti et al., 2013, Masci et al., 2013); compare earlier efficient methods for CNNs without MP (Vaillant, Monrocq, & LeCun, 1994).

Also in 2012, a system consisting of growing deep FNNs and 2D-BRNNs (Di Lena et al., 2012) won the CASP 2012 contest on protein contact map prediction. On the IAM-OnDoDB benchmark, LSTM RNNs (Section  5.13) outperformed all other methods (HMMs, SVMs) on online mode detection (Indermuhle et al., 2012, Otte et al., 2012) and keyword spotting (Indermuhle et al., 2011). On the long time lag problem of language modeling, LSTM RNNs outperformed all statistical approaches on the IAM-DB benchmark (Frinken et al., 2012); improved results were later obtained through a combination of NNs and HMMs (Zamora-Martinez et al., 2014). Compare earlier RNNs for object recognition through iterative image interpretation (Behnke, 2002, Behnke, 2003b, Behnke and Rojas, 1998); see also more recent publications (O¡¯Reilly et al., 2013, Wyatte et al., 2012) extending work on biologically plausible learning rules for RNNs (O¡¯Reilly, 1996).

5.22. 2013-: more contests and benchmark records
A stack (Fernandez et al., 2007b, Graves and Schmidhuber, 2009) (Section  5.10) of bi-directional LSTM RNNs (Graves & Schmidhuber, 2005) trained by CTC (Sections 5.13, 5.17) broke a famous TIMIT speech (phoneme) recognition record, achieving 17.7% test set error rate (Graves et al., 2013), despite thousands of man years previously spent on Hidden Markov Model (HMMs)-based speech recognition research. Compare earlier DBN results (Section  5.15).

CTC-LSTM also helped to score first at NIST¡¯s OpenHaRT2013 evaluation (Bluche et al., 2014). For optical character recognition (OCR), LSTM RNNs outperformed commercial recognizers of historical data (Breuel et al., 2013). LSTM-based systems also set benchmark records in language identification (Gonzalez-Dominguez et al., 2014), medium-vocabulary speech recognition (Geiger et al., 2014), prosody contour prediction (Fernandez et al., 2014), audio onset detection (Marchi et al., 2014), text-to-speech synthesis (Fan et al., 2014), and social signal classification (Brueckner & Schulter, 2014).

An LSTM RNN was used to estimate the state posteriors of an HMM; this system beat the previous state of the art in large vocabulary speech recognition (Sak, Senior, et al., 2014, Sak, Vinyals, et al., 2014). Another LSTM RNN with hundreds of millions of connections was used to rerank hypotheses of a statistical machine translation system; this system beat the previous state of the art in English to French translation (Sutskever et al., 2014).

A new record on the ICDAR Chinese handwriting recognition benchmark (over 3700 classes) was set on a desktop machine by an ensemble of GPU-MPCNNs (Section  5.19) with almost human performance (Ciresan & Schmidhuber, 2013); compare (Yin, Wang, Zhang, & Liu, 2013).

The MICCAI 2013 Grand Challenge on Mitosis Detection (Veta, Viergever, Pluim, Stathonikos, & van Diest, 2013) also was won by an object-detecting GPU-MPCNN ensemble (Ciresan et al., 2013). Its data set was even larger and more challenging than the one of ICPR 2012 (Section  5.21): a real-world data set including many ambiguous cases and frequently encountered problems such as imperfect slide staining.

Three 2D-CNNs (with mean-pooling instead of MP, Section  5.11) observing three orthogonal projections of 3D images outperformed traditional full 3D methods on the task of segmenting tibial cartilage in low field knee MRI scans (Prasoon et al., 2013).

Deep GPU-MPCNNs (Section  5.19) also helped to achieve new best results on important benchmarks of the computer vision community: ImageNet classification (Szegedy et al., 2014, Zeiler and Fergus, 2013) and?in conjunction with traditional approaches?PASCAL object detection (Girshick, Donahue, Darrell, & Malik, 2013). They also learned to predict bounding box coordinates of objects in the Imagenet 2013 database, and obtained state-of-the-art results on tasks of localization and detection (Sermanet et al., 2013). GPU-MPCNNs also helped to recognize multi-digit numbers in Google Street View images (Goodfellow, Bulatov, Ibarz, Arnoud, & Shet, 2014), where part of the NN was trained to count visible digits; compare earlier work on detecting ¡°numerosity¡± through DBNs (Stoianov & Zorzi, 2012). This system also excelled at recognizing distorted synthetic text in reCAPTCHA puzzles. Other successful CNN applications include scene parsing (Farabet, Couprie, Najman, & LeCun, 2013), object detection (Szegedy, Toshev, & Erhan, 2013), shadow detection (Khan, Bennamoun, Sohel, & Togneri, 2014), video classification (Karpathy et al., 2014), and Alzheimer¡¯s disease neuroimaging (Li et al., 2014).

Additional contests are mentioned in the web pages of the Swiss AI Lab IDSIA, the University of Toronto, NY University, and the University of Montreal.

5.23. Currently successful techniques: LSTM RNNs and GPU-MPCNNs
Most competition-winning or benchmark record-setting Deep Learners actually use one of two supervised techniques: (a) recurrent LSTM (1997) trained by CTC (2006) (Sections 5.13, 5.17, 5.21, 5.22), or (b) feedforward GPU-MPCNNs (2011, Sections 5.19, 5.21, 5.22) based on CNNs (1979, Section  5.4) with MP (1992, Section  5.11) trained through BP (1989?2007, Sections 5.8, 5.16).

Exceptions include two 2011 contests (Goodfellow et al., 2011, Goodfellow et al., 2012, Mesnil et al., 2011) specialized on Transfer Learning from one data set to another (e.g.,  Caruana, 1997, Pan and Yang, 2010, Schmidhuber, 2004). However, deep GPU-MPCNNs do allow for pure SL-based transfer (Ciresan, Meier, & Schmidhuber, 2012b), where pre-training on one training set greatly improves performance on quite different sets, also in more recent studies (Donahue et al., 2013, Oquab et al., 2013). In fact, deep MPCNNs pre-trained by SL can extract useful features from quite diverse off-training-set images, yielding better results than traditional, widely used features such as SIFT (Lowe, 1999, Lowe, 2004) on many vision tasks (Razavian, Azizpour, Sullivan, & Carlsson, 2014). To deal with changing data sets, slowly learning deep NNs were also combined with rapidly adapting ¡°surface¡± NNs (Kak, Chen, & Wang, 2010).

Remarkably, in the 1990s a trend went from partially unsupervised RNN stacks (Section  5.10) to purely supervised LSTM RNNs (Section  5.13), just like in the 2000s a trend went from partially unsupervised FNN stacks (Section  5.15) to purely supervised MPCNNs (Sections  5.16 2006/7: improved CNNs/GPU-CNNs/BP for MPCNNs/LSTM stacks, 5.17 2009: first official competitions won by RNNs, and with MPCNNs, 5.18 2010: plain backprop (+ distortions) on GPU breaks MNIST record, 5.19 2011: MPCNNs on GPU achieve superhuman vision performance, 5.20 2011: Hessian-free optimization for RNNs, 5.21 2012: first contests won on ImageNet, object detection, segmentation, 5.22 2013-: more contests and benchmark records). Nevertheless, in many applications it can still be advantageous to combine the best of both worlds?supervised learning and unsupervised pre-training (Sections 5.10, 5.15).

5.24. Recent tricks for improving SL deep NNs (compare Sections 5.6.2, 5.6.3)
DBN training (Section  5.15) can be improved through gradient enhancements and automatic learning rate adjustments during stochastic gradient descent (Cho, 2014, Cho et al., 2013), and through Tikhonov-type (Tikhonov, Arsenin, & John, 1977) regularization of RBMs (Cho, Ilin, & Raiko, 2012). Contractive AEs (Rifai, Vincent, Muller, Glorot, & Bengio, 2011) discourage hidden unit perturbations in response to input perturbations, similar to how FMS (Section  5.6.3) for Lococode AEs (Section  5.6.4) discourages output perturbations in response to weight perturbations.

Hierarchical CNNs in a Neural Abstraction Pyramid (e.g.,  Behnke, 2003b, Behnke, 2005) were trained to reconstruct images corrupted by structured noise (Behnke, 2001), thus enforcing increasingly abstract image representations in deeper and deeper layers. Denoising AEs later used a similar procedure (Vincent et al., 2008).

Dropout (Ba and Frey, 2013, Hinton, Srivastava, et al., 2012) removes units from NNs during training to improve generalization. Some view it as an ensemble method that trains multiple data models simultaneously (Baldi & Sadowski, 2014). Under certain circumstances, it could also be viewed as a form of training set augmentation: effectively, more and more informative complex features are removed from the training data. Compare dropout for RNNs (Pachitariu and Sahani, 2013, Pascanu, Gulcehre, et al., 2013, Pham et al., 2013). A deterministic approximation coined fast dropout (Wang & Manning, 2013) can lead to faster learning and evaluation and was adapted for RNNs (Bayer, Osendorfer, Chen, Urban, & van der Smagt, 2013). Dropout is closely related to older, biologically plausible techniques for adding noise to neurons or synapses during training (e.g.,  An, 1996, Hanson, 1990, Jim et al., 1995, Murray and Edwards, 1993, Nadal and Parga, 1994, Schuster, 1992), which in turn are closely related to finding perturbation-resistant low-complexity NNs, e.g., through FMS (Section  5.6.3). MDL-based stochastic variational methods (Graves, 2011) are also related to FMS. They are useful for RNNs, where classic regularizers such as weight decay (Section  5.6.3) represent a bias towards limited memory capacity (e.g.,  Pascanu, Mikolov, et al., 2013). Compare recent work on variational recurrent AEs (Bayer & Osendorfer, 2014).

The activation function  of Rectified Linear Units (ReLUs) is  for  otherwise?compare the old concept of half-wave rectified units (Malik & Perona, 1990). ReLU NNs are useful for RBMs (Maas et al., 2013, Nair and Hinton, 2010), outperformed sigmoidal activation functions in deep NNs (Glorot, Bordes, & Bengio, 2011), and helped to obtain best results on several benchmark problems across multiple domains (e.g.,  Dahl et al., 2013, Krizhevsky et al., 2012).

NNs with competing linear units tend to outperform those with non-competing nonlinear units, and avoid catastrophic forgetting through BP when training sets change over time (Srivastava, Masci, Kazerounian, Gomez, & Schmidhuber, 2013). In this context, choosing a learning algorithm may be more important than choosing activation functions (Goodfellow, Mirza, Da, Courville, & Bengio, 2014). Maxout NNs (Goodfellow, Warde-Farley, Mirza, Courville, & Bengio, 2013) combine competitive interactions and dropout (see above) to achieve excellent results on certain benchmarks. Compare early RNNs with competing units for SL and RL (Schmidhuber, 1989b). To address overfitting, instead of depending on pre-wired regularizers and hyper-parameters (Bishop, 2006, Hertz et al., 1991), self-delimiting RNNs (SLIM NNs) with competing units (Schmidhuber, 2012) can in principle learn to select their own runtime and their own numbers of effective free parameters, thus learning their own computable regularizers (Sections 4.4, 5.6.3), becoming fast and slim when necessary. One may penalize the task-specific total length of connections (e.g.,  Clune et al., 2013, Legenstein and Maass, 2002, Schmidhuber, 2012, Schmidhuber, 2013b) and communication costs of SLIM NNs implemented on the 3-dimensional brain-like multi-processor hardware to be expected in the future.

RmsProp (Schaul et al., 2013, Tieleman and Hinton, 2012) can speed up first order gradient descent methods (Sections 5.5, 5.6.2); compare vario- (Neuneier & Zimmermann, 1996), Adagrad (Duchi, Hazan, & Singer, 2011) and Adadelta (Zeiler, 2012). DL in NNs can also be improved by transforming hidden unit activations such that they have zero output and slope on average (Raiko, Valpola, & LeCun, 2012). Many additional, older tricks (Sections 5.6.2, 5.6.3) should also be applicable to today¡¯s deep NNs; compare (Montavon et al., 2012, Orr and Muller, 1998).

5.25. Consequences for neuroscience
It is ironic that artificial NNs (ANNs) can help to better understand biological NNs (BNNs)?see the ISBI 2012 results mentioned in Section  5.21 (Ciresan, Giusti, et al., 2012, Segmentation of Neuronal Structures in EM Stacks Challenge, 2012).

The feature detectors learned by single-layer visual ANNs are similar to those found in early visual processing stages of BNNs (e.g., Section  5.6.4). Likewise, the feature detectors learned in deep layers of visual ANNs should be highly predictive of what neuroscientists will find in deep layers of BNNs. While the visual cortex of BNNs may use quite different learning algorithms, its objective function to be minimized may be quite similar to the one of visual ANNs. In fact, results obtained with relatively deep artificial DBNs (Lee, Ekanadham, & Ng, 2007) and CNNs (Yamins, Hong, Cadieu, & DiCarlo, 2013) seem compatible with insights about the visual pathway in the primate cerebral cortex, which has been studied for many decades (e.g.,  Bichot et al., 2005, Connor et al., 2007, Desimone et al., 1984, DiCarlo et al., 2012, Felleman and Van Essen, 1991, Hubel and Wiesel, 1968, Hung et al., 2005, Kobatake and Tanaka, 1994, Kriegeskorte et al., 2008, Lennie and Movshon, 2005, Logothetis et al., 1995, Perrett et al., 1992, Perrett et al., 1982); compare a computer vision-oriented survey (Kruger et al., 2013).

5.26. DL with spiking neurons?
Many recent DL results profit from GPU-based traditional deep NNs, e.g., Sections  5.16 2006/7: improved CNNs/GPU-CNNs/BP for MPCNNs/LSTM stacks, 5.17 2009: first official competitions won by RNNs, and with MPCNNs, 5.18 2010: plain backprop (+ distortions) on GPU breaks MNIST record, 5.19 2011: MPCNNs on GPU achieve superhuman vision performance. Current GPUs, however, are little ovens, much hungrier for energy than biological brains, whose neurons efficiently communicate by brief spikes (FitzHugh, 1961, Hodgkin and Huxley, 1952, Nagumo et al., 1962), and often remain quiet. Many computational models of such spiking neurons have been proposed and analyzed (e.g.,  Amit and Brunel, 1997, Bohte et al., 2002, Brea et al., 2013, Brette et al., 2007, Brunel, 2000, Deco and Rolls, 2005, Gerstner and Kistler, 2002, Gerstner and van Hemmen, 1992, Hoerzer et al., 2014, Izhikevich et al., 2003, Kasabov, 2014, Kempter et al., 1999, Kistler et al., 1997, Maass, 1996, Maass, 1997, Maex and Orban, 1996, Nessler et al., 2013, Rezende and Gerstner, 2014, Seung, 2003, Song et al., 2000, Stemmler, 1996, Stoop et al., 2000, Tsodyks et al., 1998, Tsodyks et al., 1996, Zipser et al., 1993).

Future energy-efficient hardware for DL in NNs may implement aspects of such models (e.g.,  Fieres et al., 2008, Glackin et al., 2005, Indiveri et al., 2011, Jin et al., 2010, Khan et al., 2008, Liu et al., 2001, Merolla et al., 2014, Neil and Liu, 2014, Roggen et al., 2003, Schemmel et al., 2006, Serrano-Gotarredona et al., 2009). A simulated, event-driven, spiking variant (Neftci, Das, Pedroni, Kreutz-Delgado, & Cauwenberghs, 2014) of an RBM (Section  5.15) was trained by a variant of the Contrastive Divergence algorithm (Hinton, 2002). Spiking nets were evolved to achieve reasonable performance on small face recognition data sets (Wysoski, Benuskova, & Kasabov, 2010) and to control simple robots (Floreano and Mattiussi, 2001, Hagras et al., 2004). A spiking DBN with about 250,000 neurons (as part of a larger NN;  Eliasmith, 2013, Eliasmith et al., 2012) achieved 6% error rate on MNIST; compare similar results with a spiking DBN variant of depth 3 using a neuromorphic event-based sensor (O¡¯Connor, Neil, Liu, Delbruck, & Pfeiffer, 2013). In practical applications, however, current artificial networks of spiking neurons cannot yet compete with the best traditional deep NNs (e.g., compare MNIST results of Section  5.19).

6. DL in FNNs and RNNs for Reinforcement Learning (RL)
So far we have focused on Deep Learning (DL) in supervised or unsupervised NNs. Such NNs learn to perceive/encode/predict/classify patterns or pattern sequences, but they do not learn to act in the more general sense of Reinforcement Learning (RL) in unknown environments (see surveys, e.g.,  Kaelbling et al., 1996, Sutton and Barto, 1998, Wiering and van Otterlo, 2012). Here we add a discussion of DL FNNs and RNNs for RL. It will be shorter than the discussion of FNNs and RNNs for SL and UL (Section  5), reflecting the current size of the various fields.

Without a teacher, solely from occasional real-valued pain and pleasure signals, RL agents must discover how to interact with a dynamic, initially unknown environment to maximize their expected cumulative reward signals (Section  2). There may be arbitrary, a priori unknown delays between actions and perceivable consequences. The problem is as hard as any problem of computer science, since any task with a computable description can be formulated in the RL framework (e.g.,  Hutter, 2005). For example, an answer to the famous question of whether  (Cook, 1971, Levin, 1973b) would also set limits for what is achievable by general RL. Compare more specific limitations, e.g., Blondel and Tsitsiklis (2000), Madani, Hanks, and Condon (2003) and Vlassis, Littman, and Barber (2012). The following subsections mostly focus on certain obvious intersections between DL and RL?they cannot serve as a general RL survey.

6.1. RL through NN world models yields RNNs with deep CAPs
In the special case of an RL FNN controller  interacting with a deterministic, predictable environment, a separate FNN called  can learn to become ¡¯s world model through system identification, predicting ¡¯s inputs from previous actions and inputs (e.g.,  Cochocki and Unbehauen, 1993, Ge et al., 2010, Gomi and Kawato, 1993, Jordan, 1988, Jordan and Rumelhart, 1990, Levin and Narendra, 1995, Ljung, 1998, Miller et al., 1995, Munro, 1987, Narendra and Parthasarathy, 1990, Prokhorov et al., 2001, Robinson and Fallside, 1989, Schmidhuber, 1990d, Werbos, 1981, Werbos, 1987, Werbos, 1989a, Werbos, 1989b, Werbos, 1992). Assume  has learned to produce accurate predictions. We can use  to substitute the environment. Then  and  form an RNN where ¡¯s outputs become inputs of , whose outputs (actions) in turn become inputs of . Now BP for RNNs (Section  5.5.1) can be used to achieve desired input events such as high real-valued reward signals: While ¡¯s weights remain fixed, gradient information for ¡¯s weights is propagated back through  down into  and back through  etc. To a certain extent, the approach is also applicable in probabilistic or uncertain environments, as long as the inner products of ¡¯s -based gradient estimates and ¡¯s ¡°true¡± gradients tend to be positive.

In general, this approach implies deep CAPs for , unlike in DP-based traditional RL (Section  6.2). Decades ago, the method was used to learn to back up a model truck (Nguyen & Widrow, 1989). An RL active vision system used it to learn sequential shifts (saccades) of a fovea, to detect targets in visual scenes (Schmidhuber & Huber, 1991), thus learning to control selective attention. Compare RL-based attention learning without NNs (Whitehead, 1992).

To allow for memories of previous events in partially observable worlds (Section  6.3), the most general variant of this technique uses RNNs instead of FNNs to implement both  and (Feldkamp and Puskorius, 1998, Schmidhuber, 1990d, Schmidhuber, 1991c). This may cause deep CAPs not only for  but also for .

 can also be used to optimize expected reward by planning future action sequences (Schmidhuber, 1990d). In fact, the winners of the 2004 RoboCup World Championship in the fast league (Egorova et al., 2004) trained NNs to predict the effects of steering signals on fast robots with 4 motors for 4 different wheels. During play, such NN models were used to achieve desirable subgoals, by optimizing action sequences through quickly planning ahead. The approach also was used to create self-healing robots able to compensate for faulty motors whose effects do not longer match the predictions of the NN models (Gloye et al., 2005, Schmidhuber, 2007).

Typically  is not given in advance. Then an essential question is: which experiments should  conduct to quickly improve ? The Formal Theory of Fun and Creativity (e.g.,  Schmidhuber, 2006a, Schmidhuber, 2013b) formalizes driving forces and value functions behind such curious and exploratory behavior: A measure of the learning progress of  becomes the intrinsic reward of  (Schmidhuber, 1991a); compare (Oudeyer et al., 2013, Singh et al., 2005). This motivates  to create action sequences (experiments) such that  makes quick progress.

6.2. Deep FNNs for traditional RL and Markov Decision Processes (MDPs)
The classical approach to RL (Bertsekas and Tsitsiklis, 1996, Samuel, 1959) makes the simplifying assumption of Markov Decision Processes (MDPs): the current input of the RL agent conveys all information necessary to compute an optimal next output event or decision. This allows for greatly reducing CAP depth in RL NNs (Sections 3, 6.1) by using the Dynamic Programming (DP) trick (Bellman, 1957). The latter is often explained in a probabilistic framework (e.g.,  Sutton & Barto, 1998), but its basic idea can already be conveyed in a deterministic setting. For simplicity, using the notation of Section  2, let input events  encode the entire current state of the environment, including a real-valued reward  (no need to introduce additional vector-valued notation, since real values can encode arbitrary vectors of real values). The original RL goal (find weights that maximize the sum of all rewards of an episode) is replaced by an equivalent set of alternative goals set by a real-valued value function  defined on input events. Consider any two subsequent input events . Recursively define , where  if  is the last input event. Now search for weights that maximize the  of all input events, by causing appropriate output events or actions.

Due to the Markov assumption, an FNN suffices to implement the policy that maps input to output events. Relevant CAPs are not deeper than this FNN.  itself is often modeled by a separate FNN (also yielding typically short CAPs) learning to approximate  only from local information .

Many variants of traditional RL exist (e.g.,  Abounadi et al., 2002, Baird, 1995, Baird and Moore, 1999, Barto et al., 1983, Bertsekas, 2001, Bradtke et al., 1996, Brafman and Tennenholtz, 2002, Kaelbling et al., 1995, Lagoudakis and Parr, 2003, Maei and Sutton, 2010, Mahadevan, 1996, Meuleau et al., 1999, Moore and Atkeson, 1993, Morimoto and Doya, 2000, Peng and Williams, 1996, Prokhorov and Wunsch, 1997, Rummery and Niranjan, 1994, Santamaria et al., 1997, Schwartz, 1993, Singh, 1994, Sutton and Barto, 1998, Sutton et al., 2008, Tsitsiklis and van Roy, 1996, van Hasselt, 2012, Watkins, 1989, Watkins and Dayan, 1992, Wiering and Schmidhuber, 1998b). Most are formulated in a probabilistic framework, and evaluate pairs of input and output (action) events (instead of input events only). To facilitate certain mathematical derivations, some discount delayed rewards, but such distortions of the original RL problem are problematic.

Perhaps the most well-known RL NN is the world-class RL backgammon player (Tesauro, 1994), which achieved the level of human world champions by playing against itself. Its nonlinear, rather shallow FNN maps a large but finite number of discrete board states to values. More recently, a rather deep GPU-CNN was used in a traditional RL framework to play several Atari 2600 computer games directly from 84 ¡¿ 84 pixel 60 Hz video input (Mnih et al., 2013), using experience replay (Lin, 1993), extending previous work on Neural Fitted Q-Learning (NFQ) (Riedmiller, 2005). Even better results are achieved by using (slow) Monte Carlo tree planning to train comparatively fast deep NNs (Guo, Singh, Lee, Lewis, & Wang, 2014). Compare RBM-based RL (Sallans & Hinton, 2004) with high-dimensional inputs (Elfwing, Otsuka, Uchibe, & Doya, 2010), earlier RL Atari players (Gruttner, Sehnke, Schaul, & Schmidhuber, 2010), and an earlier, raw video-based RL NN for computer games (Koutnik, Cuccu, Schmidhuber, & Gomez, 2013) trained by Indirect Policy Search (Section  6.7).

6.3. Deep RL RNNs for partially observable MDPs (POMDPs)
The Markov assumption (Section  6.2) is often unrealistic. We cannot directly perceive what is behind our back, let alone the current state of the entire universe. However, memories of previous events can help to deal with partially observable Markov decision problems (POMDPs) (e.g.,  Boutilier and Poole, 1996, Jaakkola et al., 1995, Kaelbling et al., 1995, Kimura et al., 1997, Lin, 1993, Littman et al., 1995, McCallum, 1996, Otsuka et al., 2010, Ring, 1991, Ring, 1993, Ring, 1994, Schmidhuber, 1990d, Schmidhuber, 1991c, Teller, 1994, Wiering and Schmidhuber, 1996, Wiering and Schmidhuber, 1998a, Williams, 1992a). A naive way of implementing memories without leaving the MDP framework (Section  6.2) would be to simply consider a possibly huge state space, namely, the set of all possible observation histories and their prefixes. A more realistic way is to use function approximators such as RNNs that produce compact state features as a function of the entire history seen so far. Generally speaking, POMDP RL often uses DL RNNs to learn which events to memorize and which to ignore. Three basic alternatives are:
1.
Use an RNN as a value function mapping arbitrary event histories to values (e.g.,  Bakker, 2002, Lin, 1993, Schmidhuber, 1990b, Schmidhuber, 1991c). For example, deep LSTM RNNs were used in this way for RL robots (Bakker, Zhumatiy, Gruener, & Schmidhuber, 2003).

2.
Use an RNN controller in conjunction with a second RNN as predictive world model, to obtain a combined RNN with deep CAPs?see Section  6.1.

3.
Use an RNN for RL by Direct Search (Section  6.6) or Indirect Search (Section  6.7) in weight space.

In general, however, POMDPs may imply greatly increased CAP depth.

6.4. RL facilitated by deep UL in FNNs and RNNs
RL machines may profit from UL for input preprocessing (e.g.,  Jodogne & Piater, 2007). In particular, an UL NN can learn to compactly encode environmental inputs such as images or videos, e.g., Sections 5.7, 5.10, 5.15. The compact codes (instead of the high-dimensional raw data) can be fed into an RL machine, whose job thus may become much easier (Cuccu et al., 2011, Legenstein et al., 2010), just like SL may profit from UL, e.g., Sections 5.7, 5.10, 5.15. For example, NFQ (Riedmiller, 2005) was applied to real-world control tasks (Lange and Riedmiller, 2010, Riedmiller et al., 2012) where purely visual inputs were compactly encoded by deep autoencoders (Sections 5.7, 5.15). RL combined with UL based on Slow Feature Analysis (Kompella et al., 2012, Wiskott and Sejnowski, 2002) enabled a real humanoid robot to learn skills from raw high-dimensional video streams (Luciw, Kompella, Kazerounian, & Schmidhuber, 2013). To deal with POMDPs (Section  6.3) involving high-dimensional inputs, RBM-based RL was used (Otsuka, 2010), and a RAAM (Pollack, 1988) (Section  5.7) was employed as a deep unsupervised sequence encoder for RL (Gisslen et al., 2011). Certain types of RL and UL also were combined in biologically plausible RNNs with spiking neurons (Section  5.26) (e.g.,  Klampfl and Maass, 2013, Rezende and Gerstner, 2014, Yin et al., 2012).

6.5. Deep hierarchical RL (HRL) and subgoal learning with FNNs and RNNs
Multiple learnable levels of abstraction (Bengio et al., 2013, Deng and Yu, 2014, Fu, 1977, Lenat and Brown, 1984, Ring, 1994) seem as important for RL as for SL. Work on NN-based Hierarchical RL (HRL) has been published since the early 1990s. In particular, gradient-based subgoal discovery with FNNs or RNNs decomposes RL tasks into subtasks for RL submodules (Schmidhuber, 1991b, Schmidhuber and Wahnsiedler, 1992). Numerous alternative HRL techniques have been proposed (e.g.,  Bakker and Schmidhuber, 2004, Barto and Mahadevan, 2003, Dietterich, 2000b, Doya et al., 2002, Ghavamzadeh and Mahadevan, 2003, Jameson, 1991, Menache et al., 2002, Moore and Atkeson, 1995, Precup et al., 1998, Ring, 1991, Ring, 1994, Samejima et al., 2003, Simsek and Barto, 2008, Tenenberg et al., 1993, Weiss, 1994, Whiteson et al., 2005). While HRL frameworks such as Feudal RL (Dayan & Hinton, 1993) and options (Barto et al., 2004, Singh et al., 2005, Sutton, Precup, et al., 1999) do not directly address the problem of automatic subgoal discovery, HQ-Learning (Wiering & Schmidhuber, 1998a) automatically decomposes POMDPs (Section  6.3) into sequences of simpler subtasks that can be solved by memoryless policies learnable by reactive sub-agents. Recent HRL organizes potentially deep NN-based RL sub-modules into self-organizing, 2-dimensional motor control maps (Ring, Schaul, & Schmidhuber, 2011) inspired by neurophysiological findings (Graziano, 2009).

6.6. Deep RL by direct NN search/policy gradients/evolution
Not quite as universal as the methods of Section  6.8, yet both practical and more general than most traditional RL algorithms (Section  6.2), are methods for Direct Policy Search (DS). Without a need for value functions or Markovian assumptions (Sections 6.2, 6.3), the weights of an FNN or RNN are directly evaluated on the given RL problem. The results of successive trials inform further search for better weights. Unlike with RL supported by BP (Sections 5.5, 6.3, 6.1), CAP depth (Sections 3, 5.9) is not a crucial issue. DS may solve the credit assignment problem without backtracking through deep causal chains of modifiable parameters?it neither cares for their existence, nor tries to exploit them.

An important class of DS methods for NNs are Policy Gradient methods (Aberdeen, 2003, Baxter and Bartlett, 2001, Ghavamzadeh and Mahadevan, 2003, Grondman et al., 2012, Gruttner et al., 2010, Heess et al., 2012, Kohl and Stone, 2004, Peters, 2010, Peters and Schaal, 2008a, Peters and Schaal, 2008b, Ruckstie©¬ et al., 2008, Sehnke et al., 2010, Sutton, McAllester, et al., 1999, Wierstra et al., 2010, Wierstra et al., 2008, Williams, 1986, Williams, 1988, Williams, 1992a). Gradients of the total reward with respect to policies (NN weights) are estimated (and then exploited) through repeated NN evaluations.

RL NNs can also be evolved through Evolutionary Algorithms (EAs) (Fogel et al., 1966, Goldberg, 1989, Holland, 1975, Rechenberg, 1971, Schwefel, 1974) in a series of trials. Here several policies are represented by a population of NNs improved through mutations and/or repeated recombinations of the population¡¯s fittest individuals (e.g.,  Fogel et al., 1990, Happel and Murre, 1994, Maniezzo, 1994, Montana and Davis, 1989, Nolfi, Parisi, et al., 1994). Compare Genetic Programming (GP) (Cramer, 1985) (see also  Smith, 1980) which can be used to evolve computer programs of variable size (Dickmanns et al., 1987, Koza, 1992), and Cartesian GP (Miller and Harding, 2009, Miller and Thomson, 2000) for evolving graph-like programs, including NNs (Khan, Khan, & Miller, 2010) and their topology (Turner & Miller, 2013). Related methods include probability distribution-based EAs (Baluja, 1994, Larraanaga and Lozano, 2001, Sa©©ustowicz and Schmidhuber, 1997, Saravanan and Fogel, 1995), Covariance Matrix Estimation Evolution Strategies (CMA-ES) (Hansen et al., 2003, Hansen and Ostermeier, 2001, Heidrich-Meisner and Igel, 2009, Igel, 2003), and NeuroEvolution of Augmenting Topologies (NEAT) (Stanley & Miikkulainen, 2002). Hybrid methods combine traditional NN-based RL (Section  6.2) and EAs (e.g.,  Whiteson & Stone, 2006).

Since RNNs are general computers, RNN evolution is like GP in the sense that it can evolve general programs. Unlike sequential programs learned by traditional GP, however, RNNs can mix sequential and parallel information processing in a natural and efficient way, as already mentioned in Section  1. Many RNN evolvers have been proposed (e.g.,  Cliff et al., 1993, Juang, 2004, Miglino et al., 1995, Miller et al., 1989, Moriarty, 1997, Nolfi, Floreano, et al., 1994, Pasemann et al., 1999, Sims, 1994, Whiteson, 2012, Wieland, 1991, Yamauchi and Beer, 1994, Yao, 1993). One particularly effective family of methods coevolves neurons, combining them into networks, and selecting those neurons for reproduction that participated in the best-performing networks (Gomez, 2003, Gomez and Miikkulainen, 2003, Moriarty and Miikkulainen, 1996). This can help to solve deep POMDPs (Gomez & Schmidhuber, 2005). Co-Synaptic Neuro-Evolution (CoSyNE) does something similar on the level of synapses or weights (Gomez, Schmidhuber, & Miikkulainen, 2008); benefits of this were shown on difficult nonlinear POMDP benchmarks.

Natural Evolution Strategies (NES) (Glasmachers et al., 2010, Sun et al., 2013, Sun et al., 2009, Wierstra et al., 2008) link policy gradient methods and evolutionary approaches through the concept of Natural Gradients (Amari, 1998). RNN evolution may also help to improve SL for deep RNNs through Evolino (Schmidhuber et al., 2007) (Section  5.9).

6.7. Deep RL by indirect policy search/compressed NN search
Some DS methods (Section  6.6) can evolve NNs with hundreds or thousands of weights, but not millions. How to search for large and deep NNs? Most SL and RL methods mentioned so far somehow search the space of weights . Some profit from a reduction of the search space through shared  that get reused over and over again, e.g., in CNNs (Sections 5.4, 5.8, 5.16, 5.21), or in RNNs for SL (Sections 5.5, 5.13, 5.17) and RL (Sections 6.1, 6.3, 6.6).

It may be possible, however, to exploit additional regularities/compressibilities in the space of solutions, through indirect search in weight space. Instead of evolving large NNs directly (Section  6.6), one can sometimes greatly reduce the search space by evolving compact encodings of NNs, e.g., through Lindenmeyer Systems (Jacob et al., 1994, Lindenmayer, 1968), graph rewriting (Kitano, 1990), Cellular Encoding (Gruau, Whitley, & Pyeatt, 1996), HyperNEAT (Clune et al., 2011, D¡¯Ambrosio and Stanley, 2007, Stanley et al., 2009, van den Berg and Whiteson, 2013) (extending NEAT; Section  6.6), and extensions thereof (e.g.,  Risi & Stanley, 2012). This helps to avoid overfitting (compare Sections 5.6.3, 5.24) and is closely related to the topics of regularization and MDL (Section  4.4).

A general approach (Schmidhuber, 1997) for both SL and RL seeks to compactly encode weights of large NNs (Schmidhuber, 1997) through programs written in a universal programming language (Church, 1936, Godel, 1931, Post, 1936, Turing, 1936). Often it is much more efficient to systematically search the space of such programs with a bias towards short and fast programs (Levin, 1973b, Schmidhuber, 1997, Schmidhuber, 2004), instead of directly searching the huge space of possible NN weight matrices. A previous universal language for encoding NNs was assembler-like (Schmidhuber, 1997). More recent work uses more practical languages based on coefficients of popular transforms (Fourier, wavelet, etc.). In particular, RNN weight matrices may be compressed like images, by encoding them through the coefficients of a discrete cosine transform (DCT) (Koutnik et al., 2013, Koutnik et al., 2010). Compact DCT-based descriptions can be evolved through NES or CoSyNE (Section  6.6). An RNN with over a million weights learned (without a teacher) to drive a simulated car in the TORCS driving game (Loiacono et al., 2011, Loiacono et al., 2009), based on a high-dimensional video-like visual input stream (Koutnik et al., 2013). The RNN learned both control and visual processing from scratch, without being aided by UL. (Of course, UL might help to generate more compact image codes (Sections 6.4, 4.2) to be fed into a smaller RNN, to reduce the overall computational effort.)

6.8. Universal RL
General purpose learning algorithms may improve themselves in open-ended fashion and environment-specific ways in a lifelong learning context (Schmidhuber, 1987, Schmidhuber, Zhao, and Schraudolph, 1997, Schmidhuber, Zhao, and Wiering, 1997). The most general type of RL is constrained only by the fundamental limitations of computability identified by the founders of theoretical computer science (Church, 1936, Godel, 1931, Post, 1936, Turing, 1936). Remarkably, there exist blueprints of universal problem solvers or universal RL machines for unlimited problem depth that are time-optimal in various theoretical senses (Hutter, 2002, Hutter, 2005, Schmidhuber, 2002, Schmidhuber, 2006b). In particular, the Godel Machine can be implemented on general computers such as RNNs and may improve any part of its software (including the learning algorithm itself) in a way that is provably time-optimal in a certain sense (Schmidhuber, 2006b). It can be initialized by an asymptotically optimal meta-method (Hutter, 2002) (also applicable to RNNs) which will solve any well-defined problem as quickly as the unknown fastest way of solving it, save for an additive constant overhead that becomes negligible as problem size grows. Note that most problems are large; only few are small. AI and DL researchers are still in business because many are interested in problems so small that it is worth trying to reduce the overhead through less general methods, including heuristics. Here I will not further discuss universal RL methods, which go beyond what is usually called DL.

7. Conclusion and outlook
Deep Learning (DL) in Neural Networks (NNs) is relevant for Supervised Learning (SL) (Section  5), Unsupervised Learning (UL) (Section  5), and Reinforcement Learning (RL) (Section  6). By alleviating problems with deep Credit Assignment Paths (CAPs, Sections 3, 5.9), UL (Section  5.6.4) cannot only facilitate SL of sequences (Section  5.10) and stationary patterns (Sections 5.7, 5.15), but also RL (Sections 6.4, 4.2). Dynamic Programming (DP, Section  4.1) is important for both deep SL (Section  5.5) and traditional RL with deep NNs (Section  6.2). A search for solution-computing, perturbation-resistant (Sections 5.6.3, 5.15, 5.24), low-complexity NNs describable by few bits of information (Section  4.4) can reduce overfitting and improve deep SL & UL (Sections 5.6.3, 5.6.4) as well as RL (Section  6.7), also in the case of partially observable environments (Section  6.3). Deep SL, UL, RL often create hierarchies of more and more abstract representations of stationary data (Sections 5.3, 5.7, 5.15), sequential data (Section  5.10), or RL policies (Section  6.5). While UL can facilitate SL, pure SL for feedforward NNs (FNNs) (Sections 5.5, 5.8, 5.16, 5.18) and recurrent NNs (RNNs) (Sections 5.5, 5.13) did not only win early contests (Sections 5.12, 5.14) but also most of the recent ones (Sections  5.17 2009: first official competitions won by RNNs, and with MPCNNs, 5.18 2010: plain backprop (+ distortions) on GPU breaks MNIST record, 5.19 2011: MPCNNs on GPU achieve superhuman vision performance, 5.20 2011: Hessian-free optimization for RNNs, 5.21 2012: first contests won on ImageNet, object detection, segmentation, 5.22 2013-: more contests and benchmark records). Especially DL in FNNs profited from GPU implementations (Sections  5.16 2006/7: improved CNNs/GPU-CNNs/BP for MPCNNs/LSTM stacks, 5.17 2009: first official competitions won by RNNs, and with MPCNNs, 5.18 2010: plain backprop (+ distortions) on GPU breaks MNIST record, 5.19 2011: MPCNNs on GPU achieve superhuman vision performance). In particular, GPU-based (Section  5.19) Max-Pooling (Section  5.11) Convolutional NNs (Sections 5.4, 5.8, 5.16) won competitions not only in pattern recognition (Sections  5.19 2011: MPCNNs on GPU achieve superhuman vision performance, 5.20 2011: Hessian-free optimization for RNNs, 5.21 2012: first contests won on ImageNet, object detection, segmentation, 5.22 2013-: more contests and benchmark records) but also image segmentation (Section  5.21) and object detection (Sections 5.21, 5.22).

Unlike these systems, humans learn to actively perceive patterns by sequentially directing attention to relevant parts of the available data. Near future deep NNs will do so, too, extending previous work since 1990 on NNs that learn selective attention through RL of (a) motor actions such as saccade control (Section  6.1) and (b) internal actions controlling spotlights of attention within RNNs, thus closing the general sensorimotor loop through both external and internal feedback (e.g., Sections 2, 5.21, 6.6, 6.7).

Many future deep NNs will also take into account that it costs energy to activate neurons, and to send signals between them. Brains seem to minimize such computational costs during problem solving in at least two ways: (1) At a given time, only a small fraction of all neurons is active because local competition through winner-take-all mechanisms shuts down many neighboring neurons, and only winners can activate other neurons through outgoing connections (compare SLIM NNs; Section  5.24). (2) Numerous neurons are sparsely connected in a compact 3D volume by many short-range and few long-range connections (much like microchips in traditional supercomputers). Often neighboring neurons are allocated to solve a single task, thus reducing communication costs. Physics seems to dictate that any efficient computational hardware will in the future also have to be brain-like in keeping with these two constraints. The most successful current deep RNNs, however, are not. Unlike certain spiking NNs (Section  5.26), they usually activate all units at least slightly, and tend to be strongly connected, ignoring natural constraints of 3D hardware. It should be possible to improve them by adopting (1) and (2), and by minimizing non-differentiable energy and communication costs through direct search in program (weight) space (e.g., Sections 6.6, 6.7). These more brain-like RNNs will allocate neighboring RNN parts to related behaviors, and distant RNN parts to less related ones, thus self-modularizing in a way more general than that of traditional self-organizing maps in FNNs (Section  5.6.4). They will also implement Occam¡¯s razor (Sections 4.4, 5.6.3) as a by-product of energy minimization, by finding simple (highly generalizing) problem solutions that require few active neurons and few, mostly short connections.

The more distant future may belong to general purpose learning algorithms that improve themselves in provably optimal ways (Section  6.8), but these are not yet practical or commercially relevant.

Acknowledgments
Since 16 April 2014, drafts of this paper have undergone massive open online peer review through public mailing lists including connectionists@cs.cmu.edu, ml-news@googlegroups.com, comp-neuro@neuroinf.org, genetic_programming@yahoogroups.com, rl-list@googlegroups.com, imageworld@diku.dk, Google+  machine learning forum. Thanks to numerous NN/DL experts for valuable comments. Thanks to SNF, DFG, and the European Commission for partially funding my DL research group in the past quarter-century. The contents of this paper may be used for educational and non-commercial purposes, including articles for Wikipedia and similar sites.

References
Aberdeen, 2003
D. Aberdeen
Policy-gradient algorithms for partially observable Markov decision processes
(Ph.D. thesis)
Australian National University (2003)
Abounadi et al., 2002
J. Abounadi, D. Bertsekas, V.S. Borkar
Learning algorithms for Markov decision processes with average cost
SIAM Journal on Control and Optimization, 40 (3) (2002), pp. 681-698
Akaike, 1970
H. Akaike
Statistical predictor identification
Annals of the Institute of Statistical Mathematics, 22 (1970), pp. 203-217
Akaike, 1973
H. Akaike
Information theory and an extension of the maximum likelihood principle
Second intl. symposium on information theory, Akademinai Kiado (1973), pp. 267-281
Akaike, 1974
H. Akaike
A new look at the statistical model identification
IEEE Transactions on Automatic Control, 19 (6) (1974), pp. 716-723
Allender, 1992
A. Allender
Application of time-bounded Kolmogorov complexity in complexity theory
O. Watanabe (Ed.), Kolmogorov complexity and computational complexity, EATCS monographs on theoretical computer science, Springer (1992), pp. 6-22
Almeida, 1987
Almeida, L. B. (1987). A learning rule for asynchronous perceptrons with feedback in a combinatorial environment. In IEEE 1st international conference on neural networks, vol. 2 (pp. 609?618).
Almeida et al., 1997
L.B. Almeida, L.B. Almeida, T. Langlois, J.D. Amaral, R.A. Redol
On-line step size adaptation. Technical report, INESC, 9 Rua Alves Redol, 1000
(1997)
Amari, 1967
S. Amari
A theory of adaptive pattern classifiers
IEEE Transactions on Electronic Computers, 16 (3) (1967), pp. 299-307
Amari, 1998
S.-I. Amari
Natural gradient works efficiently in learning
Neural Computation, 10 (2) (1998), pp. 251-276
Amari et al., 1996
S. Amari, A. Cichocki, H. Yang
A new learning algorithm for blind signal separation
D.S. Touretzky, M.C. Mozer, M.E. Hasselmo (Eds.), Advances in neural information processing systems (NIPS), vol. 8, The MIT Press (1996)
Amari and Murata, 1993
S. Amari, N. Murata
Statistical theory of learning curves under entropic loss criterion
Neural Computation, 5 (1) (1993), pp. 140-153
Amit and Brunel, 1997
D.J. Amit, N. Brunel
Dynamics of a recurrent network of spiking neurons before and following learning
Network: Computation in Neural Systems, 8 (4) (1997), pp. 373-404
An, 1996
G. An
The effects of adding noise during backpropagation training on a generalization performance
Neural Computation, 8 (3) (1996), pp. 643-674
Andrade et al., 1993
M.A. Andrade, P. Chacon, J.J. Merelo, F. Moran
Evaluation of secondary structure of proteins from UV circular dichroism spectra using an unsupervised learning neural network
Protein Engineering, 6 (4) (1993), pp. 383-390
Andrews et al., 1995
R. Andrews, J. Diederich, A.B. Tickle
Survey and critique of techniques for extracting rules from trained artificial neural networks
Knowledge-Based Systems, 8 (6) (1995), pp. 373-389
ArticleDownload PDF
Anguita and Gomes, 1996
D. Anguita, B.A. Gomes
Mixing floating- and fixed-point formats for neural network learning on neuroprocessors
Microprocessing and Microprogramming, 41 (10) (1996), pp. 757-769
ArticleDownload PDF
Anguita et al., 1994
D. Anguita, G. Parodi, R. Zunino
An efficient implementation of BP on RISC-based workstations
Neurocomputing, 6 (1) (1994), pp. 57-65
ArticleDownload PDF
Arel et al., 2010
I. Arel, D.C. Rose, T.P. Karnowski
Deep machine learning?a new frontier in artificial intelligence research
IEEE Computational Intelligence Magazine, 5 (4) (2010), pp. 13-18
Ash, 1989
T. Ash
Dynamic node creation in backpropagation neural networks
Connection Science, 1 (4) (1989), pp. 365-375
Atick et al., 1992
J.J. Atick, Z. Li, A.N. Redlich
Understanding retinal color coding from first principles
Neural Computation, 4 (1992), pp. 559-572
Atiya and Parlos, 2000
A.F. Atiya, A.G. Parlos
New results on recurrent network training: unifying the algorithms and accelerating convergence
IEEE Transactions on Neural Networks, 11 (3) (2000), pp. 697-709
Ba and Frey, 2013
J. Ba, B. Frey
Adaptive dropout for training deep neural networks
Advances in neural information processing systems (NIPS) (2013), pp. 3084-3092
Baird, 1990
Baird, H. (1990). Document image defect models. In Proceddings, IAPR workshop on syntactic and structural pattern recognition.
Baird, 1995
Baird, L. C. (1995). Residual algorithms: Reinforcement learning with function approximation. In International conference on machine learning (pp. 30?37).
Baird and Moore, 1999
L. Baird, A.W. Moore
Gradient descent for general reinforcement learning
Advances in neural information processing systems, vol. 12 (NIPS), MIT Press (1999), pp. 968-974
Bakker, 2002
B. Bakker
Reinforcement learning with long short-term memory
T.G. Dietterich, S. Becker, Z. Ghahramani (Eds.), Advances in neural information processing systems, vol. 14, MIT Press, Cambridge, MA (2002), pp. 1475-1482
Bakker and Schmidhuber, 2004
B. Bakker, J. Schmidhuber
Hierarchical reinforcement learning based on subgoal discovery and subpolicy specialization
F. Groen, et al. (Eds.), Proc. 8th conference on intelligent autonomous systems IAS-8, IOS Press, Amsterdam, NL (2004), pp. 438-445
Bakker et al., 2003
Bakker, B., Zhumatiy, V., Gruener, G., & Schmidhuber, J. (2003). A robot that reinforcement-learns to identify and memorize important previous observations. In Proceedings of the 2003 IEEE/RSJ international conference on intelligent robots and systems (pp. 430?435).
Baldi, 1995
P. Baldi
Gradient descent learning algorithms overview: A general dynamical systems perspective
IEEE Transactions on Neural Networks, 6 (1) (1995), pp. 182-195
Baldi, 2012
P. Baldi
Autoencoders, unsupervised learning, and deep architectures
Journal of Machine Learning Research, 27 (2012), pp. 37-50
(Proc. 2011 ICML Workshop on Unsupervised and Transfer Learning)
Baldi et al., 1999
P. Baldi, S. Brunak, P. Frasconi, G. Pollastri, G. Soda
Exploiting the past and the future in protein secondary structure prediction
Bioinformatics, 15 (1999), pp. 937-946
Baldi and Chauvin, 1993
P. Baldi, Y. Chauvin
Neural networks for fingerprint recognition
Neural Computation, 5 (3) (1993), pp. 402-418
Baldi and Chauvin, 1996
P. Baldi, Y. Chauvin
Hybrid modeling, HMM/NN architectures, and protein applications
Neural Computation, 8 (7) (1996), pp. 1541-1565
Baldi and Hornik, 1989
P. Baldi, K. Hornik
Neural networks and principal component analysis: learning from examples without local minima
Neural Networks, 2 (1989), pp. 53-58
ArticleDownload PDF
Baldi and Hornik, 1995
P. Baldi, K. Hornik
Learning in linear networks: a survey
IEEE Transactions on Neural Networks, 6 (4) (1995), pp. 837-858
1995
Baldi and Pollastri, 2003
P. Baldi, G. Pollastri
The principled design of large-scale recursive neural network architectures?DAG-RNNs and the protein structure prediction problem
Journal of Machine Learning Research, 4 (2003), pp. 575-602
Baldi and Sadowski, 2014
P. Baldi, P. Sadowski
The dropout learning algorithm
Artificial Intelligence, 210C (2014), pp. 78-122
ArticleDownload PDF
Ballard, 1987
Ballard, D. H. (1987). Modular learning in neural networks. In Proc. AAAI (pp. 279?284).
Baluja, 1994
S. Baluja
Population-based incremental learning: A method for integrating genetic search based function optimization and competitive learning. Technical report CMU-CS-94-163
Carnegie Mellon University (1994)
Balzer, 1985
R. Balzer
A 15 year perspective on automatic programming
IEEE Transactions on Software Engineering, 11 (11) (1985), pp. 1257-1268
Barlow, 1989
H.B. Barlow
Unsupervised learning
Neural Computation, 1 (3) (1989), pp. 295-311
Barlow et al., 1989
H.B. Barlow, T.P. Kaushal, G.J. Mitchison
Finding minimum entropy codes
Neural Computation, 1 (3) (1989), pp. 412-423
Barrow, 1987
H.G. Barrow
Learning receptive fields
Proceedings of the IEEE 1st annual conference on neural networks, vol. IV, IEEE (1987), pp. 115-121
Barto and Mahadevan, 2003
A.G. Barto, S. Mahadevan
Recent advances in hierarchical reinforcement learning
Discrete Event Dynamic Systems, 13 (4) (2003), pp. 341-379
Barto et al., 2004
A.G. Barto, S. Singh, N. Chentanez
Intrinsically motivated learning of hierarchical collections of skills
Proceedings of international conference on developmental learning, MIT Press, Cambridge, MA (2004), pp. 112-119
Barto et al., 1983
A.G. Barto, R.S. Sutton, C.W. Anderson
Neuronlike adaptive elements that can solve difficult learning control problems
IEEE Transactions on Systems, Man and Cybernetics, SMC-13 (1983), pp. 834-846
Battiti, 1989
R. Battiti
Accelerated backpropagation learning: two optimization methods
Complex Systems, 3 (4) (1989), pp. 331-342
Battiti, 1992
T. Battiti
First- and second-order methods for learning: between steepest descent and Newton¡¯s method
Neural Computation, 4 (2) (1992), pp. 141-166
Baum and Haussler, 1989
E.B. Baum, D. Haussler
What size net gives valid generalization?
Neural Computation, 1 (1) (1989), pp. 151-160
Baum and Petrie, 1966
L.E. Baum, T. Petrie
Statistical inference for probabilistic functions of finite state Markov chains
The Annals of Mathematical Statistics (1966), pp. 1554-1563
Baxter and Bartlett, 2001
J. Baxter, P.L. Bartlett
Infinite-horizon policy-gradient estimation
Journal of Artificial Intelligence Research, 15 (1) (2001), pp. 319-350
Bayer and Osendorfer, 2014
Bayer, J., & Osendorfer, C. (2014). Variational inference of latent state sequences using recurrent networks. ArXiv Preprint arXiv:1406.1655.
Bayer et al., 2013
Bayer, J., Osendorfer, C., Chen, N., Urban, S., & van der Smagt, P. (2013). On fast dropout and its applicability to recurrent networks. ArXiv Preprint arXiv:1311.0701.
Bayer et al., 2009
Bayer, J., Wierstra, D., Togelius, J., & Schmidhuber, J. (2009). Evolving memory cell structures for sequence learning. In Proc. ICANN (2) (pp. 755?764).
Bayes, 1763
T. Bayes
An essay toward solving a problem in the doctrine of chances
Philosophical Transactions of the Royal Society of London, 53 (1763), pp. 370-418
Communicated by R. Price, in a letter to J. Canton
Becker, 1991
S. Becker
Unsupervised learning procedures for neural networks
International Journal of Neural Systems, 2 (1?2) (1991), pp. 17-33
Becker and Le Cun, 1989
S. Becker, Y. Le Cun
Improving the convergence of back-propagation learning with second order methods
D. Touretzky, G. Hinton, T. Sejnowski (Eds.), Proc. 1988 connectionist models summer school, 1988, Morgan Kaufmann, San Mateo (1989), pp. 29-37
Behnke, 1999
Behnke, S. (1999). Hebbian learning and competition in the neural abstraction pyramid. In Proceedings of the international joint conference on neural networks, vol. 2 (pp. 1356?1361).
Behnke, 2001
S. Behnke
Learning iterative image reconstruction in the neural abstraction pyramid
International Journal of Computational Intelligence and Applications, 1 (4) (2001), pp. 427-438
Behnke, 2002
Behnke, S. (2002). Learning face localization using hierarchical recurrent networks. In Proceedings of the 12th international conference on artificial neural networks (pp. 1319?1324).
Behnke, 2003a
Behnke, S. (2003a). Discovering hierarchical speech features using convolutional non-negative matrix factorization. In Proceedings of the international joint conference on neural networks, vol. 4 (pp. 2758?2763).
Behnke, 2003b
S. Behnke
Hierarchical neural networks for image interpretation, LNCS, Lecture notes in computer science, Vol. 2766, Springer (2003)
Behnke, 2005
S. Behnke
Face localization and tracking in the neural abstraction pyramid
Neural Computing and Applications, 14 (2) (2005), pp. 97-103
Behnke and Rojas, 1998
Behnke, S., & Rojas, R. (1998). Neural abstraction pyramid: a hierarchical image understanding architecture. In Proceedings of international joint conference on neural networks, vol. 2 (pp. 820?825).
Bell and Sejnowski, 1995
A.J. Bell, T.J. Sejnowski
An information-maximization approach to blind separation and blind deconvolution
Neural Computation, 7 (6) (1995), pp. 1129-1159
Bellman, 1957
R. Bellman
Dynamic programming
(1st ed), Princeton University Press, Princeton, NJ, USA (1957)
Belouchrani et al., 1997
A. Belouchrani, K. Abed-Meraim, J.-F. Cardoso, E. Moulines
A blind source separation technique using second-order statistics
IEEE Transactions on Signal Processing, 45 (2) (1997), pp. 434-444
Bengio, 1991
Y. Bengio
Artificial neural networks and their application to sequence recognition
(Ph.D. thesis)
McGill University, (Computer Science), Montreal, QC, Canada (1991)
Bengio, 2009
Y. Bengio
Learning deep architectures for AI, Foundations and trends in machine learning, Vol. 2(1), Now Publishers (2009)
Bengio et al., 2013
Y. Bengio, A. Courville, P. Vincent
Representation learning: a review and new perspectives
IEEE Transactions on Pattern Analysis and Machine Intelligence, 35 (8) (2013), pp. 1798-1828
Bengio et al., 2007
Y. Bengio, P. Lamblin, D. Popovici, H. Larochelle
Greedy layer-wise training of deep networks
J.D. Cowan, G. Tesauro, J. Alspector (Eds.), Advances in neural information processing systems, vol. 19 (NIPS), MIT Press (2007), pp. 153-160
Bengio et al., 1994
Y. Bengio, P. Simard, P. Frasconi
Learning long-term dependencies with gradient descent is difficult
IEEE Transactions on Neural Networks, 5 (2) (1994), pp. 157-166
Beringer et al., 2005
N. Beringer, A. Graves, F. Schiel, J. Schmidhuber
Classifying unprompted speech by retraining LSTM nets
W. Duch, J. Kacprzyk, E. Oja, S. Zadrozny (Eds.), Artificial neural networks: biological inspirations?ICANN 2005, LNCS, Vol. 3696, Springer-Verlag, Berlin, Heidelberg (2005), pp. 575-581
Bertsekas, 2001
D.P. Bertsekas
Dynamic programming and optimal control
Athena Scientific (2001)
Bertsekas and Tsitsiklis, 1996
D.P. Bertsekas, J.N. Tsitsiklis
Neuro-dynamic programming
Athena Scientific, Belmont, MA (1996)
Bichot et al., 2005
N.P. Bichot, A.F. Rossi, R. Desimone
Parallel and serial neural mechanisms for visual search in macaque area V4
Science, 308 (2005), pp. 529-534
Biegler-Konig and Barmann, 1993
F. Biegler-Konig, F. Barmann
A learning algorithm for multilayered neural networks based on linear least squares problems
Neural Networks, 6 (1) (1993), pp. 127-131
ArticleDownload PDF
Bishop, 1993
C.M. Bishop
Curvature-driven smoothing: A learning algorithm for feed-forward networks
IEEE Transactions on Neural Networks, 4 (5) (1993), pp. 882-884
Bishop, 2006
C.M. Bishop
Pattern recognition and machine learning
Springer (2006)
Blair and Pollack, 1997
A.D. Blair, J.B. Pollack
Analysis of dynamical recognizers
Neural Computation, 9 (5) (1997), pp. 1127-1142
Blondel and Tsitsiklis, 2000
V.D. Blondel, J.N. Tsitsiklis
A survey of computational complexity results in systems and control
Automatica, 36 (9) (2000), pp. 1249-1274
ArticleDownload PDF
Bluche et al., 2014
Bluche, T., Louradour, J., Knibbe, M., Moysset, B., Benzeghiba, F., & Kermorvant, C. (2014). The A2iA Arabic handwritten text recognition system at the OpenHaRT2013 evaluation. In International workshop on document analysis systems.
Blum and Rivest, 1992
A.L. Blum, R.L. Rivest
Training a 3-node neural network is NP-complete
Neural Networks, 5 (1) (1992), pp. 117-127
ArticleDownload PDF
Blumer et al., 1987
A. Blumer, A. Ehrenfeucht, D. Haussler, M.K. Warmuth
Occam¡¯s razor
Information Processing Letters, 24 (1987), pp. 377-380
ArticleDownload PDF
Bobrowski, 1978
L. Bobrowski
Learning processes in multilayer threshold nets
Biological Cybernetics, 31 (1978), pp. 1-6
Boden and Wiles, 2000
M. Boden, J. Wiles
Context-free and context-sensitive dynamics in recurrent neural networks
Connection Science, 12 (3?4) (2000), pp. 197-210
Bodenhausen and Waibel, 1991
U. Bodenhausen, A. Waibel
The Tempo 2 algorithm: adjusting time-delays by supervised learning
D.S. Lippman, J.E. Moody, D.S. Touretzky (Eds.), Advances in neural information processing systems, vol. 3, Morgan Kaufmann (1991), pp. 155-161
Bohte et al., 2002
S.M. Bohte, J.N. Kok, H. La Poutre
Error-backpropagation in temporally encoded networks of spiking neurons
Neurocomputing, 48 (1) (2002), pp. 17-37
ArticleDownload PDF
Boltzmann, 1909
L. Boltzmann
F. Hasenohrl (Ed.), Wissenschaftliche Abhandlungen, Barth, Leipzig (1909)
(collection of Boltzmann¡¯s articles in scientific journals)
Bottou, 1991
L. Bottou
Une approche theorique de l¡¯apprentissage connexioniste; applications a la reconnaissance de la parole
(Ph.D. thesis)
Universite de Paris XI (1991)
Bourlard and Morgan, 1994
H. Bourlard, N. Morgan
Connnectionist speech recognition: a hybrid approach
Kluwer Academic Publishers (1994)
Boutilier and Poole, 1996
Boutilier, C., & Poole, D. (1996). Computing optimal policies for partially observable Markov decision processes using compact representations. In Proceedings of the AAAI.
Bradtke et al., 1996
S.J. Bradtke, A.G. Barto, L.P. Kaelbling
Linear least-squares algorithms for temporal difference learning
Machine Learning (1996), pp. 22-33
Brafman and Tennenholtz, 2002
R.I. Brafman, M. Tennenholtz
R-MAX?a general polynomial time algorithm for near-optimal reinforcement learning
Journal of Machine Learning Research, 3 (2002), pp. 213-231
Brea et al., 2013
J. Brea, W. Senn, J.-P. Pfister
Matching recall and storage in sequence learning with spiking neural networks
The Journal of Neuroscience, 33 (23) (2013), pp. 9565-9575
Breiman, 1996
L. Breiman
Bagging predictors
Machine Learning, 24 (1996), pp. 123-140
Brette et al., 2007
R. Brette, M. Rudolph, T. Carnevale, M. Hines, D. Beeman, J.M. Bower, et al.
Simulation of networks of spiking neurons: a review of tools and strategies
Journal of Computational Neuroscience, 23 (3) (2007), pp. 349-398
Breuel et al., 2013
T.M. Breuel, A. Ul-Hasan, M.A. Al-Azawi, F. Shafait
High-performance OCR for printed English and Fraktur using LSTM networks
12th International conference on document analysis and recognition, IEEE (2013), pp. 683-687
Bromley et al., 1993
J. Bromley, J.W. Bentz, L. Bottou, I. Guyon, Y. LeCun, C. Moore, et al.
Signature verification using a Siamese time delay neural network
International Journal of Pattern Recognition and Artificial Intelligence, 7 (4) (1993), pp. 669-688
Broyden et al., 1965
C.G. Broyden, et al.
A class of methods for solving nonlinear simultaneous equations
Mathematics of Computation, 19 (92) (1965), pp. 577-593
Brueckner and Schulter, 2014
Brueckner, R., & Schulter, B. (2014). Social signal classification using deep BLSTM recurrent neural networks. In Proceedings 39th IEEE international conference on acoustics, speech, and signal processing (pp. 4856?4860).
Brunel, 2000
N. Brunel
Dynamics of sparsely connected networks of excitatory and inhibitory spiking neurons
Journal of Computational Neuroscience, 8 (3) (2000), pp. 183-208
Bryson, 1961
Bryson, A. E. (1961). A gradient method for optimizing multi-stage allocation processes. In Proc. Harvard Univ. symposium on digital computers and their applications.
Bryson and Denham, 1961
A.E. Bryson Jr., W.F. Denham
A steepest-ascent method for solving optimum programming problems. Technical report BR-1303
Raytheon Company, Missle and Space Division (1961)
Bryson and Ho, 1969
A. Bryson, Y. Ho
Applied optimal control: optimization, estimation, and control
Blaisdell Pub. Co (1969)
Buhler, 2001
J. Buhler
Efficient large-scale sequence comparison by locality-sensitive hashing
Bioinformatics, 17 (5) (2001), pp. 419-428
Buntine and Weigend, 1991
W.L. Buntine, A.S. Weigend
Bayesian back-propagation
Complex Systems, 5 (1991), pp. 603-643
Burgess, 1994
N. Burgess
A constructive algorithm that converges for real-valued input patterns
International Journal of Neural Systems, 5 (1) (1994), pp. 59-66
Cardoso, 1994
Cardoso, J.-F. (1994). On the performance of orthogonal source separation algorithms. In Proc. EUSIPCO (pp. 776?779).
Carreira-Perpinan, 2001
M.A. Carreira-Perpinan
Continuous latent variable models for dimensionality reduction and sequential data reconstruction
(Ph.D. thesis)
University of Sheffield, UK (2001)
Carter et al., 1990
M.J. Carter, F.J. Rudolph, A.J. Nucci
Operational fault tolerance of CMAC networks
D.S. Touretzky (Ed.), Advances in neural information processing systems (NIPS), vol. 2, Morgan Kaufmann, San Mateo, CA (1990), pp. 340-347
Caruana, 1997
R. Caruana
Multitask learning
Machine Learning, 28 (1) (1997), pp. 41-75
Casey, 1996
M.P. Casey
The dynamics of discrete-time computation, with application to recurrent neural networks and finite state machine extraction
Neural Computation, 8 (6) (1996), pp. 1135-1178
Cauwenberghs, 1993
G. Cauwenberghs
A fast stochastic error-descent algorithm for supervised learning and optimization
D.S. Lippman, J.E. Moody, D.S. Touretzky (Eds.), Advances in neural information processing systems, vol. 5, Morgan Kaufmann (1993), p. 244
Chaitin, 1966
G.J. Chaitin
On the length of programs for computing finite binary sequences
Journal of the ACM, 13 (1966), pp. 547-569
Chalup and Blair, 2003
S.K. Chalup, A.D. Blair
Incremental training of first order recurrent neural networks to predict a context-sensitive language
Neural Networks, 16 (7) (2003), pp. 955-972
ArticleDownload PDF
Chellapilla et al., 2006
Chellapilla, K., Puri, S., & Simard, P. (2006). High performance convolutional neural networks for document processing. In International workshop on Frontiers in handwriting recognition.
Chen and Salman, 2011
K. Chen, A. Salman
Learning speaker-specific characteristics with a deep neural architecture
IEEE Transactions on Neural Networks, 22 (11) (2011), pp. 1744-1756
Cho, 2014
K. Cho
Foundations and advances in deep learning
(Ph.D. thesis)
Aalto University School of Science (2014)
Cho et al., 2012
K. Cho, A. Ilin, T. Raiko
Tikhonov-type regularization for restricted Boltzmann machines
Intl. conf. on artificial neural networks 2012, Springer (2012), pp. 81-88
Cho et al., 2013
K. Cho, T. Raiko, A. Ilin
Enhanced gradient for training restricted Boltzmann machines
Neural Computation, 25 (3) (2013), pp. 805-831
Church, 1936
A. Church
An unsolvable problem of elementary number theory
The American Journal of Mathematics, 58 (1936), pp. 345-363
Ciresan, Giusti, et al., 2012
D.C. Ciresan, A. Giusti, L.M. Gambardella, J. Schmidhuber
Deep neural networks segment neuronal membranes in electron microscopy images
Advances in neural information processing systems (NIPS) (2012), pp. 2852-2860
Ciresan et al., 2013
Ciresan, D. C., Giusti, A., Gambardella, L. M., & Schmidhuber, J. (2013). Mitosis detection in breast cancer histology images with deep neural networks. In Proc. MICCAI, vol. 2 (pp. 411?418).
Ciresan et al., 2010
D.C. Ciresan, U. Meier, L.M. Gambardella, J. Schmidhuber
Deep big simple neural nets for handwritten digit recogntion
Neural Computation, 22 (12) (2010), pp. 3207-3220
Ciresan, Meier, Masci, Gambardella, et al., 2011
Ciresan, D. C., Meier, U., Masci, J., Gambardella, L. M., & Schmidhuber, J. (2011). Flexible, high performance convolutional neural networks for image classification. In Intl. joint conference on artificial intelligence (pp. 1237?1242).
Ciresan, Meier, Masci, Schmidhuber, 2011
Ciresan, D. C., Meier, U., Masci, J., & Schmidhuber, J. (2011). A committee of neural networks for traffic sign classification. In International joint conference on neural networks (pp. 1918?1921).
Ciresan, Meier, et al., 2012
D.C. Ciresan, U. Meier, J. Masci, J. Schmidhuber
Multi-column deep neural network for traffic sign classification
Neural Networks, 32 (2012), pp. 333-338
ArticleDownload PDF
Ciresan et al., 2012a
Ciresan, D. C., Meier, U., & Schmidhuber, J. (2012a). Multi-column deep neural networks for image classification. In IEEE Conference on computer vision and pattern recognition. Long preprint arXiv:1202.2745v1  [cs.CV].
Ciresan et al., 2012b
Ciresan, D. C., Meier, U., & Schmidhuber, J. (2012b). Transfer learning for Latin and Chinese characters with deep neural networks. In International joint conference on neural networks (pp. 1301?1306).
Ciresan and Schmidhuber, 2013
D.C. Ciresan, J. Schmidhuber
Multi-column deep neural networks for offline handwritten Chinese character classification. Technical report
IDSIA (2013)
arXiv:1309.0261
Cliff et al., 1993
D.T. Cliff, P. Husbands, I. Harvey
Evolving recurrent dynamical networks for robot control
Artificial neural nets and genetic algorithms, Springer (1993), pp. 428-435
Clune et al., 2013
J. Clune, J.-B. Mouret, H. Lipson
The evolutionary origins of modularity
Proceedings of the Royal Society B: Biological Sciences, 280 (1755) (2013), p. 20122863
Clune et al., 2011
J. Clune, K.O. Stanley, R.T. Pennock, C. Ofria
On the performance of indirect encoding across the continuum of regularity
IEEE Transactions on Evolutionary Computation, 15 (3) (2011), pp. 346-367
Coates et al., 2013
Coates, A., Huval, B., Wang, T., Wu, D. J., Ng, A. Y., & Catanzaro, B. (2013). Deep learning with COTS HPC systems. In Proc. international conference on machine learning.
Cochocki and Unbehauen, 1993
A. Cochocki, R. Unbehauen
Neural networks for optimization and signal processing
John Wiley & Sons, Inc (1993)
Collobert and Weston, 2008
R. Collobert, J. Weston
A unified architecture for natural language processing: deep neural networks with multitask learning
Proceedings of the 25th international conference on machine learning, ACM (2008), pp. 160-167
Comon, 1994
P. Comon
Independent component analysis?a new concept?
Signal Processing, 36 (3) (1994), pp. 287-314
ArticleDownload PDF
Connor et al., 2007
C.E. Connor, S.L. Brincat, A. Pasupathy
Transformation of shape information in the ventral pathway
Current Opinion in Neurobiology, 17 (2) (2007), pp. 140-147
ArticleDownload PDF
Connor et al., 1994
J. Connor, D.R. Martin, L.E. Atlas
Recurrent neural networks and robust time series prediction
IEEE Transactions on Neural Networks, 5 (2) (1994), pp. 240-254
Cook, 1971
S.A. Cook
The complexity of theorem-proving procedures
Proceedings of the 3rd annual ACM symposium on the theory of computing, ACM, New York (1971), pp. 151-158
Cramer, 1985
N.L. Cramer
A representation for the adaptive generation of simple sequential programs
J. Grefenstette (Ed.), Proceedings of an international conference on genetic algorithms and their applications, Carnegie-Mellon University, Lawrence Erlbaum Associates, Hillsdale, NJ (1985)
Craven and Wahba, 1979
P. Craven, G. Wahba
Smoothing noisy data with spline functions: estimating the correct degree of smoothing by the method of generalized cross-validation
Numerische Mathematik, 31 (1979), pp. 377-403
Cuccu et al., 2011
G. Cuccu, M. Luciw, J. Schmidhuber, F. Gomez
Intrinsically motivated evolutionary search for vision-based reinforcement learning
Proceedings of the 2011 IEEE conference on development and learning and epigenetic robotics IEEE-ICDL-EPIROB, vol. 2, IEEE (2011), pp. 1-7
Dahl et al., 2013
G.E. Dahl, T.N. Sainath, G.E. Hinton
Improving deep neural networks for LVCSR using rectified linear units and dropout
IEEE International conference on acoustics, speech and signal processing, IEEE (2013), pp. 8609-8613
Dahl et al., 2012
G. Dahl, D. Yu, L. Deng, A. Acero
Context-dependent pre-trained deep neural networks for large-vocabulary speech recognition
IEEE Transactions on Audio, Speech and Language Processing, 20 (1) (2012), pp. 30-42
D¡¯Ambrosio and Stanley, 2007
D¡¯Ambrosio, D. B., & Stanley, K. O. (2007). A novel generative encoding for exploiting neural network sensor and output geometry. In Proceedings of the conference on genetic and evolutionary computation (pp. 974?981).
Datar et al., 2004
M. Datar, N. Immorlica, P. Indyk, V.S. Mirrokni
Locality-sensitive hashing scheme based on -stable distributions
Proceedings of the 20th annual symposium on computational geometry, ACM (2004), pp. 253-262
Dayan and Hinton, 1993
P. Dayan, G. Hinton
Feudal reinforcement learning
D.S. Lippman, J.E. Moody, D.S. Touretzky (Eds.), Advances in neural information processing systems (NIPS), vol. 5, Morgan Kaufmann (1993), pp. 271-278
Dayan and Hinton, 1996
P. Dayan, G.E. Hinton
Varieties of Helmholtz machine
Neural Networks, 9 (8) (1996), pp. 1385-1403
ArticleDownload PDF
Dayan et al., 1995
P. Dayan, G.E. Hinton, R.M. Neal, R.S. Zemel
The Helmholtz machine
Neural Computation, 7 (1995), pp. 889-904
Dayan and Zemel, 1995
P. Dayan, R. Zemel
Competition and multiple cause models
Neural Computation, 7 (1995), pp. 565-579
Deco and Parra, 1997
G. Deco, L. Parra
Non-linear feature extraction by redundancy reduction in an unsupervised stochastic neural network
Neural Networks, 10 (4) (1997), pp. 683-691
ArticleDownload PDF
Deco and Rolls, 2005
G. Deco, E.T. Rolls
Neurodynamics of biased competition and cooperation for attention: a model with spiking neurons
Journal of Neurophysiology, 94 (1) (2005), pp. 295-313
De Freitas, 2003
J.F.G. De Freitas
Bayesian methods for neural networks
(Ph.D. thesis)
University of Cambridge (2003)
DeJong and Mooney, 1986
G. DeJong, R. Mooney
Explanation-based learning: an alternative view
Machine Learning, 1 (2) (1986), pp. 145-176
DeMers and Cottrell, 1993
D. DeMers, G. Cottrell
Non-linear dimensionality reduction
S.J. Hanson, J.D. Cowan, C.L. Giles (Eds.), Advances in neural information processing systems (NIPS), vol. 5, Morgan Kaufmann (1993), pp. 580-587
Dempster et al., 1977
A.P. Dempster, N.M. Laird, D.B. Rubin
Maximum likelihood from incomplete data via the EM algorithm
Journal of the Royal Statistical Society B, 39 (1977)
Deng and Yu, 2014
L. Deng, D. Yu
Deep learning: methods and applications
NOW Publishers (2014)
Desimone et al., 1984
R. Desimone, T.D. Albright, C.G. Gross, C. Bruce
Stimulus-selective properties of inferior temporal neurons in the macaque
The Journal of Neuroscience, 4 (8) (1984), pp. 2051-2062
de Souto et al., 1999
M.C. de Souto, M.C.P.D. Souto, W.R.D. Oliveira
The loading problem for pyramidal neural networks
Electronic Journal on Mathematics of Computation (1999)
De Valois et al., 1982
R.L. De Valois, D.G. Albrecht, L.G. Thorell
Spatial frequency selectivity of cells in macaque visual cortex
Vision Research, 22 (5) (1982), pp. 545-559
ArticleDownload PDF
Deville and Lau, 1994
Y. Deville, K.K. Lau
Logic program synthesis
Journal of Logic Programming, 19 (20) (1994), pp. 321-350
ArticleDownload PDF
de Vries and Principe, 1991
B. de Vries, J.C. Principe
A theory for neural networks with time delays
R.P. Lippmann, J.E. Moody, D.S. Touretzky (Eds.), Advances in neural information processing systems (NIPS), vol. 3, Morgan Kaufmann (1991), pp. 162-168
DiCarlo et al., 2012
J.J. DiCarlo, D. Zoccolan, N.C. Rust
How does the brain solve visual object recognition?
Neuron, 73 (3) (2012), pp. 415-434
ArticleDownload PDF
Dickmanns et al., 1994
Dickmanns, E. D., Behringer, R., Dickmanns, D., Hildebrandt, T., Maurer, M., & Thomanek, F., et al. (1994). The seeing passenger car ¡¯VaMoRs-P¡¯. In Proc. int. symp. on intelligent vehicles (pp. 68?73).
Dickmanns et al., 1987
D. Dickmanns, J. Schmidhuber, A. Winklhofer
Der genetische algorithmus: eine implementierung in prolog. Technical report
Inst. of Informatics, Tech. Univ. Munich (1987)
http://www.idsia.ch/~juergen/geneticprogramming.html
Dietterich, 2000a
T.G. Dietterich
Ensemble methods in machine learning
Multiple classifier systems, Springer (2000), pp. 1-15
Dietterich, 2000b
T.G. Dietterich
Hierarchical reinforcement learning with the MAXQ value function decomposition
Journal of Artificial Intelligence Research (JAIR), 13 (2000), pp. 227-303
Di Lena et al., 2012
P. Di Lena, K. Nagata, P. Baldi
Deep architectures for protein contact map prediction
Bioinformatics, 28 (2012), pp. 2449-2457
Director and Rohrer, 1969
S.W. Director, R.A. Rohrer
Automated network design?the frequency-domain case
IEEE Transactions on Circuit Theory, CT-16 (1969), pp. 330-337
Dittenbach et al., 2000
M. Dittenbach, D. Merkl, A. Rauber
The growing hierarchical self-organizing map
IEEE-INNS-ENNS International joint conference on neural networks, vol. 6, IEEE Computer Society (2000), p. 6015
Donahue et al., 2013
Donahue, J., Jia, Y., Vinyals, O., Hoffman, J., Zhang, N., & Tzeng, E., et al. (2013). DeCAF: a deep convolutional activation feature for generic visual recognition. ArXiv Preprint arXiv:1310.1531.
Dorffner, 1996
Dorffner, G. (1996). Neural networks for time series processing. In Neural network world.
Doya et al., 2002
K. Doya, K. Samejima, K. Ichi Katagiri, M. Kawato
Multiple model-based reinforcement learning
Neural Computation, 14 (6) (2002), pp. 1347-1369
Dreyfus, 1962
S.E. Dreyfus
The numerical solution of variational problems
Journal of Mathematical Analysis and Applications, 5 (1) (1962), pp. 30-45
ArticleDownload PDF
Dreyfus, 1973
S.E. Dreyfus
The computational solution of optimal control problems with time lag
IEEE Transactions on Automatic Control, 18 (4) (1973), pp. 383-385
Duchi et al., 2011
J. Duchi, E. Hazan, Y. Singer
Adaptive subgradient methods for online learning and stochastic optimization
The Journal of Machine Learning, 12 (2011), pp. 2121-2159
Egorova et al., 2004
Egorova, A., Gloye, A., Goktekin, C., Liers, A., Luft, M., & Rojas, R., et al. (2004). FU-fighters small size 2004, team description. In RoboCup 2004 symposium: papers and team description papers. CD edition.
Elfwing et al., 2010
S. Elfwing, M. Otsuka, E. Uchibe, K. Doya
Free-energy based reinforcement learning for vision-based navigation with high-dimensional sensory inputs
Neural information processing. theory and algorithms (ICONIP), vol. 1, Springer (2010), pp. 215-222
Eliasmith, 2013
C. Eliasmith
How to build a brain: a neural architecture for biological cognition
Oxford University Press, New York, NY (2013)
Eliasmith et al., 2012
C. Eliasmith, T.C. Stewart, X. Choo, T. Bekolay, T. DeWolf, Y. Tang, et al.
A large-scale model of the functioning brain
Science, 338 (6111) (2012), pp. 1202-1205
Elman, 1990
J.L. Elman
Finding structure in time
Cognitive Science, 14 (2) (1990), pp. 179-211
ArticleDownload PDF
Erhan et al., 2010
D. Erhan, Y. Bengio, A. Courville, P.-A. Manzagol, P. Vincent, S. Bengio
Why does unsupervised pre-training help deep learning?
Journal of Machine Learning Research, 11 (2010), pp. 625-660
Escalante-B and Wiskott, 2013
A.N. Escalante-B, L. Wiskott
How to solve classification and regression problems on high-dimensional data with a supervised extension of slow feature analysis
Journal of Machine Learning Research, 14 (2013), pp. 3683-3719
Eubank, 1988
R.L. Eubank
Spline smoothing and nonparametric regression
S. Farlow (Ed.), Self-organizing methods in modeling, Marcel Dekker, New York (1988)
Euler, 1744
Euler, L. (1744). Methodus inveniendi.
Eyben et al., 2013
Eyben, F., Weninger, F., Squartini, S., & Schuller, B. (2013). Real-life voice activity detection with LSTM recurrent neural networks and an application to Hollywood movies. In Proc. 38th IEEE international conference on acoustics, speech, and signal processing (pp. 483?487).
Faggin, 1992
Faggin, F. (1992). Neural network hardware. In International joint conference on neural networks, vol. 1 (p. 153).
Fahlman, 1988
S.E. Fahlman
An empirical study of learning speed in back-propagation networks. Technical report CMU-CS-88-162
Carnegie-Mellon Univ. (1988)
Fahlman, 1991
S.E. Fahlman
The recurrent cascade-correlation learning algorithm
R.P. Lippmann, J.E. Moody, D.S. Touretzky (Eds.), Advances in neural information processing systems (NIPS), vol. 3, Morgan Kaufmann (1991), pp. 190-196
Falconbridge et al., 2006
M.S. Falconbridge, R.L. Stamps, D.R. Badcock
A simple Hebbian/anti-Hebbian network learns the sparse, independent components of natural images
Neural Computation, 18 (2) (2006), pp. 415-429
Fan et al., 2014
Fan, Y., Qian, Y., Xie, F., & Soong, F. K. (2014). TTS synthesis with bidirectional LSTM based recurrent neural networks. In Proc. Interspeech.
Farabet et al., 2013
C. Farabet, C. Couprie, L. Najman, Y. LeCun
Learning hierarchical features for scene labeling
IEEE Transactions on Pattern Analysis and Machine Intelligence, 35 (8) (2013), pp. 1915-1929
Farlow, 1984
S.J. Farlow
Self-organizing methods in modeling: GMDH type algorithms, vol. 54
CRC Press (1984)
Feldkamp et al., 1998
L.A. Feldkamp, D.V. Prokhorov, C.F. Eagen, F. Yuan
Enhanced multi-stream Kalman filter training for recurrent networks
Nonlinear modeling, Springer (1998), pp. 29-53
Feldkamp et al., 2003
L.A. Feldkamp, D.V. Prokhorov, T.M. Feldkamp
Simple and conditioned adaptive behavior from Kalman filter trained recurrent networks
Neural Networks, 16 (5) (2003), pp. 683-689
ArticleDownload PDF
Feldkamp and Puskorius, 1998
L.A. Feldkamp, G.V. Puskorius
A signal processing framework based on dynamic neural networks with application to problems in adaptation, filtering, and classification
Proceedings of the IEEE, 86 (11) (1998), pp. 2259-2277
Felleman and Van Essen, 1991
D.J. Felleman, D.C. Van Essen
Distributed hierarchical processing in the primate cerebral cortex
Cerebral Cortex, 1 (1) (1991), pp. 1-47
Fernandez et al., 2007a
Fernandez, S., Graves, A., & Schmidhuber, J. (2007a). An application of recurrent neural networks to discriminative keyword spotting. In Proc. ICANN (2) (pp. 220?229).
Fernandez et al., 2007b
Fernandez, S., Graves, A., & Schmidhuber, J. (2007b). Sequence labelling in structured domains with hierarchical recurrent neural networks. In Proceedings of the 20th international joint conference on artificial intelligence.
Fernandez et al., 2014
Fernandez, R., Rendel, A., Ramabhadran, B., & Hoory, R. (2014). Prosody contour prediction with long short-term memory, bi-directional, deep recurrent neural networks. In Proc. Interspeech.
Field, 1987
D.J. Field
Relations between the statistics of natural images and the response properties of cortical cells
Journal of the Optical Society of America, 4 (1987), pp. 2379-2394
Field, 1994
D.J. Field
What is the goal of sensory coding?
Neural Computation, 6 (1994), pp. 559-601
Fieres et al., 2008
Fieres, J., Schemmel, J., & Meier, K. (2008). Realizing biological spiking network models in a configurable wafer-scale hardware system. In IEEE International joint conference on neural networks (pp. 969?976).
Fine et al., 1998
S. Fine, Y. Singer, N. Tishby
The hierarchical hidden Markov model: analysis and applications
Machine Learning, 32 (1) (1998), pp. 41-62
Fischer and Igel, 2014
A. Fischer, C. Igel
Training restricted Boltzmann machines: an introduction
Pattern Recognition, 47 (2014), pp. 25-39
ArticleDownload PDF
FitzHugh, 1961
R. FitzHugh
Impulses and physiological states in theoretical models of nerve membrane
Biophysical Journal, 1 (6) (1961), pp. 445-466
ArticleDownload PDF
Fletcher and Powell, 1963
R. Fletcher, M.J. Powell
A rapidly convergent descent method for minimization
The Computer Journal, 6 (2) (1963), pp. 163-168
Floreano and Mattiussi, 2001
D. Floreano, C. Mattiussi
Evolution of spiking neural controllers for autonomous vision-based robots
Evolutionary robotics. From intelligent robotics to artificial life, Springer (2001), pp. 38-61
Fogel et al., 1990
D.B. Fogel, L.J. Fogel, V. Porto
Evolving neural networks
Biological Cybernetics, 63 (6) (1990), pp. 487-493
Fogel et al., 1966
L. Fogel, A. Owens, M. Walsh
Artificial intelligence through simulated evolution
Wiley, New York (1966)
Foldiak, 1990
P. Foldiak
Forming sparse representations by local anti-Hebbian learning
Biological Cybernetics, 64 (1990), pp. 165-170
Foldiak and Young, 1995
P. Foldiak, M.P. Young
Sparse coding in the primate cortex
M.A. Arbib (Ed.), The handbook of brain theory and neural networks, The MIT Press (1995), pp. 895-898
Forster et al., 2007
Forster, A., Graves, A., & Schmidhuber, J. (2007). RNN-based learning of compact maps for efficient robot localization. In 15th European symposium on artificial neural networks (pp. 537?542).
Franzius et al., 2007
M. Franzius, H. Sprekeler, L. Wiskott
Slowness and sparseness lead to place, head-direction, and spatial-view cells
PLoS Computational Biology, 3 (8) (2007), p. 166
Friedman et al., 2001
Friedman, J., Hastie, T., & Tibshirani, R. (2001). Springer series in statistics: Vol. 1. The elements of statistical learning. New York.
Frinken et al., 2012
V. Frinken, F. Zamora-Martinez, S. Espana-Boquera, M.J. Castro-Bleda, A. Fischer, H. Bunke
Long-short term memory neural networks language modeling for handwriting recognition
2012 21st International conference on pattern recognition, IEEE (2012), pp. 701-704
Fritzke, 1994
B. Fritzke
A growing neural gas network learns topologies
G. Tesauro, D.S. Touretzky, T.K. Leen (Eds.), NIPS, MIT Press (1994), pp. 625-632
Fu, 1977
K.S. Fu
Syntactic pattern recognition and applications
Springer, Berlin (1977)
Fukada et al., 1999
T. Fukada, M. Schuster, Y. Sagisaka
Phoneme boundary estimation using bidirectional recurrent neural networks and its applications
Systems and Computers in Japan, 30 (4) (1999), pp. 20-30
Fukushima, 1979
K. Fukushima
Neural network model for a mechanism of pattern recognition unaffected by shift in position?Neocognitron
Transactions of the IECE, J62-A (10) (1979), pp. 658-665
Fukushima, 1980
K. Fukushima
Neocognitron: A self-organizing neural network for a mechanism of pattern recognition unaffected by shift in position
Biological Cybernetics, 36 (4) (1980), pp. 193-202
Fukushima, 2011
K. Fukushima
Increasing robustness against background noise: visual pattern recognition by a neocognitron
Neural Networks, 24 (7) (2011), pp. 767-778
ArticleDownload PDF
Fukushima, 2013a
K. Fukushima
Artificial vision by multi-layered neural networks: neocognitron and its advances
Neural Networks, 37 (2013), pp. 103-119
ArticleDownload PDF
Fukushima, 2013b
K. Fukushima
Training multi-layered neural network neocognitron
Neural Networks, 40 (2013), pp. 18-31
ArticleDownload PDF
Gabor, 1946
D. Gabor
Theory of communication. Part 1: the analysis of information
Electrical Engineers-Part III: Journal of the Institution of Radio and Communication Engineering, 93 (26) (1946), pp. 429-441
Gallant, 1988
S.I. Gallant
Connectionist expert systems
Communications of the ACM, 31 (2) (1988), pp. 152-169
Gauss, 1809
Gauss, C. F. (1809). Theoria motus corporum coelestium in sectionibus conicis solem ambientium.
Gauss, 1821
Gauss, C. F. (1821). Theoria combinationis observationum erroribus minimis obnoxiae (Theory of the combination of observations least subject to error).
Ge et al., 2010
S. Ge, C.C. Hang, T.H. Lee, T. Zhang
Stable adaptive neural network control
Springer (2010)
Geiger et al., 2014
Geiger, J. T., Zhang, Z., Weninger, F., Schuller, B., & Rigoll, G. (2014). Robust speech recognition using long short-term memory recurrent neural networks for hybrid acoustic modelling. In Proc. interspeech.
Geman et al., 1992
S. Geman, E. Bienenstock, R. Doursat
Neural networks and the bias/variance dilemma
Neural Computation, 4 (1992), pp. 1-58
Gers and Schmidhuber, 2000
F.A. Gers, J. Schmidhuber
Recurrent nets that time and count
Proceedings of the IEEE-INNS-ENNS international joint conference on neural networks, 2000, vol. 3, IEEE (2000), pp. 189-194
Gers and Schmidhuber, 2001
F.A. Gers, J. Schmidhuber
LSTM recurrent networks learn simple context free and context sensitive languages
IEEE Transactions on Neural Networks, 12 (6) (2001), pp. 1333-1340
Gers et al., 2000
F.A. Gers, J. Schmidhuber, F. Cummins
Learning to forget: continual prediction with LSTM
Neural Computation, 12 (10) (2000), pp. 2451-2471
Gers et al., 2002
F.A. Gers, N. Schraudolph, J. Schmidhuber
Learning precise timing with LSTM recurrent networks
Journal of Machine Learning Research, 3 (2002), pp. 115-143
Gerstner and Kistler, 2002
W. Gerstner, W.K. Kistler
Spiking neuron models
Cambridge University Press (2002)
Gerstner and van Hemmen, 1992
W. Gerstner, J.L. van Hemmen
Associative memory in a network of spiking neurons
Network: Computation in Neural Systems, 3 (2) (1992), pp. 139-164
Ghavamzadeh and Mahadevan, 2003
Ghavamzadeh, M., & Mahadevan, S. (2003). Hierarchical policy gradient algorithms. In Proceedings of the twentieth conference on machine learning (pp. 226?233).
Gherrity, 1989
Gherrity, M. (1989). A learning algorithm for analog fully recurrent neural networks. In IEEE/INNS International joint conference on neural networks, San Diego, vol. 1 (pp. 643?644).
Girshick et al., 2013
R. Girshick, J. Donahue, T. Darrell, J. Malik
Rich feature hierarchies for accurate object detection and semantic segmentation. Technical report
UC Berkeley and ICSI (2013)
arxiv.org/abs/1311.2524
Gisslen et al., 2011
L. Gisslen, M. Luciw, V. Graziano, J. Schmidhuber
Sequential constant size compressor for reinforcement learning
Proc. fourth conference on artificial general intelligence, Springer (2011), pp. 31-40
Giusti et al., 2013
Giusti, A., Ciresan, D. C., Masci, J., Gambardella, L. M., & Schmidhuber, J. (2013). Fast image scanning with deep max-pooling convolutional neural networks. In Proc. ICIP.
Glackin et al., 2005
B. Glackin, T.M. McGinnity, L.P. Maguire, Q. Wu, A. Belatreche
A novel approach for the implementation of large scale spiking neural networks on FPGA hardware
Computational intelligence and bioinspired systems, Springer (2005), pp. 552-563
Glasmachers et al., 2010
T. Glasmachers, T. Schaul, Y. Sun, D. Wierstra, J. Schmidhuber
Exponential natural evolution strategies
Proceedings of the genetic and evolutionary computation conference, ACM (2010), pp. 393-400
Glorot et al., 2011
Glorot, X., Bordes, A., & Bengio, Y. (2011). Deep sparse rectifier networks. In AISTATS, vol. 15 (pp. 315?323).
Gloye et al., 2005
A. Gloye, F. Wiesel, O. Tenchio, M. Simon
Reinforcing the driving quality of soccer playing robots by anticipation
IT?Information Technology, 47 (5) (2005)
Godel, 1931
K. Godel
Uber formal unentscheidbare Satze der Principia Mathematica und verwandter Systeme I
Monatshefte fur Mathematik und Physik, 38 (1931), pp. 173-198
Goldberg, 1989
D.E. Goldberg
Genetic algorithms in search, optimization and machine learning
Addison-Wesley, Reading, MA (1989)
Goldfarb, 1970
D. Goldfarb
A family of variable-metric methods derived by variational means
Mathematics of Computation, 24 (109) (1970), pp. 23-26
Golub et al., 1979
G. Golub, H. Heath, G. Wahba
Generalized cross-validation as a method for choosing a good ridge parameter
Technometrics, 21 (1979), pp. 215-224
Gomez, 2003
F.J. Gomez
Robust nonlinear control through neuroevolution
(Ph.D. thesis)
Department of Computer Sciences, University of Texas at Austin (2003)
Gomez and Miikkulainen, 2003
Gomez, F. J., & Miikkulainen, R. (2003). Active guidance for a finless rocket using neuroevolution. In Proc. GECCO 2003.
Gomez and Schmidhuber, 2005
F.J. Gomez, J. Schmidhuber
Co-evolving recurrent neurons learn deep memory POMDPs
Proc. of the 2005 conference on genetic and evolutionary computation, ACM Press, New York, NY, USA (2005)
Gomez et al., 2008
F.J. Gomez, J. Schmidhuber, R. Miikkulainen
Accelerated neural evolution through cooperatively coevolved synapses
Journal of Machine Learning Research, 9 (May) (2008), pp. 937-965
Gomi and Kawato, 1993
H. Gomi, M. Kawato
Neural network control for a closed-loop system using feedback-error-learning
Neural Networks, 6 (7) (1993), pp. 933-946
ArticleDownload PDF
Gonzalez-Dominguez et al., 2014
Gonzalez-Dominguez, J., Lopez-Moreno, I., Sak, H., Gonzalez-Rodriguez, J., & Moreno, P. J. (2014). Automatic language identification using long short-term memory recurrent neural networks. In Proc. Interspeech.
Goodfellow, Bulatov, et al., 2014
Goodfellow, I. J., Bulatov, Y., Ibarz, J., Arnoud, S., & Shet, V. (2014). Multi-digit number recognition from street view imagery using deep convolutional neural networks. ArXiv Preprint arXiv:1312.6082v4.
Goodfellow et al., 2011
Goodfellow, I. J., Courville, A., & Bengio, Y. (2011). Spike-and-slab sparse coding for unsupervised feature discovery. In NIPS Workshop on challenges in learning hierarchical models.
Goodfellow et al., 2012
Goodfellow, I. J., Courville, A. C., & Bengio, Y. (2012). Large-scale feature learning with spike-and-slab sparse coding. In Proceedings of the 29th international conference on machine learning.
Goodfellow, Mirza, et al., 2014
I. Goodfellow, M. Mirza, X. Da, A. Courville, Y. Bengio
An empirical investigation of catastrophic forgetting in gradient-based neural networks. TR
(2014)
arXiv:1312.6211v2
Goodfellow et al., 2013
Goodfellow, I. J., Warde-Farley, D., Mirza, M., Courville, A., & Bengio, Y. (2013). Maxout networks. In International conference on machine learning.
Graves, 2011
A. Graves
Practical variational inference for neural networks
Advances in neural information processing systems (NIPS) (2011), pp. 2348-2356
Graves et al., 2003
Graves, A., Eck, D., Beringer, N., & Schmidhuber, J. (2003). Isolated digit recognition with LSTM recurrent networks. In First international workshop on biologically inspired approaches to advanced information technology.
Graves et al., 2006
Graves, A., Fernandez, S., Gomez, F. J., & Schmidhuber, J. (2006). Connectionist temporal classification: Labelling unsegmented sequence data with recurrent neural nets. In ICML¡¯06: Proceedings of the 23rd international conference on machine learning (pp. 369?376).
Graves et al., 2008
A. Graves, S. Fernandez, M. Liwicki, H. Bunke, J. Schmidhuber
Unconstrained on-line handwriting recognition with recurrent neural networks
J. Platt, D. Koller, Y. Singer, S. Roweis (Eds.), Advances in neural information processing systems (NIPS), vol. 20, MIT Press, Cambridge, MA (2008), pp. 577-584
Graves and Jaitly, 2014
Graves, A., & Jaitly, N. (2014). Towards end-to-end speech recognition with recurrent neural networks. In Proc. 31st International conference on machine learning (pp. 1764?1772).
Graves et al., 2009
A. Graves, M. Liwicki, S. Fernandez, R. Bertolami, H. Bunke, J. Schmidhuber
A novel connectionist system for improved unconstrained handwriting recognition
IEEE Transactions on Pattern Analysis and Machine Intelligence, 31 (5) (2009)
Graves et al., 2013
A. Graves, A.-R. Mohamed, G.E. Hinton
Speech recognition with deep recurrent neural networks
IEEE International conference on acoustics, speech and signal processing, IEEE (2013), pp. 6645-6649
Graves and Schmidhuber, 2005
A. Graves, J. Schmidhuber
Framewise phoneme classification with bidirectional LSTM and other neural network architectures
Neural Networks, 18 (5?6) (2005), pp. 602-610
ArticleDownload PDF
Graves and Schmidhuber, 2009
A. Graves, J. Schmidhuber
Offline handwriting recognition with multidimensional recurrent neural networks
Advances in neural information processing systems (NIPS), vol. 21, MIT Press, Cambridge, MA (2009), pp. 545-552
Graziano, 2009
M. Graziano
The intelligent movement machine: an ethological perspective on the primate motor system
Oxford University Press, USA (2009)
Griewank, 2012
Griewank, A. (2012). Documenta Mathematica?Extra Volume ISMP, (pp. 389?400).
Grondman et al., 2012
I. Grondman, L. Busoniu, G.A.D. Lopes, R. Babuska
A survey of actor-critic reinforcement learning: standard and natural policy gradients
IEEE Transactions on Systems, Man, and Cybernetics Part C: Applications and Reviews, 42 (6) (2012), pp. 1291-1307
Grossberg, 1969
S. Grossberg
Some networks that can learn, remember, and reproduce any number of complicated space?time patterns, I
Journal of Mathematics and Mechanics, 19 (1969), pp. 53-91
Grossberg, 1976a
S. Grossberg
Adaptive pattern classification and universal recoding, 1: parallel development and coding of neural feature detectors
Biological Cybernetics, 23 (1976), pp. 187-202
Grossberg, 1976b
S. Grossberg
Adaptive pattern classification and universal recoding, 2: feedback, expectation, olfaction, and illusions
Biological Cybernetics, 23 (1976)
Gruau et al., 1996
F. Gruau, D. Whitley, L. Pyeatt
A comparison between cellular encoding and direct encoding for genetic neural networks. NeuroCOLT Technical report NC-TR-96-048, ESPRIT Working Group in Neural and Computational Learning, NeuroCOLT 8556
(1996)
Grunwald et al., 2005
P.D. Grunwald, I.J. Myung, M.A. Pitt
Advances in minimum description length: theory and applications
MIT Press (2005)
Gruttner et al., 2010
M. Gruttner, F. Sehnke, T. Schaul, J. Schmidhuber
Multi-dimensional deep memory atari-go players for parameter exploring policy gradients
Proceedings of the international conference on artificial neural networks ICANN, Springer (2010), pp. 114-123
Guo et al., 2014
X. Guo, S. Singh, H. Lee, R. Lewis, X. Wang
Deep learning for real-time Atari game play using offline Monte-Carlo tree search planning
Advances in neural information processing systems, vol. 27 (NIPS) (2014)
Guyon et al., 1992
I. Guyon, V. Vapnik, B. Boser, L. Bottou, S.A. Solla
Structural risk minimization for character recognition
D.S. Lippman, J.E. Moody, D.S. Touretzky (Eds.), Advances in neural information processing systems (NIPS), vol. 4, Morgan Kaufmann (1992), pp. 471-479
Hadamard, 1908
J. Hadamard
Memoire sur le probleme d¡¯analyse relatif a l¡¯equilibre des plaques elastiques encastrees. Memoires presentes par divers savants a l¡¯Academie des sciences de l¡¯Institut de France: Extrait
Imprimerie nationale (1908)
Hadsell et al., 2006
R. Hadsell, S. Chopra, Y. LeCun
Dimensionality reduction by learning an invariant mapping
Proc. computer vision and pattern recognition conference, IEEE Press (2006)
Hagras et al., 2004
Hagras, H., Pounds-Cornish, A., Colley, M., Callaghan, V., & Clarke, G. (2004). Evolving spiking neural network controllers for autonomous robots. In IEEE International conference on robotics and automation, vol. 5 (pp. 4620?4626).
Hansen et al., 2003
N. Hansen, S.D. Muller, P. Koumoutsakos
Reducing the time complexity of the derandomized evolution strategy with covariance matrix adaptation (CMA-ES)
Evolutionary Computation, 11 (1) (2003), pp. 1-18
Hansen and Ostermeier, 2001
N. Hansen, A. Ostermeier
Completely derandomized self-adaptation in evolution strategies
Evolutionary Computation, 9 (2) (2001), pp. 159-195
Hanson, 1990
S.J. Hanson
A stochastic version of the delta rule
Physica D: Nonlinear Phenomena, 42 (1) (1990), pp. 265-272
ArticleDownload PDF
Hanson and Pratt, 1989
S.J. Hanson, L.Y. Pratt
Comparing biases for minimal network construction with back-propagation
D.S. Touretzky (Ed.), Advances in neural information processing systems (NIPS), vol. 1, Morgan Kaufmann, San Mateo, CA (1989), pp. 177-185
Happel and Murre, 1994
B.L. Happel, J.M. Murre
Design and evolution of modular neural network architectures
Neural Networks, 7 (6) (1994), pp. 985-1004
ArticleDownload PDF
Hashem and Schmeiser, 1992
S. Hashem, B. Schmeiser
Improving model accuracy using optimal linear combinations of trained neural networks
IEEE Transactions on Neural Networks, 6 (1992), pp. 792-794
Hassibi and Stork, 1993
B. Hassibi, D.G. Stork
Second order derivatives for network pruning: optimal brain surgeon
D.S. Lippman, J.E. Moody, D.S. Touretzky (Eds.), Advances in neural information processing systems, vol. 5, Morgan Kaufmann (1993), pp. 164-171
Hastie and Tibshirani, 1990
T.J. Hastie, R.J. Tibshirani
Generalized additive models, Monographs on statisics and applied probability, Vol. 43 (1990)
Hastie et al., 2009
T. Hastie, R. Tibshirani, J. Friedman
The elements of statistical learning, Springer series in statistics (2009)
Hawkins and George, 2006
J. Hawkins, D. George
Hierarchical temporal memory?concepts, theory, and terminology
Numenta Inc (2006)
Haykin, 2001
S.S. Haykin
Kalman filtering and neural networks
Wiley Online Library (2001)
Hebb, 1949
D.O. Hebb
The organization of behavior
Wiley, New York (1949)
Hecht-Nielsen, 1989
R. Hecht-Nielsen
Theory of the backpropagation neural network
International joint conference on neural networks, IEEE (1989), pp. 593-605
Heemskerk, 1995
J.N. Heemskerk
Overview of neural hardware
Neurocomputers for brain-style processing. Design, implementation and application (1995)
Heess et al., 2012
Heess, N., Silver, D., & Teh, Y. W. (2012). Actor-critic reinforcement learning with energy-based policies. In Proc. European workshop on reinforcement learning (pp. 43?57).
Heidrich-Meisner and Igel, 2009
V. Heidrich-Meisner, C. Igel
Neuroevolution strategies for episodic reinforcement learning
Journal of Algorithms, 64 (4) (2009), pp. 152-168
ArticleDownload PDF
Herrero et al., 2001
J. Herrero, A. Valencia, J. Dopazo
A hierarchical unsupervised growing neural network for clustering gene expression patterns
Bioinformatics, 17 (2) (2001), pp. 126-136
Hertz et al., 1991
J. Hertz, A. Krogh, R. Palmer
Introduction to the theory of neural computation
Addison-Wesley, Redwood City (1991)
Hestenes and Stiefel, 1952
M.R. Hestenes, E. Stiefel
Methods of conjugate gradients for solving linear systems
Journal of Research of the National Bureau of Standards, 49 (1952), pp. 409-436
Hihi and Bengio, 1996
S.E. Hihi, Y. Bengio
Hierarchical recurrent neural networks for long-term dependencies
D.S. Touretzky, M.C. Mozer, M.E. Hasselmo (Eds.), Advances in neural information processing systems, vol. 8, MIT Press (1996), pp. 493-499
Hinton, 1989
G.E. Hinton
Connectionist learning procedures
Artificial Intelligence, 40 (1) (1989), pp. 185-234
ArticleDownload PDF
Hinton, 2002
G.E. Hinton
Training products of experts by minimizing contrastive divergence
Neural Computation, 14 (8) (2002), pp. 1771-1800
Hinton et al., 1995
G.E. Hinton, P. Dayan, B.J. Frey, R.M. Neal
The wake-sleep algorithm for unsupervised neural networks
Science, 268 (1995), pp. 1158-1160
Hinton, Deng, et al., 2012
G.E. Hinton, L. Deng, D. Yu, G.E. Dahl, A. Mohamed, N. Jaitly, et al.
Deep neural networks for acoustic modeling in speech recognition: the shared views of four research groups
IEEE Signal Processing Magazine, 29 (6) (2012), pp. 82-97
Hinton and Ghahramani, 1997
G.E. Hinton, Z. Ghahramani
Generative models for discovering sparse distributed representations
Philosophical Transactions of the Royal Society B, 352 (1997), pp. 1177-1190
Hinton et al., 2006
G.E. Hinton, S. Osindero, Y.-W. Teh
A fast learning algorithm for deep belief nets
Neural Computation, 18 (7) (2006), pp. 1527-1554
Hinton and Salakhutdinov, 2006
G. Hinton, R. Salakhutdinov
Reducing the dimensionality of data with neural networks
Science, 313 (5786) (2006), pp. 504-507
Hinton and Sejnowski, 1986
G.E. Hinton, T.E. Sejnowski
Learning and relearning in Boltzmann machines
Parallel distributed processing, vol. 1, MIT Press (1986), pp. 282-317
Hinton, Srivastava, et al., 2012
G.E. Hinton, N. Srivastava, A. Krizhevsky, I. Sutskever, R.R. Salakhutdinov
Improving neural networks by preventing co-adaptation of feature detectors. Technical report
(2012)
arXiv:1207.0580
Hinton and van Camp, 1993
G.E. Hinton, D. van Camp
Keeping neural networks simple
Proceedings of the international conference on artificial neural networks, Amsterdam, Springer (1993), pp. 11-18
Hochreiter, 1991
S. Hochreiter
Untersuchungen zu dynamischen neuronalen Netzen
(Diploma thesis)
Institut fur Informatik, Lehrstuhl Prof. Brauer, Technische Universitat Munchen (1991)
Advisor: J. Schmidhuber
Hochreiter, Bengio, et al., 2001
S. Hochreiter, Y. Bengio, P. Frasconi, J. Schmidhuber
Gradient flow in recurrent nets: the difficulty of learning long-term dependencies
S.C. Kremer, J.F. Kolen (Eds.), A field guide to dynamical recurrent neural networks, IEEE Press (2001)
Hochreiter and Obermayer, 2005
Hochreiter, S., & Obermayer, K. (2005). Sequence classification for protein analysis. In Snowbird workshop, Snowbird: Utah. Computational and Biological Learning Society.
Hochreiter and Schmidhuber, 1996
S. Hochreiter, J. Schmidhuber
Bridging long time lags by weight guessing and Long Short-Term Memory
F.L. Silva, J.C. Principe, L.B. Almeida (Eds.), Spatiotemporal models in biological and artificial systems, Frontiers in artificial intelligence and applications, Vol. 37, IOS Press, Amsterdam, Netherlands (1996), pp. 65-72
Hochreiter and Schmidhuber, 1997a
S. Hochreiter, J. Schmidhuber
Flat minima
Neural Computation, 9 (1) (1997), pp. 1-42
Hochreiter and Schmidhuber, 1997b
S. Hochreiter, J. Schmidhuber
Long short-term memory
Neural Computation, 9 (8) (1997), pp. 1735-1780
Based on TR FKI-207-95, TUM (1995)
Hochreiter and Schmidhuber, 1999
S. Hochreiter, J. Schmidhuber
Feature extraction through LOCOCODE
Neural Computation, 11 (3) (1999), pp. 679-714
Hochreiter, Younger, et al., 2001
S. Hochreiter, A.S. Younger, P.R. Conwell
Learning to learn using gradient descent
Proc. intl. conf. on artificial neural networks, Lecture notes on comp. sci., Vol. 2130, Springer, Berlin, Heidelberg (2001), pp. 87-94
Hodgkin and Huxley, 1952
A.L. Hodgkin, A.F. Huxley
A quantitative description of membrane current and its application to conduction and excitation in nerve
The Journal of Physiology, 117 (4) (1952), p. 500
Hoerzer et al., 2014
G.M. Hoerzer, R. Legenstein, W. Maass
Emergence of complex computational structures from chaotic neural networks through reward-modulated Hebbian learning
Cerebral Cortex, 24 (2014), pp. 677-690
Holden, 1994
S.B. Holden
On the theory of generalization and self-structuring in linearly weighted connectionist networks
(Ph.D. thesis)
Cambridge University, Engineering Department (1994)
Holland, 1975
J.H. Holland
Adaptation in natural and artificial systems
University of Michigan Press, Ann Arbor (1975)
Honavar and Uhr, 1988
V. Honavar, L.M. Uhr
A network of neuron-like units that learns to perceive by generation as well as reweighting of its links
D. Touretzky, G.E. Hinton, T. Sejnowski (Eds.), Proc. of the 1988 connectionist models summer school, Morgan Kaufman, San Mateo (1988), pp. 472-484
Honavar and Uhr, 1993
V. Honavar, L. Uhr
Generative learning structures and processes for generalized connectionist networks
Information Sciences, 70 (1) (1993), pp. 75-108
ArticleDownload PDF
Hopfield, 1982
J.J. Hopfield
Neural networks and physical systems with emergent collective computational abilities
Proceedings of the National Academy of Sciences, 79 (1982), pp. 2554-2558
Hornik et al., 1989
K. Hornik, M. Stinchcombe, H. White
Multilayer feedforward networks are universal approximators
Neural Networks, 2 (5) (1989), pp. 359-366
ArticleDownload PDF
Hubel and Wiesel, 1962
D.H. Hubel, T. Wiesel
Receptive fields, binocular interaction, and functional architecture in the cat¡¯s visual cortex
Journal of Physiology (London), 160 (1962), pp. 106-154
Hubel and Wiesel, 1968
D.H. Hubel, T.N. Wiesel
Receptive fields and functional architecture of monkey striate cortex
The Journal of Physiology, 195 (1) (1968), pp. 215-243
Huffman, 1952
D.A. Huffman
A method for construction of minimum-redundancy codes
Proceedings IRE, 40 (1952), pp. 1098-1101
Hung et al., 2005
C.P. Hung, G. Kreiman, T. Poggio, J.J. DiCarlo
Fast readout of object identity from macaque inferior temporal cortex
Science, 310 (5749) (2005), pp. 863-866
Hutter, 2002
M. Hutter
The fastest and shortest algorithm for all well-defined problems
International Journal of Foundations of Computer Science, 13 (3) (2002), pp. 431-443
(On J. Schmidhuber¡¯s SNF grant 20-61847)
Hutter, 2005
M. Hutter
Universal artificial intelligence: sequential decisions based on algorithmic probability
Springer, Berlin (2005)
(On J. Schmidhuber¡¯s SNF grant 20-61847)
Hyvarinen et al., 1999
A. Hyvarinen, P. Hoyer, E. Oja
Sparse code shrinkage: denoising by maximum likelihood estimation
M. Kearns, S.A. Solla, D. Cohn (Eds.), Advances in neural information processing systems (NIPS), vol. 12, MIT Press (1999)
Hyvarinen et al., 2001
A. Hyvarinen, J. Karhunen, E. Oja
Independent component analysis
John Wiley & Sons (2001)
ICPR, 2012
ICPR (2012). Contest on Mitosis Detection in Breast Cancer Histological Images (2012). IPAL laboratory and TRIBVN company and pitie-salpetriere hospital and CIALAB of Ohio State Univ. http://ipal.cnrs.fr/ICPR2012/.
Igel, 2003
C. Igel
Neuroevolution for reinforcement learning using evolution strategies
R. Reynolds, H. Abbass, K.C. Tan, B. Mckay, D. Essam, T. Gedeon (Eds.), Congress on evolutionary computation, vol. 4, IEEE (2003), pp. 2588-2595
Igel and Husken, 2003
C. Igel, M. Husken
Empirical evaluation of the improved Rprop learning algorithm
Neurocomputing, 50 (C) (2003), pp. 105-123
ArticleDownload PDF
Ikeda et al., 1976
S. Ikeda, M. Ochiai, Y. Sawaragi
Sequential GMDH algorithm and its application to river flow prediction
IEEE Transactions on Systems, Man and Cybernetics (7) (1976), pp. 473-479
Indermuhle et al., 2012
E. Indermuhle, V. Frinken, H. Bunke
Mode detection in online handwritten documents using BLSTM neural networks
Frontiers in handwriting recognition (ICFHR), 2012 international conference on, IEEE (2012), pp. 302-307
Indermuhle et al., 2011
E. Indermuhle, V. Frinken, A. Fischer, H. Bunke
Keyword spotting in online handwritten documents containing text and non-text using BLSTM neural networks
Document analysis and recognition (ICDAR), 2011 international conference on, IEEE (2011), pp. 73-77
Indiveri et al., 2011
G. Indiveri, B. Linares-Barranco, T.J. Hamilton, A. Van Schaik, R. Etienne-Cummings, T. Delbruck, et al.
Neuromorphic silicon neuron circuits
Frontiers in Neuroscience, 5 (73) (2011)
Ivakhnenko, 1968
A.G. Ivakhnenko
The group method of data handling?a rival of the method of stochastic approximation
Soviet Automatic Control, 13 (3) (1968), pp. 43-55
Ivakhnenko, 1971
A.G. Ivakhnenko
Polynomial theory of complex systems
IEEE Transactions on Systems, Man and Cybernetics (4) (1971), pp. 364-378
Ivakhnenko, 1995
A.G. Ivakhnenko
The review of problems solvable by algorithms of the group method of data handling (GMDH)
Pattern Recognition and Image Analysis/Raspoznavaniye Obrazov I Analiz Izobrazhenii, 5 (1995), pp. 527-535
Ivakhnenko and Lapa, 1965
A.G. Ivakhnenko, V.G. Lapa
Cybernetic predicting devices
CCM Information Corporation (1965)
Ivakhnenko et al., 1967
A.G. Ivakhnenko, V.G. Lapa, R.N. McDonough
Cybernetics and forecasting techniques
American Elsevier, NY (1967)
Izhikevich et al., 2003
E.M. Izhikevich, et al.
Simple model of spiking neurons
IEEE Transactions on Neural Networks, 14 (6) (2003), pp. 1569-1572
Jaakkola et al., 1995
T. Jaakkola, S.P. Singh, M.I. Jordan
Reinforcement learning algorithm for partially observable Markov decision problems
G. Tesauro, D.S. Touretzky, T.K. Leen (Eds.), Advances in neural information processing systems, vol. 7, MIT Press (1995), pp. 345-352
Jackel et al., 1990
Jackel, L., Boser, B., Graf, H.-P., Denker, J., LeCun, Y., & Henderson, D., et al. (1990). VLSI implementation of electronic neural networks: and example in character recognition. In IEEE (Ed.), IEEE international conference on systems, man, and cybernetics (pp. 320?322).
Jacob et al., 1994
C. Jacob, A. Lindenmayer, G. Rozenberg
Genetic L-system programming
Parallel problem solving from nature III, Lecture notes in computer science (1994)
Jacobs, 1988
R.A. Jacobs
Increased rates of convergence through learning rate adaptation
Neural Networks, 1 (4) (1988), pp. 295-307
ArticleDownload PDF
Jaeger, 2001
H. Jaeger
The ¡°echo state¡± approach to analysing and training recurrent neural networks. Technical report GMD Report 148
German National Research Center for Information Technology (2001)
Jaeger, 2004
H. Jaeger
Harnessing nonlinearity: Predicting chaotic systems and saving energy in wireless communication
Science, 304 (2004), pp. 78-80
Jain and Seung, 2009
V. Jain, S. Seung
Natural image denoising with convolutional networks
D. Koller, D. Schuurmans, Y. Bengio, L. Bottou (Eds.), Advances in neural information processing systems (NIPS), vol. 21, Curran Associates, Inc (2009), pp. 769-776
Jameson, 1991
J. Jameson
Delayed reinforcement learning with multiple time scale hierarchical backpropagated adaptive critics
Neural networks for control (1991)
Ji et al., 2013
S. Ji, W. Xu, M. Yang, K. Yu
3D convolutional neural networks for human action recognition
IEEE Transactions on Pattern Analysis and Machine Intelligence, 35 (1) (2013), pp. 221-231
Jim et al., 1995
K. Jim, C.L. Giles, B.G. Horne
Effects of noise on convergence and generalization in recurrent networks
G. Tesauro, D. Touretzky, T. Leen (Eds.), Advances in neural information processing systems (NIPS), vol. 7, Morgan Kaufmann, San Mateo, CA (1995), p. 649
Jin et al., 2010
X. Jin, M. Lujan, L.A. Plana, S. Davies, S. Temple, S.B. Furber
Modeling spiking neural networks on SpiNNaker
Computing in Science and Engineering, 12 (5) (2010), pp. 91-97
Jodogne and Piater, 2007
S.R. Jodogne, J.H. Piater
Closed-loop learning of visual control policies
Journal of Artificial Intelligence Research, 28 (2007), pp. 349-391
Jones and Palmer, 1987
J.P. Jones, L.A. Palmer
An evaluation of the two-dimensional Gabor filter model of simple receptive fields in cat striate cortex
Journal of Neurophysiology, 58 (6) (1987), pp. 1233-1258
Jordan, 1986
M.I. Jordan
Serial order: a parallel distributed processing approach. Technical report ICS report 8604
Institute for Cognitive Science, University of California, San Diego (1986)
Jordan, 1988
M.I. Jordan
Supervised learning and systems with excess degrees of freedom. Technical report COINS TR 88-27
Massachusetts Institute of Technology (1988)
Jordan, 1997
M.I. Jordan
Serial order: a parallel distributed processing approach
Advances in Psychology, 121 (1997), pp. 471-495
ArticleDownload PDF
Jordan and Rumelhart, 1990
M.I. Jordan, D.E. Rumelhart
Supervised learning with a distal teacher. Technical report Occasional Paper #40
Center for Cog. Sci., Massachusetts Institute of Technology (1990)
Jordan and Sejnowski, 2001
M.I. Jordan, T.J. Sejnowski
Graphical models: foundations of neural computation
MIT Press (2001)
Joseph, 1961
R.D. Joseph
Contributions to perceptron theory
(Ph.D. thesis)
Cornell Univ (1961)
Juang, 2004
C.-F. Juang
A hybrid of genetic algorithm and particle swarm optimization for recurrent network design
IEEE Transactions on Systems, Man, and Cybernetics, Part B: Cybernetics, 34 (2) (2004), pp. 997-1006
Judd, 1990
J.S. Judd
Neural network design and the complexity of learning, Neural network modeling and connectionism, MIT Press (1990)
Jutten and Herault, 1991
C. Jutten, J. Herault
Blind separation of sources, part I: an adaptive algorithm based on neuromimetic architecture
Signal Processing, 24 (1) (1991), pp. 1-10
ArticleDownload PDF
Kaelbling et al., 1995
L.P. Kaelbling, M.L. Littman, A.R. Cassandra
Planning and acting in partially observable stochastic domains. Technical report
Brown University, Providence RI (1995)
Kaelbling et al., 1996
L.P. Kaelbling, M.L. Littman, A.W. Moore
Reinforcement learning: A survey
Journal of AI Research, 4 (1996), pp. 237-285
Kak et al., 2010
Kak, S., Chen, Y., & Wang, L. (2010). Data mining using surface and deep agents based on neural networks. In AMCIS 2010 proceedings.
Kalinke and Lehmann, 1998
Y. Kalinke, H. Lehmann
Computation in recurrent neural networks: from counters to iterated function systems
G. Antoniou, J. Slaney (Eds.), Advanced topics in artificial intelligence, Proceedings of the 11th Australian joint conference on artificial intelligence, LNAI, Vol. 1502, Springer, Berlin, Heidelberg (1998)
Kalman, 1960
R.E. Kalman
A new approach to linear filtering and prediction problems
Journal of Basic Engineering, 82 (1) (1960), pp. 35-45
Karhunen and Joutsensalo, 1995
J. Karhunen, J. Joutsensalo
Generalizations of principal component analysis, optimization problems, and neural networks
Neural Networks, 8 (4) (1995), pp. 549-562
ArticleDownload PDF
Karpathy et al., 2014
Karpathy, A., Toderici, G., Shetty, S., Leung, T., Sukthankar, R., & Fei-Fei, L. (2014). Large-scale video classification with convolutional neural networks. In IEEE conference on computer vision and pattern recognition.
Kasabov, 2014
N.K. Kasabov
Neucube: a spiking neural network architecture for mapping, learning and understanding of spatio-temporal brain data
Neural Networks (2014)
Kelley, 1960
H.J. Kelley
Gradient theory of optimal flight paths
ARS Journal, 30 (10) (1960), pp. 947-954
Kempter et al., 1999
R. Kempter, W. Gerstner, J.L. Van Hemmen
Hebbian learning and spiking neurons
Physical Review E, 59 (4) (1999), p. 4498
Kerlirzin and Vallet, 1993
P. Kerlirzin, F. Vallet
Robustness in multilayer perceptrons
Neural Computation, 5 (1) (1993), pp. 473-482
Khan et al., 2014
Khan, S. H., Bennamoun, M., Sohel, F., & Togneri, R. (2014). Automatic feature learning for robust shadow detection. In IEEE conference on computer vision and pattern recognition.
Khan et al., 2010
Khan, M. M., Khan, G. M., & Miller, J. F. (2010). Evolution of neural networks using Cartesian Genetic Programming. In IEEE congress on evolutionary computation (pp. 1?8).
Khan et al., 2008
M.M. Khan, D.R. Lester, L.A. Plana, A. Rast, X. Jin, E. Painkras, et al.
SpiNNaker: mapping neural networks onto a massively-parallel chip multiprocessor
International joint conference on neural networks, IEEE (2008), pp. 2849-2856
Kimura et al., 1997
Kimura, H., Miyazaki, K., & Kobayashi, S. (1997). Reinforcement learning in POMDPs with function approximation. In ICML, vol. 97 (pp. 152?160).
Kistler et al., 1997
W.M. Kistler, W. Gerstner, J.L. van Hemmen
Reduction of the Hodgkin?Huxley equations to a single-variable threshold model
Neural Computation, 9 (5) (1997), pp. 1015-1045
Kitano, 1990
H. Kitano
Designing neural networks using genetic algorithms with graph generation system
Complex Systems, 4 (1990), pp. 461-476
Klampfl and Maass, 2013
S. Klampfl, W. Maass
Emergence of dynamic memory traces in cortical microcircuit models through STDP
The Journal of Neuroscience, 33 (28) (2013), pp. 11515-11529
Klapper-Rybicka et al., 2001
M. Klapper-Rybicka, N.N. Schraudolph, J. Schmidhuber
Unsupervised learning in LSTM recurrent neural networks
Proc. intl. conf. on artificial neural networks, Lecture Notes on Comp. Sci., Vol. 2130, Springer, Berlin, Heidelberg (2001), pp. 684-691
Kobatake and Tanaka, 1994
E. Kobatake, K. Tanaka
Neuronal selectivities to complex object features in the ventral visual pathway of the macaque cerebral cortex
Journal of Neurophysiology, 71 (1994), pp. 856-867
Kohl and Stone, 2004
N. Kohl, P. Stone
Policy gradient reinforcement learning for fast quadrupedal locomotion
Robotics and automation, 2004. Proceedings. ICRA¡¯04. 2004 IEEE international conference on, vol. 3, IEEE (2004), pp. 2619-2624
Kohonen, 1972
T. Kohonen
Correlation matrix memories
IEEE Transactions on Computers, 100 (4) (1972), pp. 353-359
Kohonen, 1982
T. Kohonen
Self-organized formation of topologically correct feature maps
Biological Cybernetics, 43 (1) (1982), pp. 59-69
Kohonen, 1988
T. Kohonen
Self-organization and associative memory
(2nd ed), Springer (1988)
Koikkalainen and Oja, 1990
P. Koikkalainen, E. Oja
Self-organizing hierarchical feature maps
International joint conference on neural networks, IEEE (1990), pp. 279-284
Kolmogorov, 1965a
A.N. Kolmogorov
On the representation of continuous functions of several variables by superposition of continuous functions of one variable and addition
Doklady Akademii Nauk SSSR, 114 (1965), pp. 679-681
Kolmogorov, 1965b
A.N. Kolmogorov
Three approaches to the quantitative definition of information
Problems of Information Transmission, 1 (1965), pp. 1-11
Kompella et al., 2012
V.R. Kompella, M.D. Luciw, J. Schmidhuber
Incremental slow feature analysis: Adaptive low-complexity slow feature updating from high-dimensional input streams
Neural Computation, 24 (11) (2012), pp. 2994-3024
Kondo, 1998
T. Kondo
GMDH neural network algorithm using the heuristic self-organization method and its application to the pattern identification problem
Proceedings of the 37th SICE annual conference, IEEE (1998), pp. 1143-1148
Kondo and Ueno, 2008
T. Kondo, J. Ueno
Multi-layered GMDH-type neural network self-selecting optimum neural network architecture and its application to 3-dimensional medical image recognition of blood vessels
International Journal of Innovative Computing, Information and Control, 4 (1) (2008), pp. 175-187
Kordik et al., 2003
P. Kordik, P. Naplava, M. Snorek, M. Genyk-Berezovskyj
Modified GMDH method and models quality evaluation by visualization
Control Systems and Computers, 2 (2003), pp. 68-75
Korkin et al., 1997
Korkin, M., de Garis, H., Gers, F., & Hemmi, H. (1997). CBM (CAM-Brain Machine)?a hardware tool which evolves a neural net module in a fraction of a second and runs a million neuron artificial brain in real time.
Kosko, 1990
B. Kosko
Unsupervised learning in noise
IEEE Transactions on Neural Networks, 1 (1) (1990), pp. 44-57
Koutnik et al., 2013
J. Koutnik, G. Cuccu, J. Schmidhuber, F. Gomez
Evolving large-scale neural networks for vision-based reinforcement learning
Proceedings of the genetic and evolutionary computation conference, ACM, Amsterdam (2013), pp. 1061-1068
Koutnik et al., 2010
Koutnik, J., Gomez, F., & Schmidhuber, J. (2010). Evolving neural networks in compressed weight space. In Proceedings of the 12th annual conference on genetic and evolutionary computation (pp. 619?626).
Koutnik et al., 2014
Koutnik, J., Greff, K., Gomez, F., & Schmidhuber, J. (2014). A clockwork RNN. In Proceedings of the 31th international conference on machine learning, vol. 32 (pp. 1845?1853). arXiv:1402.3511  [cs.NE].
Koza, 1992
J.R. Koza
Genetic programming?on the programming of computers by means of natural selection
MIT Press (1992)
Kramer, 1991
M. Kramer
Nonlinear principal component analysis using autoassociative neural networks
AIChE Journal, 37 (1991), pp. 233-243
Kremer and Kolen, 2001
S.C. Kremer, J.F. Kolen
Field guide to dynamical recurrent networks
Wiley-IEEE Press (2001)
Kriegeskorte et al., 2008
N. Kriegeskorte, M. Mur, D.A. Ruff, R. Kiani, J. Bodurka, H. Esteky, et al.
Matching categorical object representations in inferior temporal cortex of man and monkey
Neuron, 60 (6) (2008), pp. 1126-1141
ArticleDownload PDF
Krizhevsky et al., 2012
A. Krizhevsky, I. Sutskever, G.E. Hinton
Imagenet classification with deep convolutional neural networks
Advances in neural information processing systems (2012), p. 4
Krogh and Hertz, 1992
A. Krogh, J.A. Hertz
A simple weight decay can improve generalization
D.S. Lippman, J.E. Moody, D.S. Touretzky (Eds.), Advances in neural information processing systems, vol. 4, Morgan Kaufmann (1992), pp. 950-957
Kruger et al., 2013
N. Kruger, P. Janssen, S. Kalkan, M. Lappe, A. Leonardis, J. Piater, et al.
Deep hierarchies in the primate visual cortex: what can we learn for computer vision?
IEEE Transactions on Pattern Analysis and Machine Intelligence, 35 (8) (2013), pp. 1847-1871
Kullback and Leibler, 1951
S. Kullback, R.A. Leibler
On information and sufficiency
The Annals of Mathematical Statistics (1951), pp. 79-86
Kurzweil, 2012
R. Kurzweil
How to create a mind: the secret of human thought revealed
(2012)
Lagoudakis and Parr, 2003
M.G. Lagoudakis, R. Parr
Least-squares policy iteration
Journal of Machine Learning Research, 4 (2003), pp. 1107-1149
Lampinen and Oja, 1992
J. Lampinen, E. Oja
Clustering properties of hierarchical self-organizing maps
Journal of Mathematical Imaging and Vision, 2 (2?3) (1992), pp. 261-272
Lang et al., 1990
K. Lang, A. Waibel, G.E. Hinton
A time-delay neural network architecture for isolated word recognition
Neural Networks, 3 (1990), pp. 23-43
ArticleDownload PDF
Lange and Riedmiller, 2010
Lange, S., & Riedmiller, M. (2010). Deep auto-encoder neural networks in reinforcement learning. In Neural networks, The 2010 international joint conference on (pp. 1?8).
Lapedes and Farber, 1986
A. Lapedes, R. Farber
A self-optimizing, nonsymmetrical neural net for content addressable memory and pattern recognition
Physica D, 22 (1986), pp. 247-259
ArticleDownload PDF
Laplace, 1774
P. Laplace
Memoire sur la probabilite des causes par les evenements
Memoires de l¡¯Academie Royale des Sciences Presentes par Divers Savan, 6 (1774), pp. 621-656
Larraanaga and Lozano, 2001
P. Larraanaga, J.A. Lozano
Estimation of distribution algorithms: a new tool for evolutionary computation
Kluwer Academic Publishers, Norwell, MA, USA (2001)
Le et al., 2012
Le, Q. V., Ranzato, M., Monga, R., Devin, M., Corrado, G., & Chen, K., et al. (2012). Building high-level features using large scale unsupervised learning. In Proc. ICML¡¯12.
LeCun, 1985
LeCun, Y. (1985). Une procedure d¡¯apprentissage pour reseau a seuil asymetrique. In Proceedings of cognitiva 85 (pp. 599?604).
LeCun, 1988
Y. LeCun
A theoretical framework for back-propagation
D. Touretzky, G. Hinton, T. Sejnowski (Eds.), Proceedings of the 1988 connectionist models summer school, Morgan Kaufmann, CMU, Pittsburgh, Pa (1988), pp. 21-28
LeCun et al., 1989
Y. LeCun, B. Boser, J.S. Denker, D. Henderson, R.E. Howard, W. Hubbard, et al.
Back-propagation applied to handwritten zip code recognition
Neural Computation, 1 (4) (1989), pp. 541-551
LeCun, Boser, et al., 1990
Y. LeCun, B. Boser, J.S. Denker, D. Henderson, R.E. Howard, W. Hubbard, et al.
Handwritten digit recognition with a back-propagation network
D.S. Touretzky (Ed.), Advances in neural information processing systems, vol. 2, Morgan Kaufmann (1990), pp. 396-404
LeCun et al., 1998
Y. LeCun, L. Bottou, Y. Bengio, P. Haffner
Gradient-based learning applied to document recognition
Proceedings of the IEEE, 86 (11) (1998), pp. 2278-2324
LeCun, Denker, et al., 1990
Y. LeCun, J.S. Denker, S.A. Solla
Optimal brain damage
D.S. Touretzky (Ed.), Advances in neural information processing systems, vol. 2, Morgan Kaufmann (1990), pp. 598-605
LeCun et al., 2006
Y. LeCun, U. Muller, E. Cosatto, B. Flepp
Off-road obstacle avoidance through end-to-end learning
Advances in neural information processing systems (NIPS 2005) (2006)
LeCun et al., 1993
Y. LeCun, P. Simard, B. Pearlmutter
Automatic learning rate maximization by on-line estimation of the Hessian¡¯s eigenvectors
S. Hanson, J. Cowan, L. Giles (Eds.), Advances in neural information processing systems, vol. 5 (NIPS 1992), Morgan Kaufmann Publishers, San Mateo, CA (1993)
Lee, 1996
L. Lee
Learning of context-free languages: a survey of the literature. Technical report TR-12-96
Center for Research in Computing Technology, Harvard University, Cambridge, Massachusetts (1996)
Lee, Battle, et al., 2007
H. Lee, A. Battle, R. Raina, A.Y. Ng
Efficient sparse coding algorithms
Advances in neural information processing systems (NIPS), vol. 19 (2007), pp. 801-808
Lee, Ekanadham, et al., 2007
H. Lee, C. Ekanadham, A.Y. Ng
Sparse deep belief net model for visual area V2
Advances in neural information processing systems (NIPS), vol. 7 (2007), pp. 873-880
Lee, Grosse, et al., 2009
Lee, H., Grosse, R., Ranganath, R., & Ng, A. Y. (2009). Convolutional deep belief networks for scalable unsupervised learning of hierarchical representations. In Proceedings of the 26th international conference on machine learning (pp. 609?616).
Lee and Kil, 1991
S. Lee, R.M. Kil
A Gaussian potential function network with hierarchically self-organizing learning
Neural Networks, 4 (2) (1991), pp. 207-224
ArticleDownload PDF
Lee, Pham, et al., 2009
Lee, H., Pham, P. T., Largman, Y., & Ng, A. Y. (2009). Unsupervised feature learning for audio classification using convolutional deep belief networks. In Proc. NIPS, vol. 9 (pp. 1096?1104).
Legendre, 1805
A.M. Legendre
Nouvelles methodes pour la determination des orbites des cometes
F. Didot (1805)
Legenstein and Maass, 2002
R.A. Legenstein, W. Maass
Neural circuits for pattern recognition with small total wire length
Theoretical Computer Science, 287 (1) (2002), pp. 239-249
ArticleDownload PDF
Legenstein et al., 2010
R. Legenstein, N. Wilbert, L. Wiskott
Reinforcement learning on slow features of high-dimensional input streams
PLoS Computational Biology, 6 (8) (2010)
Leibniz, 1676
Leibniz, G. W. (1676). Memoir using the chain rule (cited in TMME 7:2&3 p. 321?332, 2010).
Leibniz, 1684
G.W. Leibniz
Nova methodus pro maximis et minimis, itemque tangentibus, quae nec fractas, nec irrationales quantitates moratur, et singulare pro illis calculi genus
Acta Eruditorum (1684), pp. 467-473
Lenat, 1983
D.B. Lenat
Theory formation by heuristic search
Machine Learning, 21 (1983)
Lenat and Brown, 1984
D.B. Lenat, J.S. Brown
Why AM an EURISKO appear to work
Artificial Intelligence, 23 (3) (1984), pp. 269-294
ArticleDownload PDF
Lennie and Movshon, 2005
P. Lennie, J.A. Movshon
Coding of color and form in the geniculostriate visual pathway
Journal of the Optical Society of America A, 22 (10) (2005), pp. 2013-2033
Levenberg, 1944
K. Levenberg
A method for the solution of certain problems in least squares
Quarterly of Applied Mathematics, 2 (1944), pp. 164-168
Levin, 1973a
L.A. Levin
On the notion of a random sequence
Soviet Mathematics Doklady, 14 (5) (1973), pp. 1413-1416
Levin, 1973b
L.A. Levin
Universal sequential search problems
Problems of Information Transmission, 9 (3) (1973), pp. 265-266
Levin et al., 1994
A.U. Levin, T.K. Leen, J.E. Moody
Fast pruning using principal components
Advances in neural information processing systems (NIPS), vol. 6, Morgan Kaufmann (1994), p. 35
Levin and Narendra, 1995
A.U. Levin, K.S. Narendra
Control of nonlinear dynamical systems using neural networks. II. Observability, identification, and control
IEEE Transactions on Neural Networks, 7 (1) (1995), pp. 30-42
Lewicki and Olshausen, 1998
M.S. Lewicki, B.A. Olshausen
Inferring sparse, overcomplete image codes using an efficient coding framework
M.I. Jordan, M.J. Kearns, S.A. Solla (Eds.), Advances in neural information processing systems (NIPS), vol. 10 (1998), pp. 815-821
L¡¯Hopital, 1696
G.F.A. L¡¯Hopital
Analyse des infiniment petits, pour l¡¯intelligence des lignes courbes
L¡¯Imprimerie Royale, Paris (1696)
Li and Vitanyi, 1997
M. Li, P.M.B. Vitanyi
An introduction to Kolmogorov complexity and its applications
(2nd ed.), Springer (1997)
Li et al., 2014
R. Li, W. Zhang, H.-I. Suk, L. Wang, J. Li, D. Shen, et al.
Deep learning based imaging data completion for improved brain disease diagnosis
Proc. MICCAI, Springer (2014)
Lin, 1993
L. Lin
Reinforcement learning for robots using neural networks
(Ph.D. thesis)
Carnegie Mellon University, Pittsburgh (1993)
Lin et al., 1996
T. Lin, B. Horne, P. Tino, C. Giles
Learning long-term dependencies in NARX recurrent neural networks
IEEE Transactions on Neural Networks, 7 (6) (1996), pp. 1329-1338
Lindenmayer, 1968
A. Lindenmayer
Mathematical models for cellular interaction in development
Journal of Theoretical Biology, 18 (1968), pp. 280-315
Lindstadt, 1993
S. Lindstadt
Comparison of two unsupervised neural network models for redundancy reduction
M.C. Mozer, P. Smolensky, D.S. Touretzky, J.L. Elman, A.S. Weigend (Eds.), Proc. of the 1993 connectionist models summer school, Erlbaum Associates, Hillsdale, NJ (1993), pp. 308-315
Linnainmaa, 1970
S. Linnainmaa
The representation of the cumulative rounding error of an algorithm as a Taylor expansion of the local rounding errors
(Master¡¯s thesis)
Univ. Helsinki (1970)
Linnainmaa, 1976
S. Linnainmaa
Taylor expansion of the accumulated rounding error
BIT Numerical Mathematics, 16 (2) (1976), pp. 146-160
Linsker, 1988
R. Linsker
Self-organization in a perceptual network
IEEE Computer, 21 (1988), pp. 105-117
Littman et al., 1995
M.L. Littman, A.R. Cassandra, L.P. Kaelbling
Learning policies for partially observable environments: scaling up
A. Prieditis, S. Russell (Eds.), Machine learning: proceedings of the twelfth international conference, Morgan Kaufmann Publishers, San Francisco, CA (1995), pp. 362-370
ArticleDownload PDF
Liu et al., 2001
S.-C. Liu, J. Kramer, G. Indiveri, T. Delbruck, T. Burg, R. Douglas, et al.
Orientation-selective aVLSI spiking neurons
Neural Networks, 14 (6?7) (2001), pp. 629-643
ArticleDownload PDF
Ljung, 1998
L. Ljung
System identification
Springer (1998)
Logothetis et al., 1995
N.K. Logothetis, J. Pauls, T. Poggio
Shape representation in the inferior temporal cortex of monkeys
Current Biology, 5 (5) (1995), pp. 552-563
ArticleDownload PDF
Loiacono et al., 2011
D. Loiacono, L. Cardamone, P.L. Lanzi
Simulated car racing championship competition software manual. Technical report
Dipartimento di Elettronica e Informazione, Politecnico di Milano, Italy (2011)
Loiacono et al., 2009
Loiacono, D., Lanzi, P. L., Togelius, J., Onieva, E., Pelta, D. A., & Butz, M. V., et al. (2009). The 2009 simulated car racing championship.
Lowe, 1999
Lowe, D. (1999). Object recognition from local scale-invariant features. In The Proceedings of the seventh IEEE international conference on computer vision, vol. 2 (pp. 1150?1157).
Lowe, 2004
D. Lowe
Distinctive image features from scale-invariant key-points
International Journal of Computer Vision, 60 (2004), pp. 91-110
Luciw et al., 2013
M. Luciw, V.R. Kompella, S. Kazerounian, J. Schmidhuber
An intrinsic value system for developing multiple invariant representations with incremental slowness learning
Frontiers in Neurorobotics, 7 (9) (2013)
Lusci et al., 2013
A. Lusci, G. Pollastri, P. Baldi
Deep architectures and deep learning in chemoinformatics: the prediction of aqueous solubility for drug-like molecules
Journal of Chemical Information and Modeling, 53 (7) (2013), pp. 1563-1575
Maas et al., 2013
Maas, A. L., Hannun, A. Y., & Ng, A. Y. (2013). Rectifier nonlinearities improve neural network acoustic models. In International conference on machine learning.
Maass, 1996
W. Maass
Lower bounds for the computational power of networks of spiking neurons
Neural Computation, 8 (1) (1996), pp. 1-40
Maass, 1997
W. Maass
Networks of spiking neurons: the third generation of neural network models
Neural Networks, 10 (9) (1997), pp. 1659-1671
ArticleDownload PDF
Maass, 2000
W. Maass
On the computational power of winner-take-all
Neural Computation, 12 (2000), pp. 2519-2535
Maass et al., 2002
W. Maass, T. Natschlager, H. Markram
Real-time computing without stable states: A new framework for neural computation based on perturbations
Neural Computation, 14 (11) (2002), pp. 2531-2560
MacKay, 1992
D.J.C. MacKay
A practical Bayesian framework for backprop networks
Neural Computation, 4 (1992), pp. 448-472
MacKay and Miller, 1990
D.J.C. MacKay, K.D. Miller
Analysis of Linsker¡¯s simulation of Hebbian rules
Neural Computation, 2 (1990), pp. 173-187
Maclin and Shavlik, 1993
R. Maclin, J.W. Shavlik
Using knowledge-based neural networks to improve algorithms: Refining the Chou?Fasman algorithm for protein folding
Machine Learning, 11 (2?3) (1993), pp. 195-215
Maclin and Shavlik, 1995
Maclin, R., & Shavlik, J. W. (1995). Combining the predictions of multiple classifiers: Using competitive learning to initialize neural networks. In Proc. IJCAI (pp. 524?531).
Madala and Ivakhnenko, 1994
H.R. Madala, A.G. Ivakhnenko
Inductive learning algorithms for complex systems modeling
CRC Press, Boca Raton (1994)
Madani et al., 2003
O. Madani, S. Hanks, A. Condon
On the undecidability of probabilistic planning and related stochastic optimization problems
Artificial Intelligence, 147 (1) (2003), pp. 5-34
ArticleDownload PDF
Maei and Sutton, 2010
Maei, H. R., & Sutton, R. S. (2010). GQ(): A general gradient algorithm for temporal-difference prediction learning with eligibility traces. In Proceedings of the third conference on artificial general intelligence, vol. 1 (pp. 91?96).
Maex and Orban, 1996
R. Maex, G. Orban
Model circuit of spiking neurons generating directional selectivity in simple cells
Journal of Neurophysiology, 75 (4) (1996), pp. 1515-1545
Mahadevan, 1996
S. Mahadevan
Average reward reinforcement learning: Foundations, algorithms, and empirical results
Machine Learning, 22 (1996), p. 159
Malik and Perona, 1990
J. Malik, P. Perona
Preattentive texture discrimination with early vision mechanisms
Journal of the Optical Society of America A, 7 (5) (1990), pp. 923-932
Maniezzo, 1994
V. Maniezzo
Genetic evolution of the topology and weight distribution of neural networks
IEEE Transactions on Neural Networks, 5 (1) (1994), pp. 39-53
Manolios and Fanelli, 1994
P. Manolios, R. Fanelli
First-order recurrent neural networks and deterministic finite state automata
Neural Computation, 6 (1994), pp. 1155-1173
Marchi et al., 2014
Marchi, E., Ferroni, G., Eyben, F., Gabrielli, L., Squartini, S., & Schuller, B. (2014). Multi-resolution linear prediction based features for audio onset detection with bidirectional LSTM neural networks. In Proc. 39th IEEE international conference on acoustics, speech, and signal processing (pp. 2183?2187).
Markram, 2012
H. Markram
The human brain project
Scientific American, 306 (6) (2012), pp. 50-55
Marquardt, 1963
D.W. Marquardt
An algorithm for least-squares estimation of nonlinear parameters
Journal of the Society for Industrial & Applied Mathematics, 11 (2) (1963), pp. 431-441
Martens, 2010
J. Martens
Deep learning via Hessian-free optimization
J. Furnkranz, T. Joachims (Eds.), Proceedings of the 27th international conference on machine learning, OmniPress, Haifa, Israel (2010), pp. 735-742
Martens and Sutskever, 2011
Martens, J., & Sutskever, I. (2011). Learning recurrent neural networks with Hessian-free optimization. In Proceedings of the 28th international conference on machine learning (pp. 1033?1040).
Martinetz et al., 1990
T.M. Martinetz, H.J. Ritter, K.J. Schulten
Three-dimensional neural net for learning visuomotor coordination of a robot arm
IEEE Transactions on Neural Networks, 1 (1) (1990), pp. 131-136
Masci et al., 2013
Masci, J., Giusti, A., Ciresan, D. C., Fricout, G., & Schmidhuber, J. (2013). A fast learning algorithm for image segmentation with max-pooling convolutional networks. In International conference on image processing (pp. 2713?2717).
Matsuoka, 1992
K. Matsuoka
Noise injection into inputs in back-propagation learning
IEEE Transactions on Systems, Man and Cybernetics, 22 (3) (1992), pp. 436-440
Mayer et al., 2008
H. Mayer, F. Gomez, D. Wierstra, I. Nagy, A. Knoll, J. Schmidhuber
A system for robotic heart surgery that learns to tie knots using recurrent neural networks
Advanced Robotics, 22 (13?14) (2008), pp. 1521-1537
McCallum, 1996
R.A. McCallum
Learning to use selective attention and short-term memory in sequential tasks
P. Maes, M. Mataric, J.-A. Meyer, J. Pollack, S.W. Wilson (Eds.), From animals to animats 4: proceedings of the fourth international conference on simulation of adaptive behavior, MIT Press, Bradford Books (1996), pp. 315-324
McCulloch and Pitts, 1943
W. McCulloch, W. Pitts
A logical calculus of the ideas immanent in nervous activity
Bulletin of Mathematical Biophysics, 7 (1943), pp. 115-133
Melnik et al., 2000
Melnik, O., Levy, S. D., & Pollack, J. B. (2000). RAAM for infinite context-free languages. In Proc. IJCNN (5) (pp. 585?590).
Memisevic and Hinton, 2010
R. Memisevic, G.E. Hinton
Learning to represent spatial transformations with factored higher-order Boltzmann machines
Neural Computation, 22 (6) (2010), pp. 1473-1492
Menache et al., 2002
Menache, I., Mannor, S., & Shimkin, N. (2002). -cut?dynamic discovery of sub-goals in reinforcement learning. In Proc. ECML¡¯02 (pp. 295?306).
Merolla et al., 2014
P.A. Merolla, J.V. Arthur, R. Alvarez-Icaza, A.S. Cassidy, J. Sawada, F. Akopyan, et al.
A million spiking-neuron integrated circuit with a scalable communication network and interface
Science, 345 (6197) (2014), pp. 668-673
Mesnil et al., 2011
Mesnil, G., Dauphin, Y., Glorot, X., Rifai, S., Bengio, Y., & Goodfellow, I., et al. (2011). Unsupervised and transfer learning challenge: a deep learning approach. In JMLR W&CP: proc. unsupervised and transfer learning, vol. 7.
Meuleau et al., 1999
Meuleau, N., Peshkin, L., Kim, K. E., & Kaelbling, L. P. (1999). Learning finite state controllers for partially observable environments. In 15th international conference of uncertainty in AI (pp. 427?436).
Miglino et al., 1995
O. Miglino, H. Lund, S. Nolfi
Evolving mobile robots in simulated and real environments
Artificial Life, 2 (4) (1995), pp. 417-434
Miller, 1994
K.D. Miller
A model for the development of simple cell receptive fields and the ordered arrangement of orientation columns through activity-dependent competition between on- and off-center inputs
Journal of Neuroscience, 14 (1) (1994), pp. 409-441
Miller and Harding, 2009
J.F. Miller, S.L. Harding
Cartesian genetic programming
Proceedings of the 11th annual conference companion on genetic and evolutionary computation conference: late breaking papers, ACM (2009), pp. 3489-3512
Miller and Thomson, 2000
J.F. Miller, P. Thomson
Cartesian genetic programming
Genetic programming, Springer (2000), pp. 121-132
Miller et al., 1989
G. Miller, P. Todd, S. Hedge
Designing neural networks using genetic algorithms
Proceedings of the 3rd international conference on genetic algorithms, Morgan Kauffman (1989), pp. 379-384
Miller et al., 1995
W.T. Miller, P.J. Werbos, R.S. Sutton
Neural networks for control
MIT Press (1995)
Minai and Williams, 1994
A.A. Minai, R.D. Williams
Perturbation response in feedforward networks
Neural Networks, 7 (5) (1994), pp. 783-796
ArticleDownload PDF
Minsky, 1963
M. Minsky
Steps toward artificial intelligence
E. Feigenbaum, J. Feldman (Eds.), Computers and thought, McGraw-Hill, New York (1963), pp. 406-450
Minsky and Papert, 1969
M. Minsky, S. Papert
Perceptrons
MIT Press, Cambridge, MA (1969)
Minton et al., 1989
S. Minton, J.G. Carbonell, C.A. Knoblock, D.R. Kuokka, O. Etzioni, Y. Gil
Explanation-based learning: A problem solving perspective
Artificial Intelligence, 40 (1) (1989), pp. 63-118
ArticleDownload PDF
Mitchell, 1997
T. Mitchell
Machine learning
McGraw Hill (1997)
Mitchell et al., 1986
T.M. Mitchell, R.M. Keller, S.T. Kedar-Cabelli
Explanation-based generalization: A unifying view
Machine Learning, 1 (1) (1986), pp. 47-80
Mnih et al., 2013
V. Mnih, K. Kavukcuoglu, D. Silver, A. Graves, I. Antonoglou, D. Wierstra, et al.
Playing Atari with deep reinforcement learning. Technical report
Deepmind Technologies (2013)
arXiv:1312.5602 [cs.LG]
Mohamed and Hinton, 2010
Mohamed, A., & Hinton, G. E. (2010). Phone recognition using restricted Boltzmann machines. In IEEE international conference on acoustics, speech and signal processing (pp. 4354?4357).
Molgedey and Schuster, 1994
L. Molgedey, H.G. Schuster
Separation of independent signals using time-delayed correlations
Physical Review Letters, 72 (23) (1994), pp. 3634-3637
M©ªller, 1993
M.F. M©ªller
Exact calculation of the product of the Hessian matrix of feed-forward network error functions and a vector in O(N) time. Technical report PB-432
Computer Science Department, Aarhus University, Denmark (1993)
Montana and Davis, 1989
D.J. Montana, L. Davis
Training feedforward neural networks using genetic algorithms
Proceedings of the 11th international joint conference on artificial intelligence?vol. 1, Morgan Kaufmann Publishers Inc, San Francisco, CA, USA (1989), pp. 762-767
Montavon et al., 2012
G. Montavon, G. Orr, K. Muller
Neural networks: tricks of the trade, Lecture Notes in Computer Science Series. LNCS, Vol. 7700, Springer Verlag (2012)
Moody, 1989
J.E. Moody
Fast learning in multi-resolution hierarchies
D.S. Touretzky (Ed.), Advances in neural information processing systems (NIPS), vol. 1, Morgan Kaufmann (1989), pp. 29-39
Moody, 1992
J.E. Moody
The effective number of parameters: An analysis of generalization and regularization in nonlinear learning systems
D.S. Lippman, J.E. Moody, D.S. Touretzky (Eds.), Advances in neural information processing systems (NIPS), vol. 4, Morgan Kaufmann (1992), pp. 847-854
Moody and Utans, 1994
J.E. Moody, J. Utans
Architecture selection strategies for neural networks: Application to corporate bond rating prediction
A.N. Refenes (Ed.), Neural networks in the capital markets, John Wiley & Sons (1994)
Moore and Atkeson, 1993
A. Moore, C.G. Atkeson
Prioritized sweeping: Reinforcement learning with less data and less time
Machine Learning, 13 (1993), pp. 103-130
Moore and Atkeson, 1995
A. Moore, C. Atkeson
The parti-game algorithm for variable resolution reinforcement learning in multidimensional state-spaces
Machine Learning, 21 (3) (1995), pp. 199-233
Moriarty, 1997
D.E. Moriarty
Symbiotic evolution of neural networks in sequential decision tasks
(Ph.D. thesis)
Department of Computer Sciences, The University of Texas at Austin (1997)
Moriarty and Miikkulainen, 1996
D.E. Moriarty, R. Miikkulainen
Efficient reinforcement learning through symbiotic evolution
Machine Learning, 22 (1996), pp. 11-32
Morimoto and Doya, 2000
J. Morimoto, K. Doya
Robust reinforcement learning
T.K. Leen, T.G. Dietterich, V. Tresp (Eds.), Advances in neural information processing systems (NIPS), vol. 13, MIT Press (2000), pp. 1061-1067
Mosteller and Tukey, 1968
F. Mosteller, J.W. Tukey
Data analysis, including statistics
G. Lindzey, E. Aronson (Eds.), Handbook of social psychology, vol. 2, Addison-Wesley (1968)
Mozer, 1989
M.C. Mozer
A focused back-propagation algorithm for temporal sequence recognition
Complex Systems, 3 (1989), pp. 349-381
Mozer, 1991
M.C. Mozer
Discovering discrete distributed representations with iterative competitive learning
R.P. Lippmann, J.E. Moody, D.S. Touretzky (Eds.), Advances in neural information processing systems, vol. 3, Morgan Kaufmann (1991), pp. 627-634
Mozer, 1992
M.C. Mozer
Induction of multiscale temporal structure
D.S. Lippman, J.E. Moody, D.S. Touretzky (Eds.), Advances in neural information processing systems (NIPS), vol. 4, Morgan Kaufmann (1992), pp. 275-282
Mozer and Smolensky, 1989
M.C. Mozer, P. Smolensky
Skeletonization: A technique for trimming the fat from a network via relevance assessment
D.S. Touretzky (Ed.), Advances in neural information processing systems (NIPS), vol. 1, Morgan Kaufmann (1989), pp. 107-115
Muller et al., 1995
U.A. Muller, A. Gunzinger, W. Guggenbuhl
Fast neural net simulation with a DSP processor array
IEEE Transactions on Neural Networks, 6 (1) (1995), pp. 203-213
Munro, 1987
Munro, P. W. (1987). A dual back-propagation scheme for scalar reinforcement learning. In Proceedings of the ninth annual conference of the cognitive science society (pp. 165?176).
Murray and Edwards, 1993
A.F. Murray, P.J. Edwards
Synaptic weight noise during MLP learning enhances fault-tolerance, generalisation and learning trajectory
S.J. Hanson, J.D. Cowan, C.L. Giles (Eds.), Advances in neural information processing systems (NIPS), vol. 5, Morgan Kaufmann, San Mateo, CA (1993), pp. 491-498
Nadal and Parga, 1994
J.-P. Nadal, N. Parga
Non-linear neurons in the low noise limit: a factorial code maximises information transfer
Networks, 5 (1994), pp. 565-581
Nagumo et al., 1962
J. Nagumo, S. Arimoto, S. Yoshizawa
An active pulse transmission line simulating nerve axon
Proceedings of the IRE, 50 (10) (1962), pp. 2061-2070
Nair and Hinton, 2010
Nair, V., & Hinton, G. E. (2010). Rectified linear units improve restricted Boltzmann machines. In International conference on machine learning.
Narendra and Parthasarathy, 1990
K.S. Narendra, K. Parthasarathy
Identification and control of dynamical systems using neural networks
IEEE Transactions on Neural Networks, 1 (1) (1990), pp. 4-27
Narendra and Thathatchar, 1974
K.S. Narendra, M.A.L. Thathatchar
Learning automata?a survey
IEEE Transactions on Systems, Man and Cybernetics, 4 (1974), pp. 323-334
Neal, 1995
R.M. Neal
Bayesian learning for neural networks
(Ph.D. thesis)
University of Toronto (1995)
Neal, 2006
R.M. Neal
Classification with Bayesian neural networks
J. Quinonero-Candela, B. Magnini, I. Dagan, F. D¡¯Alche-Buc (Eds.), Machine learning challenges. Evaluating predictive uncertainty, visual object classification, and recognising textual entailment, Lecture notes in computer science, Vol. 3944, Springer (2006), pp. 28-32
Neal and Zhang, 2006
R.M. Neal, J. Zhang
High dimensional classification with Bayesian neural networks and Dirichlet diffusion trees
I. Guyon, S. Gunn, M. Nikravesh, L.A. Zadeh (Eds.), Feature extraction: foundations and applications, Studies in fuzziness and soft computing, Springer (2006), pp. 265-295
Neftci et al., 2014
E. Neftci, S. Das, B. Pedroni, K. Kreutz-Delgado, G. Cauwenberghs
Event-driven contrastive divergence for spiking neuromorphic systems
Frontiers in Neuroscience, 7 (272) (2014)
Neil and Liu, 2014
D. Neil, S.-C. Liu
Minitaur, an event-driven FPGA-based spiking network accelerator
IEEE Transactions on Very Large Scale Integration (VLSI) Systems, PP (99) (2014), pp. 1-8
Nessler et al., 2013
B. Nessler, M. Pfeiffer, L. Buesing, W. Maass
Bayesian computation emerges in generic cortical microcircuits through spike-timing-dependent plasticity
PLoS Computational Biology, 9 (4) (2013), p. e1003037
Neti et al., 1992
C. Neti, M.H. Schneider, E.D. Young
Maximally fault tolerant neural networks
IEEE Transactions on Neural Networks, 3 (1992), pp. 14-23
Neuneier and Zimmermann, 1996
R. Neuneier, H.-G. Zimmermann
How to train neural networks
G.B. Orr, K.-R. Muller (Eds.), Neural networks: tricks of the trade, Lecture notes in computer science, Vol. 1524, Springer (1996), pp. 373-423
Newton, 1687
I. Newton
Philosophiae naturalis principia mathematica
William Dawson & Sons Ltd, London (1687)
Nguyen and Widrow, 1989
N. Nguyen, B. Widrow
The truck backer-upper: An example of self learning in neural networks
Proceedings of the international joint conference on neural networks, IEEE Press (1989), pp. 357-363
Nilsson, 1980
N.J. Nilsson
Principles of artificial intelligence
Morgan Kaufmann, San Francisco, CA, USA (1980)
Nolfi, Floreano, et al., 1994
S. Nolfi, D. Floreano, O. Miglino, F. Mondada
How to evolve autonomous robots: Different approaches in evolutionary robotics
R.A. Brooks, P. Maes (Eds.), Fourth international workshop on the synthesis and simulation of living systems (artificial life IV), MIT (1994), pp. 190-197
Nolfi, Parisi, et al., 1994
S. Nolfi, D. Parisi, J.L. Elman
Learning and evolution in neural networks
Adaptive Behavior, 3 (1) (1994), pp. 5-28
Nowak et al., 2006
E. Nowak, F. Jurie, B. Triggs
Sampling strategies for bag-of-features image classification
Proc. ECCV 2006, Springer (2006), pp. 490-503
Nowlan and Hinton, 1992
S.J. Nowlan, G.E. Hinton
Simplifying neural networks by soft weight sharing
Neural Computation, 4 (1992), pp. 173-193
O¡¯Connor et al., 2013
P. O¡¯Connor, D. Neil, S.-C. Liu, T. Delbruck, M. Pfeiffer
Real-time classification and sensor fusion with a spiking deep belief network
Frontiers in Neuroscience, 7 (178) (2013)
Oh and Jung, 2004
K.-S. Oh, K. Jung
GPU implementation of neural networks
Pattern Recognition, 37 (6) (2004), pp. 1311-1314
ArticleDownload PDF
Oja, 1989
E. Oja
Neural networks, principal components, and subspaces
International Journal of Neural Systems, 1 (1) (1989), pp. 61-68
Oja, 1991
E. Oja
Data compression, feature extraction, and autoassociation in feedforward neural networks
T. Kohonen, K. Makisara, O. Simula, J. Kangas (Eds.), Artificial neural networks, vol. 1, Elsevier Science Publishers BV, North-Holland (1991), pp. 737-745
Olshausen and Field, 1996
B.A. Olshausen, D.J. Field
Emergence of simple-cell receptive field properties by learning a sparse code for natural images
Nature, 381 (6583) (1996), pp. 607-609
Omlin and Giles, 1996
C. Omlin, C.L. Giles
Extraction of rules from discrete-time recurrent neural networks
Neural Networks, 9 (1) (1996), pp. 41-52
ArticleDownload PDF
Oquab et al., 2013
M. Oquab, L. Bottou, I. Laptev, J. Sivic
Learning and transferring mid-level image representations using convolutional neural networks. Technical report hal-00911179
(2013)
O¡¯Reilly, 1996
R.C. O¡¯Reilly
Biologically plausible error-driven learning using local activation differences: The generalized recirculation algorithm
Neural Computation, 8 (5) (1996), pp. 895-938
O¡¯Reilly, 2003
R. O¡¯Reilly
Making working memory work: A computational model of learning in the prefrontal cortex and basal ganglia. Technical report ICS-03-03
ICS (2003)
O¡¯Reilly et al., 2013
R.C. O¡¯Reilly, D. Wyatte, S. Herd, B. Mingus, D.J. Jilk
Recurrent processing during object recognition
Frontiers in Psychology, 4 (2013), p. 124
Orr and Muller, 1998
G. Orr, K. Muller
Neural networks: tricks of the trade, Lecture Notes in Computer Science Series. LNCS, Vol. 1524, Springer Verlag (1998)
Ostrovskii et al., 1971
G.M. Ostrovskii, Y.M. Volin, W.W. Borisov
Uber die Berechnung von Ableitungen
Wissenschaftliche Zeitschrift der Technischen Hochschule fur Chemie, 13 (1971), pp. 382-384
Otsuka, 2010
M. Otsuka
Goal-oriented representation of the external world: a free-energy-based approach
(Ph.D. thesis)
Nara Institute of Science and Technology (2010)
Otsuka et al., 2010
Otsuka, M., Yoshimoto, J., & Doya, K. (2010). Free-energy-based reinforcement learning in a partially observable environment. In Proc. ESANN.
Otte et al., 2012
S. Otte, D. Krechel, M. Liwicki, A. Dengel
Local feature based online mode detection with recurrent neural networks
Proceedings of the 2012 international conference on Frontiers in handwriting recognition, IEEE Computer Society (2012), pp. 533-537
Oudeyer et al., 2013
P.-Y. Oudeyer, A. Baranes, F. Kaplan
Intrinsically motivated learning of real world sensorimotor skills with developmental constraints
G. Baldassarre, M. Mirolli (Eds.), Intrinsically motivated learning in natural and artificial systems, Springer (2013)
Pachitariu and Sahani, 2013
Pachitariu, M., & Sahani, M. (2013). Regularization and nonlinearities for neural language models: when are they needed? arXiv Preprint arXiv:1301.5650.
Palm, 1980
G. Palm
On associative memory
Biological Cybernetics, 36 (1980)
Palm, 1992
G. Palm
On the information storage capacity of local learning rules
Neural Computation, 4 (2) (1992), pp. 703-711
Pan and Yang, 2010
S.J. Pan, Q. Yang
A survey on transfer learning
The IEEE Transactions on Knowledge and Data Engineering, 22 (10) (2010), pp. 1345-1359
Parekh et al., 2000
R. Parekh, J. Yang, V. Honavar
Constructive neural network learning algorithms for multi-category pattern classification
IEEE Transactions on Neural Networks, 11 (2) (2000), pp. 436-451
Parker, 1985
D.B. Parker
Learning-logic. Technical report TR-47
Center for Comp. Research in Economics and Management Sci., MIT (1985)
Pascanu, Gulcehre, et al., 2013
Pascanu, R., Gulcehre, C., Cho, K., & Bengio, Y. (2013). How to construct deep recurrent neural networks. arXiv Preprint arXiv:1312.6026.
Pascanu, Mikolov, et al., 2013
Pascanu, R., Mikolov, T., & Bengio, Y. (2013). On the difficulty of training recurrent neural networks. In ICML¡¯13: JMLR: W&CP, vol. 28.
Pasemann et al., 1999
F. Pasemann, U. Steinmetz, U. Dieckman
Evolving structure and function of neurocontrollers
P.J. Angeline, Z. Michalewicz, M. Schoenauer, X. Yao, A. Zalzala (Eds.), Proceedings of the congress on evolutionary computation, vol. 3, IEEE Press, Mayflower Hotel, Washington, DC, USA (1999), pp. 1973-1978
Pearlmutter, 1989
B.A. Pearlmutter
Learning state space trajectories in recurrent neural networks
Neural Computation, 1 (2) (1989), pp. 263-269
Pearlmutter, 1994
B.A. Pearlmutter
Fast exact multiplication by the Hessian
Neural Computation, 6 (1) (1994), pp. 147-160
Pearlmutter, 1995
B.A. Pearlmutter
Gradient calculations for dynamic recurrent neural networks: A survey
IEEE Transactions on Neural Networks, 6 (5) (1995), pp. 1212-1228
Pearlmutter and Hinton, 1986
Pearlmutter, B. A., & Hinton, G. E. (1986). -maximization: An unsupervised learning procedure for discovering regularities. In Denker, J.S., (Ed.), Neural networks for computing: American institute of physics conference proceedings 151, vol. 2 (pp. 333?338).
Peng and Williams, 1996
J. Peng, R.J. Williams
Incremental multi-step Q-learning
Machine Learning, 22 (1996), pp. 283-290
Perez-Ortiz et al., 2003
J.A. Perez-Ortiz, F.A. Gers, D. Eck, J. Schmidhuber
Kalman filters improve LSTM network performance in problems unsolvable by traditional recurrent nets
Neural Networks (16) (2003), pp. 241-250
ArticleDownload PDF
Perrett et al., 1992
D. Perrett, J. Hietanen, M. Oram, P. Benson, E. Rolls
Organization and functions of cells responsive to faces in the temporal cortex [and discussion]
Philosophical Transactions of the Royal Society of London. Series B: Biological Sciences, 335 (1273) (1992), pp. 23-30
Perrett et al., 1982
D. Perrett, E. Rolls, W. Caan
Visual neurones responsive to faces in the monkey temporal cortex
Experimental Brain Research, 47 (3) (1982), pp. 329-342
Peters, 2010
J. Peters
Policy gradient methods
Scholarpedia, 5 (11) (2010), p. 3698
Peters and Schaal, 2008a
J. Peters, S. Schaal
Natural actor-critic
Neurocomputing, 71 (2008), pp. 1180-1190
ArticleDownload PDF
Peters and Schaal, 2008b
J. Peters, S. Schaal
Reinforcement learning of motor skills with policy gradients
Neural Networks, 21 (4) (2008), pp. 682-697
ArticleDownload PDF
Pham et al., 2013
Pham, V., Kermorvant, C., & Louradour, J. (2013). Dropout improves recurrent neural networks for handwriting recognition. arXiv Preprint arXiv:1312.4569.
Pineda, 1987
F.J. Pineda
Generalization of back-propagation to recurrent neural networks
Physical Review Letters, 19 (59) (1987), pp. 2229-2232
Plate, 1993
T.A. Plate
Holographic recurrent networks
S.J. Hanson, J.D. Cowan, C.L. Giles (Eds.), Advances in neural information processing systems (NIPS), vol. 5, Morgan Kaufmann (1993), pp. 34-41
Plumbley, 1991
M.D. Plumbley
On information theory and unsupervised neural networks. Dissertation, published as Technical report CUED/F-INFENG/TR.78
Engineering Department, Cambridge University (1991)
Pollack, 1988
Pollack, J. B. (1988). Implications of recursive distributed representations. In Proc. NIPS (pp. 527?536).
Pollack, 1990
J.B. Pollack
Recursive distributed representation
Artificial Intelligence, 46 (1990), pp. 77-105
ArticleDownload PDF
Pontryagin et al., 1961
L.S. Pontryagin, V.G. Boltyanskii, R.V. Gamrelidze, E.F. Mishchenko
The mathematical theory of optimal processes
(1961)
Poon and Domingos, 2011
H. Poon, P. Domingos
Sum?product networks: A new deep architecture
IEEE International conference on computer vision workshops, IEEE (2011), pp. 689-690
Post, 1936
E.L. Post
Finite combinatory processes-formulation 1
The Journal of Symbolic Logic, 1 (3) (1936), pp. 103-105
Prasoon et al., 2013
A. Prasoon, K. Petersen, C. Igel, F. Lauze, E. Dam, M. Nielsen
Voxel classification based on triplanar convolutional neural networks applied to cartilage segmentation in knee MRI
Medical image computing and computer assisted intervention (MICCAI), LNCS, Vol. 8150, Springer (2013), pp. 246-253
Precup et al., 1998
D. Precup, R.S. Sutton, S. Singh
Multi-time models for temporally abstract planning
Advances in neural information processing systems (NIPS), Morgan Kaufmann (1998), pp. 1050-1056
Prokhorov, 2010
D. Prokhorov
A convolutional learning system for object classification in 3-D LIDAR data
IEEE Transactions on Neural Networks, 21 (5) (2010), pp. 858-863
Prokhorov et al., 2002
Prokhorov, D. V., Feldkamp, L. A., & Tyukin, I. Y. (2002). Adaptive behavior with fixed weights in RNN: an overview. In Proceedings of the IEEE international joint conference on neural networks (pp. 2018?2023).
Prokhorov et al., 2001
D. Prokhorov, G. Puskorius, L. Feldkamp
Dynamical neural networks for control
J. Kolen, S. Kremer (Eds.), A field guide to dynamical recurrent networks, IEEE Press (2001), pp. 23-78
Prokhorov and Wunsch, 1997
D. Prokhorov, D. Wunsch
Adaptive critic design
IEEE Transactions on Neural Networks, 8 (5) (1997), pp. 997-1007
Puskorius and Feldkamp, 1994
G.V. Puskorius, L.A. Feldkamp
Neurocontrol of nonlinear dynamical systems with Kalman filter trained recurrent networks
IEEE Transactions on Neural Networks, 5 (2) (1994), pp. 279-297
Raiko et al., 2012
Raiko, T., Valpola, H., & LeCun, Y. (2012). Deep learning made easier by linear transformations in perceptrons. In International conference on artificial intelligence and statistics (pp. 924?932).
Raina et al., 2009
R. Raina, A. Madhavan, A. Ng
Large-scale deep unsupervised learning using graphics processors
Proceedings of the 26th annual International conference on machine learning, ACM (2009), pp. 873-880
Ramacher et al., 1993
U. Ramacher, W. Raab, J. Anlauf, U. Hachmann, J. Beichter, N. Bruels, et al.
Multiprocessor and memory architecture of the neurocomputer SYNAPSE-1
International Journal of Neural Systems, 4 (4) (1993), pp. 333-336
Ranzato et al., 2007
M.A. Ranzato, F. Huang, Y. Boureau, Y. LeCun
Unsupervised learning of invariant feature hierarchies with applications to object recognition
Proc. computer vision and pattern recognition conference, IEEE Press (2007), pp. 1-8
Ranzato et al., 2006
M. Ranzato, C. Poultney, S. Chopra, Y. LeCun
Efficient learning of sparse representations with an energy-based model
J. Platt, et al. (Eds.), Advances in neural information processing systems (NIPS 2006), MIT Press (2006)
Rauber et al., 2002
A. Rauber, D. Merkl, M. Dittenbach
The growing hierarchical self-organizing map: exploratory analysis of high-dimensional data
IEEE Transactions on Neural Networks, 13 (6) (2002), pp. 1331-1341
Razavian et al., 2014
Razavian, A. S., Azizpour, H., Sullivan, J., & Carlsson, S. (2014). CNN features off-the-shelf: an astounding baseline for recognition. ArXiv Preprint arXiv:1403.6382.
Rechenberg, 1971
I. Rechenberg
Evolutionsstrategie?optimierung technischer systeme nach prinzipien der biologischen evolution
(Dissertation)
(1971)
Published 1973 by Fromman-Holzboog
Redlich, 1993
A.N. Redlich
Redundancy reduction as a strategy for unsupervised learning
Neural Computation, 5 (1993), pp. 289-304
Refenes et al., 1994
N.A. Refenes, A. Zapranis, G. Francis
Stock performance modeling using neural networks: a comparative study with regression models
Neural Networks, 7 (2) (1994), pp. 375-388
Rezende and Gerstner, 2014
D.J. Rezende, W. Gerstner
Stochastic variational learning in recurrent spiking networks
Frontiers in Computational Neuroscience, 8 (2014), p. 38
Riedmiller, 2005
M. Riedmiller
Neural fitted Q iteration?first experiences with a data efficient neural reinforcement learning method
Proc. ECML-2005, Springer-Verlag, Berlin, Heidelberg (2005), pp. 317-328
Riedmiller and Braun, 1993
M. Riedmiller, H. Braun
A direct adaptive method for faster backpropagation learning: The Rprop algorithm
Proc. IJCNN, IEEE Press (1993), pp. 586-591
Riedmiller et al., 2012
Riedmiller, M., Lange, S., & Voigtlaender, A. (2012). Autonomous reinforcement learning on raw visual input data in a real world application. In International joint conference on neural networks (pp. 1?8).
Riesenhuber and Poggio, 1999
M. Riesenhuber, T. Poggio
Hierarchical models of object recognition in cortex
Nature Neuroscience, 2 (11) (1999), pp. 1019-1025
Rifai et al., 2011
Rifai, S., Vincent, P., Muller, X., Glorot, X., & Bengio, Y. (2011). Contractive auto-encoders: Explicit invariance during feature extraction. In Proceedings of the 28th international conference on machine learning (pp. 833?840).
Ring, 1991
M.B. Ring
Incremental development of complex behaviors through automatic construction of sensory-motor hierarchies
L. Birnbaum, G. Collins (Eds.), Machine learning: proceedings of the eighth international workshop, Morgan Kaufmann (1991), pp. 343-347
ArticleDownload PDF
Ring, 1993
M.B. Ring
Learning sequential tasks by incrementally adding higher orders
S.J. Hanson, J.D. Cowan, C.L. Giles (Eds.), Advances in neural information processing systems, vol. 5, Morgan Kaufmann (1993), pp. 115-122
Ring, 1994
M.B. Ring
Continual learning in reinforcement environments
(Ph.D. thesis)
University of Texas at Austin, Austin, Texas 78712 (1994)
Ring et al., 2011
Ring, M., Schaul, T., & Schmidhuber, J. (2011). The two-dimensional organization of behavior. In Proceedings of the first joint conference on development learning and on epigenetic robotics.
Risi and Stanley, 2012
S. Risi, K.O. Stanley
A unified approach to evolving plasticity and neural geometry
International joint conference on neural networks, IEEE (2012), pp. 1-8
Rissanen, 1986
J. Rissanen
Stochastic complexity and modeling
The Annals of Statistics, 14 (3) (1986), pp. 1080-1100
Ritter and Kohonen, 1989
H. Ritter, T. Kohonen
Self-organizing semantic maps
Biological Cybernetics, 61 (4) (1989), pp. 241-254
Robinson and Fallside, 1987
A.J. Robinson, F. Fallside
The utility driven dynamic error propagation network. Technical report CUED/F-INFENG/TR.1
Cambridge University Engineering Department (1987)
Robinson and Fallside, 1989
Robinson, T., & Fallside, F. (1989). Dynamic reinforcement driven error propagation networks with application to game playing. In Proceedings of the 11th conference of the cognitive science society (pp. 836?843).
Rodriguez and Wiles, 1998
P. Rodriguez, J. Wiles
Recurrent neural networks can learn to implement symbol-sensitive counting
Advances in neural information processing systems (NIPS), vol. 10, The MIT Press (1998), pp. 87-93
Rodriguez et al., 1999
P. Rodriguez, J. Wiles, J. Elman
A recurrent neural network that learns to count
Connection Science, 11 (1) (1999), pp. 5-40
Roggen et al., 2003
D. Roggen, S. Hofmann, Y. Thoma, D. Floreano
Hardware spiking neural network with run-time reconfigurable connectivity in an autonomous robot
Proc. NASA/DoD conference on evolvable hardware, IEEE (2003), pp. 189-198
Rohwer, 1989
R. Rohwer
The ¡®moving targets¡¯ training method
J. Kindermann, A. Linden (Eds.), Proceedings of ¡®distributed adaptive neural information processing¡¯, Oldenbourg (1989)
Rosenblatt, 1958
F. Rosenblatt
The perceptron: a probabilistic model for information storage and organization in the brain
Psychological Review, 65 (6) (1958), p. 386
Rosenblatt, 1962
F. Rosenblatt
Principles of neurodynamics
Spartan, New York (1962)
Roux et al., 2013
L. Roux, D. Racoceanu, N. Lomenie, M. Kulikova, H. Irshad, J. Klossa, et al.
Mitosis detection in breast cancer histological images?an ICPR 2012 contest
Journal of Pathology Informatics, 4 (2013), p. 8
Rubner and Schulten, 1990
J. Rubner, K. Schulten
Development of feature detectors by self-organization: A network model
Biological Cybernetics, 62 (1990), pp. 193-199
Ruckstie©¬ et al., 2008
T. Ruckstie©¬, M. Felder, J. Schmidhuber
State-dependent exploration for policy gradient methods
W. Daelemans, et al. (Eds.), European conference on machine learning (ECML) and principles and practice of knowledge discovery in databases 2008, part II, LNAI, Vol. 5212 (2008), pp. 234-249
Rumelhart et al., 1986
D.E. Rumelhart, G.E. Hinton, R.J. Williams
Learning internal representations by error propagation
D.E. Rumelhart, J.L. McClelland (Eds.), Parallel distributed processing, vol. 1, MIT Press (1986), pp. 318-362
Rumelhart and Zipser, 1986
D.E. Rumelhart, D. Zipser
Feature discovery by competitive learning
Parallel distributed processing, MIT Press (1986), pp. 151-193
Rummery and Niranjan, 1994
G. Rummery, M. Niranjan
On-line Q-learning using connectionist sytems. Technical report CUED/F-INFENG-TR 166
Cambridge University, UK (1994)
Russell et al., 1995
S.J. Russell, P. Norvig, J.F. Canny, J.M. Malik, D.D. Edwards
Artificial intelligence: a modern approach, vol. 2
Prentice Hall, Englewood Cliffs (1995)
Saito and Nakano, 1997
K. Saito, R. Nakano
Partial BFGS update and efficient step-length calculation for three-layer neural networks
Neural Computation, 9 (1) (1997), pp. 123-141
Sak, Senior, et al., 2014
Sak, H., Senior, A., & Beaufays, F. (2014). Long short-term memory recurrent neural network architectures for large scale acoustic modeling. In Proc. interspeech.
Sak, Vinyals, et al., 2014
Sak, H., Vinyals, O., Heigold, G., Senior, A., McDermott, E., & Monga, R., et al. (2014). Sequence discriminative distributed training of long short-term memory recurrent neural networks. In Proc. Interspeech.
Salakhutdinov and Hinton, 2009
R. Salakhutdinov, G. Hinton
Semantic hashing
International Journal of Approximate Reasoning, 50 (7) (2009), pp. 969-978
ArticleDownload PDF
Sallans and Hinton, 2004
B. Sallans, G. Hinton
Reinforcement learning with factored states and actions
Journal of Machine Learning Research, 5 (2004), pp. 1063-1088
Sa©©ustowicz and Schmidhuber, 1997
R.P. Sa©©ustowicz, J. Schmidhuber
Probabilistic incremental program evolution
Evolutionary Computation, 5 (2) (1997), pp. 123-141
Samejima et al., 2003
K. Samejima, K. Doya, M. Kawato
Inter-module credit assignment in modular reinforcement learning
Neural Networks, 16 (7) (2003), pp. 985-994
ArticleDownload PDF
Samuel, 1959
A.L. Samuel
Some studies in machine learning using the game of checkers
IBM Journal of Research and Development, 3 (1959), pp. 210-229
Sanger, 1989
T.D. Sanger
An optimality principle for unsupervised learning
D.S. Touretzky (Ed.), Advances in neural information processing systems (NIPS), vol. 1, Morgan Kaufmann (1989), pp. 11-19
Santamaria et al., 1997
J.C. Santamaria, R.S. Sutton, A. Ram
Experiments with reinforcement learning in problems with continuous state and action spaces
Adaptive Behavior, 6 (2) (1997), pp. 163-217
Saravanan and Fogel, 1995
N. Saravanan, D.B. Fogel
Evolving neural control systems
IEEE Expert (1995), pp. 23-27
Saund, 1994
E. Saund
Unsupervised learning of mixtures of multiple causes in binary data
J.D. Cowan, G. Tesauro, J. Alspector (Eds.), Advances in neural information processing systems (NIPS), vol. 6, Morgan Kaufmann (1994), pp. 27-34
Schaback and Werner, 1992
R. Schaback, H. Werner
Numerische mathematik, vol. 4
Springer (1992)
Schafer et al., 2006
A.M. Schafer, S. Udluft, H.-G. Zimmermann
Learning long term dependencies with recurrent neural networks
S.D. Kollias, A. Stafylopatis, W. Duch, E. Oja (Eds.), ICANN (1), Lecture notes in computer science, Vol. 4131, Springer (2006), pp. 71-80
Schapire, 1990
R.E. Schapire
The strength of weak learnability
Machine Learning, 5 (1990), pp. 197-227
Schaul and Schmidhuber, 2010
T. Schaul, J. Schmidhuber
Metalearning
Scholarpedia, 6 (5) (2010), p. 4650
Schaul et al., 2013
Schaul, T., Zhang, S., & LeCun, Y. (2013). No more pesky learning rates. In Proc. 30th International conference on machine learning.
Schemmel et al., 2006
J. Schemmel, A. Grubl, K. Meier, E. Mueller
Implementing synaptic plasticity in a VLSI spiking neural network model
International joint conference on neural networks, IEEE (2006), pp. 1-6
Scherer et al., 2010
Scherer, D., Muller, A., & Behnke, S. (2010). Evaluation of pooling operations in convolutional architectures for object recognition. In Proc. International conference on artificial neural networks (pp. 92?101).
Schmidhuber, 1987
J. Schmidhuber
Evolutionary principles in self-referential learning, or on learning how to learn: the meta-meta-... hook
(Diploma thesis)
Inst. f. Inf., Tech. Univ. Munich (1987)
http://www.idsia.ch/~juergen/diploma.html
Schmidhuber, 1989a
J. Schmidhuber
Accelerated learning in back-propagation nets
R. Pfeifer, Z. Schreter, Z. Fogelman, L. Steels (Eds.), Connectionism in perspective, Elsevier, North-Holland, Amsterdam (1989), pp. 429-438
Schmidhuber, 1989b
J. Schmidhuber
A local learning algorithm for dynamic feedforward and recurrent networks
Connection Science, 1 (4) (1989), pp. 403-412
Schmidhuber, 1990a
J. Schmidhuber
Dynamische neuronale Netze und das fundamentale raumzeitliche Lernproblem. (Dynamic neural nets and the fundamental spatio-temporal credit assignment problem.)
(Dissertation)
Inst. f. Inf., Tech. Univ. Munich (1990)
Schmidhuber, 1990b
J. Schmidhuber
Learning algorithms for networks with internal and external feedback
D.S. Touretzky, J.L. Elman, T.J. Sejnowski, G.E. Hinton (Eds.), Proc. of the 1990 connectionist models summer school, Morgan Kaufmann (1990), pp. 52-61
Schmidhuber, 1990c
Schmidhuber, J. (1990c). The neural heat exchanger. Talks at TU Munich (1990), University of Colorado at Boulder (1992), and Z. Li¡¯s NIPS*94 workshop on unsupervised learning. Also published at the Intl. conference on neural information processing, vol. 1 (pp. 194?197), 1996.
Schmidhuber, 1990d
Schmidhuber, J. (1990d). An on-line algorithm for dynamic reinforcement learning and planning in reactive environments. In Proc. IEEE/INNS international joint conference on neural networks, vol. 2 (pp. 253?258).
Schmidhuber, 1991a
J. Schmidhuber
Curious model-building control systems
Proceedings of the international joint conference on neural networks, vol. 2, IEEE Press (1991), pp. 1458-1463
Schmidhuber, 1991b
J. Schmidhuber
Learning to generate sub-goals for action sequences
T. Kohonen, K. Makisara, O. Simula, J. Kangas (Eds.), Artificial neural networks, Elsevier Science Publishers BV, North-Holland (1991), pp. 967-972
Schmidhuber, 1991c
J. Schmidhuber
Reinforcement learning in Markovian and non-Markovian environments
D.S. Lippman, J.E. Moody, D.S. Touretzky (Eds.), Advances in neural information processing systems, vol. 3 (NIPS 3), Morgan Kaufmann (1991), pp. 500-506
Schmidhuber, 1992a
J. Schmidhuber
A fixed size storage  time complexity learning algorithm for fully recurrent continually running networks
Neural Computation, 4 (2) (1992), pp. 243-248
Schmidhuber, 1992b
J. Schmidhuber
Learning complex, extended sequences using the principle of history compression
Neural Computation, 4 (2) (1992), pp. 234-242
Based on TR FKI-148-91, TUM, 1991
Schmidhuber, 1992c
J. Schmidhuber
Learning factorial codes by predictability minimization
Neural Computation, 4 (6) (1992), pp. 863-879
Schmidhuber, 1993a
J. Schmidhuber
An introspective network that can learn to run its own weight change algorithm
Proc. of the intl. conf. on artificial neural networks, Brighton, IEE (1993), pp. 191-195
Schmidhuber, 1993b
J. Schmidhuber
Netzwerkarchitekturen, Zielfunktionen und Kettenregel. (Network architectures, objective functions, and chain rule.)
(Habilitation thesis)
Inst. f. Inf., Tech. Univ. Munich (1993)
Schmidhuber, 1997
J. Schmidhuber
Discovering neural nets with low Kolmogorov complexity and high generalization capability
Neural Networks, 10 (5) (1997), pp. 857-873
ArticleDownload PDF
Schmidhuber, 2002
J. Schmidhuber
The speed prior: a new simplicity measure yielding near-optimal computable predictions
J. Kivinen, R.H. Sloan (Eds.), Proceedings of the 15th annual conference on computational learning theory, Lecture notes in artificial intelligence, Springer, Sydney, Australia (2002), pp. 216-228
Schmidhuber, 2004
J. Schmidhuber
Optimal ordered problem solver
Machine Learning, 54 (2004), pp. 211-254
Schmidhuber, 2006a
J. Schmidhuber
Developmental robotics, optimal artificial curiosity, creativity, music, and the fine arts
Connection Science, 18 (2) (2006), pp. 173-187
Schmidhuber, 2006b
J. Schmidhuber
Godel machines: Fully self-referential optimal universal self-improvers
B. Goertzel, C. Pennachin (Eds.), Artificial general intelligence, Springer Verlag (2006), pp. 199-226
Variant available as arXiv:cs.LO/0309048
Schmidhuber, 2007
J. Schmidhuber
Prototype resilient, self-modeling robots
Science, 316 (5825) (2007), p. 688
Schmidhuber, 2012
J. Schmidhuber
Self-delimiting neural networks. Technical report IDSIA-08-12
The Swiss AI Lab IDSIA (2012)
arXiv:1210.0118v1 [cs.NE]
Schmidhuber, 2013a
J. Schmidhuber
My first deep learning system of 1991 + deep learning timeline 1962?2013. Technical report
The Swiss AI Lab IDSIA (2013)
arXiv:1312.5548v1 [cs.NE]
Schmidhuber, 2013b
J. Schmidhuber
PowerPlay: training an increasingly general problem solver by continually searching for the simplest still unsolvable problem
Frontiers in Psychology (2013)
Schmidhuber et al., 2011
Schmidhuber, J., Ciresan, D., Meier, U., Masci, J., & Graves, A. (2011). On fast deep nets for AGI vision. In Proc. fourth conference on artificial general intelligence (pp. 243?246).
Schmidhuber et al., 1996
J. Schmidhuber, M. Eldracher, B. Foltin
Semilinear predictability minimization produces well-known feature detectors
Neural Computation, 8 (4) (1996), pp. 773-786
Schmidhuber and Huber, 1991
J. Schmidhuber, R. Huber
Learning to generate artificial fovea trajectories for target detection
International Journal of Neural Systems, 2 (1 and 2) (1991), pp. 135-141
Schmidhuber et al., 1993
J. Schmidhuber, M.C. Mozer, D. Prelinger
Continuous history compression
H. Huning, S. Neuhauser, M. Raus, W. Ritschel (Eds.), Proc. of intl. workshop on neural networks, RWTH Aachen, Augustinus (1993), pp. 87-95
Schmidhuber and Prelinger, 1992
J. Schmidhuber, D. Prelinger
Discovering predictable classifications. Technical report CU-CS-626-92
Dept. of Comp. Sci., University of Colorado at Boulder (1992)
Published in Neural Computation 5 (4) (1993) 625?635
Schmidhuber and Wahnsiedler, 1992
J. Schmidhuber, R. Wahnsiedler
Planning simple trajectories using neural subgoal generators
J.A. Meyer, H.L. Roitblat, S.W. Wilson (Eds.), Proc. of the 2nd international conference on simulation of adaptive behavior, MIT Press (1992), pp. 196-202
Schmidhuber et al., 2007
J. Schmidhuber, D. Wierstra, M. Gagliolo, F.J. Gomez
Training recurrent networks by Evolino
Neural Computation, 19 (3) (2007), pp. 757-779
Schmidhuber, Zhao, and Schraudolph, 1997
J. Schmidhuber, J. Zhao, N. Schraudolph
Reinforcement learning with self-modifying policies
S. Thrun, L. Pratt (Eds.), Learning to learn, Kluwer (1997), pp. 293-309
Schmidhuber, Zhao, and Wiering, 1997
J. Schmidhuber, J. Zhao, M. Wiering
Shifting inductive bias with success-story algorithm, adaptive Levin search, and incremental self-improvement
Machine Learning, 28 (1997), pp. 105-130
Scholkopf et al., 1998
B. Scholkopf, C.J.C. Burges, A.J. Smola (Eds.), Advances in kernel methods?support vector learning, MIT Press, Cambridge, MA (1998)
Schraudolph, 2002
N.N. Schraudolph
Fast curvature matrix?vector products for second-order gradient descent
Neural Computation, 14 (7) (2002), pp. 1723-1738
Schraudolph and Sejnowski, 1993
N. Schraudolph, T.J. Sejnowski
Unsupervised discrimination of clustered data via optimization of binary information gain
S.J. Hanson, J.D. Cowan, C.L. Giles (Eds.), Advances in neural information processing systems, vol. 5, Morgan Kaufmann, San Mateo (1993), pp. 499-506
Schraudolph and Sejnowski, 1996
N.N. Schraudolph, T.J. Sejnowski
Tempering backpropagation networks: not all weights are created equal
D.S. Touretzky, M.C. Mozer, M.E. Hasselmo (Eds.), Advances in neural information processing systems (NIPS), vol. 8, The MIT Press, Cambridge, MA (1996), pp. 563-569
Schrauwen et al., 2007
Schrauwen, B., Verstraeten, D., & Van Campenhout, J. (2007). An overview of reservoir computing: theory, applications and implementations. In Proceedings of the 15th European symposium on artificial neural networks (pp. 471?482).
Schuster, 1992
H.G. Schuster
Learning by maximization the information transfer through nonlinear noisy neurons and ¡°noise breakdown¡±
Physical Review A, 46 (4) (1992), pp. 2131-2138
Schuster, 1999
M. Schuster
On supervised learning from sequential data with applications for speech recognition
(Ph.D. thesis)
Nara Institute of Science and Technolog, Kyoto, Japan (1999)
Schuster and Paliwal, 1997
M. Schuster, K.K. Paliwal
Bidirectional recurrent neural networks
IEEE Transactions on Signal Processing, 45 (1997), pp. 2673-2681
Schwartz, 1993
Schwartz, A. (1993). A reinforcement learning method for maximizing undiscounted rewards. In Proc. ICML (pp. 298?305).
Schwefel, 1974
H.P. Schwefel
Numerische optimierung von computer-modellen
(Dissertation)
(1974)
Published 1977 by Birkhauser, Basel
Segmentation of Neuronal Structures in EM Stacks Challenge, 2012
Segmentation of Neuronal Structures in EM Stacks Challenge,  (2012). IEEE International symposium on biomedical imaging. http://tinyurl.com/d2fgh7g.
Sehnke et al., 2010
F. Sehnke, C. Osendorfer, T. Ruckstie©¬, A. Graves, J. Peters, J. Schmidhuber
Parameter-exploring policy gradients
Neural Networks, 23 (4) (2010), pp. 551-559
ArticleDownload PDF
Sermanet et al., 2013
Sermanet, P., Eigen, D., Zhang, X., Mathieu, M., Fergus, R., & LeCun, Y. (2013). OverFeat: integrated recognition, localization and detection using convolutional networks. ArXiv Preprint arXiv:1312.6229.
Sermanet and LeCun, 2011
Sermanet, P., & LeCun, Y. (2011). Traffic sign recognition with multi-scale convolutional networks. In Proceedings of international joint conference on neural networks (pp. 2809?2813).
Serrano-Gotarredona et al., 2009
R. Serrano-Gotarredona, M. Oster, P. Lichtsteiner, A. Linares-Barranco, R. Paz-Vicente, F. Gomez-Rodriguez, et al.
Caviar: A 45 k neuron, 5 m synapse, 12 g connects/s AER hardware sensory?processing?learning?actuating system for high-speed visual object recognition and tracking
IEEE Transactions on Neural Networks, 20 (9) (2009), pp. 1417-1438
Serre et al., 2002
T. Serre, M. Riesenhuber, J. Louie, T. Poggio
On the role of object-specific features for real world object recognition in biological vision
Biologically motivated computer vision (2002), pp. 387-397
Seung, 2003
H.S. Seung
Learning in spiking neural networks by reinforcement of stochastic synaptic transmission
Neuron, 40 (6) (2003), pp. 1063-1073
ArticleDownload PDF
Shan and Cottrell, 2014
Shan, H., & Cottrell, G. (2014). Efficient visual coding: From retina to V2. In Proc. international conference on learning representations. ArXiv Preprint arXiv:1312.6077.
Shan et al., 2007
H. Shan, L. Zhang, G.W. Cottrell
Recursive ICA
Advances in neural information processing systems (NIPS), vol. 19 (2007), p. 1273
Shanno, 1970
D.F. Shanno
Conditioning of quasi-Newton methods for function minimization
Mathematics of Computation, 24 (111) (1970), pp. 647-656
Shannon, 1948
C.E. Shannon
A mathematical theory of communication (parts I and II)
Bell System Technical Journal, XXVII (1948), pp. 379-423
Shao et al., 2014
L. Shao, D. Wu, X. Li
Learning deep and wide: A spectral method for learning deep networks
IEEE Transactions on Neural Networks and Learning Systems (2014)
Shavlik, 1994
J.W. Shavlik
Combining symbolic and neural learning
Machine Learning, 14 (3) (1994), pp. 321-331
Shavlik and Towell, 1989
J.W. Shavlik, G.G. Towell
Combining explanation-based and neural learning: An algorithm and empirical results
Connection Science, 1 (3) (1989), pp. 233-255
Siegelmann, 1992
H. Siegelmann
Theoretical foundations of recurrent neural networks
(Ph.D. thesis)
Rutgers, New Brunswick Rutgers, The State of New Jersey (1992)
Siegelmann and Sontag, 1991
H.T. Siegelmann, E.D. Sontag
Turing computability with neural nets
Applied Mathematics Letters, 4 (6) (1991), pp. 77-80
ArticleDownload PDF
Silva and Almeida, 1990
F.M. Silva, L.B. Almeida
Speeding up back-propagation
R. Eckmiller (Ed.), Advanced neural computers, Elsevier, Amsterdam (1990), pp. 151-158
ArticleDownload PDF
Sima, 1994
J. Sima
Loading deep networks is hard
Neural Computation, 6 (5) (1994), pp. 842-850
Sima, 2002
J. Sima
Training a single sigmoidal neuron is hard
Neural Computation, 14 (11) (2002), pp. 2709-2728
Simard et al., 2003
Simard, P., Steinkraus, D., & Platt, J. (2003). Best practices for convolutional neural networks applied to visual document analysis. In Seventh international conference on document analysis and recognition (pp. 958?963).
Sims, 1994
K. Sims
Evolving virtual creatures
A. Glassner (Ed.), Proceedings of SIGGRAPH ¡¯94, computer graphics proceedings, annual conference, ACM SIGGRAPH, 0-89791-667-0, ACM Press (1994), pp. 15-22
Simsek and Barto, 2008
Simsek, O., & Barto, A. G. (2008). Skill characterization based on betweenness. In NIPS¡¯08 (pp. 1497?1504).
Singh, 1994
Singh, S. P. (1994). Reinforcement learning algorithms for average-payoff Markovian decision processes. In National conference on artificial intelligence (pp. 700?705).
Singh et al., 2005
S. Singh, A.G. Barto, N. Chentanez
Intrinsically motivated reinforcement learning
Advances in neural information processing systems, vol. 17 (NIPS), MIT Press, Cambridge, MA (2005)
Smith, 1980
S.F. Smith
A learning system based on genetic adaptive algorithms
(Ph.D. thesis)
Univ. Pittsburgh (1980)
Smolensky, 1986
P. Smolensky
Parallel distributed processing: Explorations in the microstructure of cognition
Information processing in dynamical systems: foundations of harmony theory, vol. 1, MIT Press, Cambridge, MA, USA (1986), pp. 194-281
(Chapter)
Solla, 1988
S.A. Solla
Accelerated learning in layered neural networks
Complex Systems, 2 (1988), pp. 625-640
Solomonoff, 1964
R.J. Solomonoff
A formal theory of inductive inference. Part I
Information and Control, 7 (1964), pp. 1-22
ArticleDownload PDF
Solomonoff, 1978
R.J. Solomonoff
Complexity-based induction systems
IEEE Transactions on Information Theory, IT-24 (5) (1978), pp. 422-432
Soloway, 1986
E. Soloway
Learning to program  learning to construct mechanisms and explanations
Communications of the ACM, 29 (9) (1986), pp. 850-858
Song et al., 2000
S. Song, K.D. Miller, L.F. Abbott
Competitive Hebbian learning through spike-timing-dependent synaptic plasticity
Nature Neuroscience, 3 (9) (2000), pp. 919-926
Speelpenning, 1980
B. Speelpenning
Compiling fast partial derivatives of functions given by algorithms
(Ph.D. thesis)
Department of Computer Science, University of Illinois, Urbana-Champaign (1980)
Srivastava et al., 2013
R.K. Srivastava, J. Masci, S. Kazerounian, F. Gomez, J. Schmidhuber
Compete to compute
Advances in neural information processing systems (NIPS) (2013), pp. 2310-2318
Stallkamp et al., 2011
J. Stallkamp, M. Schlipsing, J. Salmen, C. Igel
The German traffic sign recognition benchmark: A multi-class classification competition
International joint conference on neural networks, IEEE Press (2011), pp. 1453-1460
Stallkamp et al., 2012
J. Stallkamp, M. Schlipsing, J. Salmen, C. Igel
Man vs. computer: benchmarking machine learning algorithms for traffic sign recognition
Neural Networks, 32 (2012), pp. 323-332
ArticleDownload PDF
Stanley et al., 2009
K.O. Stanley, D.B. D¡¯Ambrosio, J. Gauci
A hypercube-based encoding for evolving large-scale neural networks
Artificial Life, 15 (2) (2009), pp. 185-212
Stanley and Miikkulainen, 2002
K.O. Stanley, R. Miikkulainen
Evolving neural networks through augmenting topologies
Evolutionary Computation, 10 (2002), pp. 99-127
Steijvers and Grunwald, 1996
M. Steijvers, P. Grunwald
A recurrent network that performs a contextsensitive prediction task
Proceedings of the 18th annual conference of the cognitive science society, Erlbaum (1996)
Steil, 2007
J.J. Steil
Online reservoir adaptation by intrinsic plasticity for backpropagation?decorrelation and echo state learning
Neural Networks, 20 (3) (2007), pp. 353-364
ArticleDownload PDF
Stemmler, 1996
M. Stemmler
A single spike suffices: the simplest form of stochastic resonance in model neurons
Network: Computation in Neural Systems, 7 (4) (1996), pp. 687-716
Stoianov and Zorzi, 2012
I. Stoianov, M. Zorzi
Emergence of a ¡®visual number sense¡¯ in hierarchical generative models
Nature Neuroscience, 15 (2) (2012), pp. 194-196
Stone, 1974
M. Stone
Cross-validatory choice and assessment of statistical predictions
Journal of the Royal Statistical Society B, 36 (1974), pp. 111-147
Stoop et al., 2000
R. Stoop, K. Schindler, L. Bunimovich
When pyramidal neurons lock, when they respond chaotically, and when they like to synchronize
Neuroscience Research, 36 (1) (2000), pp. 81-91
ArticleDownload PDF
Stratonovich, 1960
R. Stratonovich
Conditional Markov processes
Theory of Probability and Its Applications, 5 (2) (1960), pp. 156-178
Sun, Chen, et al., 1993
G. Sun, H. Chen, Y. Lee
Time warping invariant neural networks
S.J. Hanson, J.D. Cowan, C.L. Giles (Eds.), Advances in neural information processing systems (NIPS), vol. 5, Morgan Kaufmann (1993), pp. 180-187
Sun, Giles, et al., 1993
G.Z. Sun, C.L. Giles, H.H. Chen, Y.C. Lee
The neural network pushdown automaton: Model, stack and learning simulations. Technical report CS-TR-3118
University of Maryland, College Park (1993)
Sun et al., 2013
Y. Sun, F. Gomez, T. Schaul, J. Schmidhuber
A linear time natural evolution strategy for non-separable functions
Proceedings of the genetic and evolutionary computation conference, ACM, Amsterdam, NL (2013), p. 61
ArticleDownload PDF
Sun et al., 2009
Sun, Y., Wierstra, D., Schaul, T., & Schmidhuber, J. (2009). Efficient natural evolution strategies. In Proc. 11th genetic and evolutionary computation conference (pp. 539?546).
Sutskever et al., 2008
Sutskever, I., Hinton, G. E., & Taylor, G. W. (2008). The recurrent temporal restricted Boltzmann machine. In NIPS, vol. 21 (p. 2008).
Sutskever et al., 2014
I. Sutskever, O. Vinyals, Q.V. Le
Sequence to sequence learning with neural networks. Technical report
(2014)
arXiv:1409.3215 [cs.CL] Google. NIPS¡¯2014
Sutton and Barto, 1998
R. Sutton, A. Barto
Reinforcement learning: An introduction
MIT Press, Cambridge, MA (1998)
Sutton, McAllester, et al., 1999
R.S. Sutton, D.A. McAllester, S.P. Singh, Y. Mansour
Policy gradient methods for reinforcement learning with function approximation
Advances in neural information processing systems (NIPS), vol. 12 (1999), pp. 1057-1063
Sutton, Precup, et al., 1999
R.S. Sutton, D. Precup, S.P. Singh
Between MDPs and semi-MDPs: A framework for temporal abstraction in reinforcement learning
Artificial Intelligence, 112 (1?2) (1999), pp. 181-211
ArticleDownload PDF
Sutton et al., 2008
R.S. Sutton, C. Szepesvari, H.R. Maei
A convergent  algorithm for off-policy temporal-difference learning with linear function approximation
Advances in neural information processing systems (NIPS¡¯08), vol. 21 (2008), pp. 1609-1616
Szabo et al., 2006
Z. Szabo, B. Poczos, A. L?rincz
Cross-entropy optimization for independent process analysis
Independent component analysis and blind signal separation, Springer (2006), pp. 909-916
Szegedy et al., 2014
C. Szegedy, W. Liu, Y. Jia, P. Sermanet, S. Reed, D. Anguelov, et al.
Going deeper with convolutions. Technical report
(2014)
arXiv:1409.4842 [cs.CV], Google
Szegedy et al., 2013
Szegedy, C., Toshev, A., & Erhan, D. (2013). Deep neural networks for object detection (pp. 2553?2561).
Taylor et al., 2011
G.W. Taylor, I. Spiro, C. Bregler, R. Fergus
Learning invariance through imitation
Conference on computer vision and pattern recognition, IEEE (2011), pp. 2729-2736
Tegge et al., 2009
A.N. Tegge, Z. Wang, J. Eickholt, J. Cheng
NNcon: improved protein contact map prediction using 2D-recursive neural networks
Nucleic Acids Research, 37 (Suppl 2) (2009), pp. W515-W518
Teichmann et al., 2012
M. Teichmann, J. Wiltschut, F. Hamker
Learning invariance from natural images inspired by observations in the primary visual cortex
Neural Computation, 24 (5) (2012), pp. 1271-1296
Teller, 1994
A. Teller
The evolution of mental models
E. Kenneth, J. Kinnear (Eds.), Advances in genetic programming, MIT Press (1994), pp. 199-219
Tenenberg et al., 1993
J. Tenenberg, J. Karlsson, S. Whitehead
Learning via task decomposition
J.A. Meyer, H. Roitblat, S. Wilson (Eds.), From animals to animats 2: proceedings of the second international conference on simulation of adaptive behavior, MIT Press (1993), pp. 337-343
Tesauro, 1994
G. Tesauro
TD-gammon, a self-teaching backgammon program, achieves master-level play
Neural Computation, 6 (2) (1994), pp. 215-219
Tieleman and Hinton, 2012
T. Tieleman, G. Hinton
Lecture 6.5?RmsProp: Divide the gradient by a running average of its recent magnitude
COURSERA: Neural Networks for Machine Learning (2012)
Tikhonov et al., 1977
A.N. Tikhonov, V.I. Arsenin, F. John
Solutions of ill-posed problems
Winston (1977)
Ting and Witten, 1997
Ting, K. M., & Witten, I. H. (1997). Stacked generalization: when does it work? In Proc. international joint conference on artificial intelligence.
Ti?o and Hammer, 2004
P. Ti?o, B. Hammer
Architectural bias in recurrent neural networks: Fractal analysis
Neural Computation, 15 (8) (2004), pp. 1931-1957
Tonkes and Wiles, 1997
Tonkes, B., & Wiles, J. (1997). Learning a context-free task with a recurrent neural network: An analysis of stability. In Proceedings of the fourth Biennial conference of the Australasian cognitive science society.
Towell and Shavlik, 1994
G.G. Towell, J.W. Shavlik
Knowledge-based artificial neural networks
Artificial Intelligence, 70 (1) (1994), pp. 119-165
ArticleDownload PDF
Tsitsiklis and van Roy, 1996
J.N. Tsitsiklis, B. van Roy
Feature-based methods for large scale dynamic programming
Machine Learning, 22 (1?3) (1996), pp. 59-94
Tsodyks et al., 1998
M. Tsodyks, K. Pawelzik, H. Markram
Neural networks with dynamic synapses
Neural Computation, 10 (4) (1998), pp. 821-835
Tsodyks et al., 1996
M.V. Tsodyks, W.E. Skaggs, T.J. Sejnowski, B.L. McNaughton
Population dynamics and theta rhythm phase precession of hippocampal place cell firing: a spiking neuron model
Hippocampus, 6 (3) (1996), pp. 271-280
Turaga et al., 2010
S.C. Turaga, J.F. Murray, V. Jain, F. Roth, M. Helmstaedter, K. Briggman, et al.
Convolutional networks can learn to generate affinity graphs for image segmentation
Neural Computation, 22 (2) (2010), pp. 511-538
Turing, 1936
A.M. Turing
On computable numbers, with an application to the Entscheidungsproblem
Proceedings of the London Mathematical Society, Series 2, 41 (1936), pp. 230-267
Turner and Miller, 2013
Turner, A. J., & Miller, J. F. (2013). Cartesian genetic programming encoded artificial neural networks: A comparison using three benchmarks. In Proceedings of the conference on genetic and evolutionary computation, GECCO (pp. 1005?1012).
Ueda, 2000
N. Ueda
Optimal linear combination of neural networks for improving classification performance
IEEE Transactions on Pattern Analysis and Machine Intelligence, 22 (2) (2000), pp. 207-215
Urlbe, 1999
A.P. Urlbe
Structure-adaptable digital neural networks
(Ph.D. thesis)
Universidad del Valle (1999)
Utgoff and Stracuzzi, 2002
P.E. Utgoff, D.J. Stracuzzi
Many-layered learning
Neural Computation, 14 (10) (2002), pp. 2497-2529
Vahed and Omlin, 2004
A. Vahed, C.W. Omlin
A machine learning method for extracting symbolic knowledge from recurrent neural networks
Neural Computation, 16 (1) (2004), pp. 59-71
Vaillant et al., 1994
R. Vaillant, C. Monrocq, Y. LeCun
Original approach for the localisation of objects in images
IEE Proceedings Vision, Image, and Signal Processing, 141 (4) (1994), pp. 245-250
van den Berg and Whiteson, 2013
van den Berg, T., & Whiteson, S. (2013). Critical factors in the performance of HyperNEAT. In GECCO 2013: proceedings of the genetic and evolutionary computation conference (pp. 759?766).
van Hasselt, 2012
H. van Hasselt
Reinforcement learning in continuous state and action spaces
M. Wiering, M. van Otterlo (Eds.), Reinforcement learning, Springer (2012), pp. 207-251
Vapnik, 1992
V. Vapnik
Principles of risk minimization for learning theory
D.S. Lippman, J.E. Moody, D.S. Touretzky (Eds.), Advances in neural information processing systems (NIPS), vol. 4, Morgan Kaufmann (1992), pp. 831-838
Vapnik, 1995
V. Vapnik
The nature of statistical learning theory
Springer, New York (1995)
Versino and Gambardella, 1996
C. Versino, L.M. Gambardella
Learning fine motion by using the hierarchical extended Kohonen map
Proc. intl. conf. on artificial neural networks, Springer (1996), pp. 221-226
Veta et al., 2013
Veta, M., Viergever, M., Pluim, J., Stathonikos, N., & van Diest, P. J. (2013). MICCAI 2013 grand challenge on mitosis detection.
Vieira and Barradas, 2003
A. Vieira, N. Barradas
A training algorithm for classification of high-dimensional data
Neurocomputing, 50 (2003), pp. 461-472
ArticleDownload PDF
Viglione, 1970
S. Viglione
Applications of pattern recognition technology
J.M. Mendel, K.S. Fu (Eds.), Adaptive, learning, and pattern recognition systems, Academic Press (1970)
Vincent et al., 2008
P. Vincent, L. Hugo, Y. Bengio, P.-A. Manzagol
Extracting and composing robust features with denoising autoencoders
Proceedings of the 25th international conference on Machine learning, ACM, New York, NY, USA (2008), pp. 1096-1103
Vlassis et al., 2012
N. Vlassis, M.L. Littman, D. Barber
On the computational complexity of stochastic controller optimization in POMDPs
ACM Transactions on Computation Theory, 4 (4) (2012), p. 12
Vogl et al., 1988
T. Vogl, J. Mangis, A. Rigler, W. Zink, D. Alkon
Accelerating the convergence of the back-propagation method
Biological Cybernetics, 59 (1988), pp. 257-263
von der Malsburg, 1973
C. von der Malsburg
Self-organization of orientation sensitive cells in the striate cortex
Kybernetik, 14 (2) (1973), pp. 85-100
Waldinger and Lee, 1969
R.J. Waldinger, R.C.T. Lee
PROW: a step toward automatic program writing
D.E. Walker, L.M. Norton (Eds.), Proceedings of the 1st international joint conference on artificial intelligence, Morgan Kaufmann (1969), pp. 241-252
Wallace and Boulton, 1968
C.S. Wallace, D.M. Boulton
An information theoretic measure for classification
The Computer Journal, 11 (2) (1968), pp. 185-194
Wan, 1994
E.A. Wan
Time series prediction by using a connectionist network with internal delay lines
A.S. Weigend, N.A. Gershenfeld (Eds.), Time series prediction: forecasting the future and understanding the past, Addison-Wesley (1994), pp. 265-295
Wang and Manning, 2013
Wang, S., & Manning, C. (2013). Fast dropout training. In Proceedings of the 30th international conference on machine learning (pp. 118?126).
Wang et al., 1994
C. Wang, S.S. Venkatesh, J.S. Judd
Optimal stopping and effective machine complexity in learning
Advances in neural information processing systems (NIPS¡¯6), Morgan Kaufmann (1994), pp. 303-310
Watanabe, 1985
S. Watanabe
Pattern recognition: human and mechanical
Wiley, New York (1985)
Watanabe, 1992
O. Watanabe
Kolmogorov complexity and computational complexity
EATCS monographs on theoretical computer science, Springer (1992)
Watkins, 1989
C.J.C.H. Watkins
Learning from delayed rewards
(Ph.D. thesis)
King¡¯s College, Oxford (1989)
Watkins and Dayan, 1992
C.J.C.H. Watkins, P. Dayan
Q-learning
Machine Learning, 8 (1992), pp. 279-292
Watrous and Kuhn, 1992
R.L. Watrous, G.M. Kuhn
Induction of finite-state automata using second-order recurrent networks
J.E. Moody, S.J. Hanson, R.P. Lippman (Eds.), Advances in neural information processing systems, vol. 4, Morgan Kaufmann (1992), pp. 309-316
Waydo and Koch, 2008
S. Waydo, C. Koch
Unsupervised learning of individuals and categories from images
Neural Computation, 20 (5) (2008), pp. 1165-1178
Weigend and Gershenfeld, 1993
A.S. Weigend, N.A. Gershenfeld
Results of the time series prediction competition at the Santa Fe Institute
Neural networks, 1993., IEEE international conference on, IEEE (1993), pp. 1786-1793
Weigend et al., 1991
A.S. Weigend, D.E. Rumelhart, B.A. Huberman
Generalization by weight-elimination with application to forecasting
R.P. Lippmann, J.E. Moody, D.S. Touretzky (Eds.), Advances in neural information processing systems (NIPS), vol. 3, Morgan Kaufmann, San Mateo, CA (1991), pp. 875-882
Weiss, 1994
G. Weiss
Hierarchical chunking in classifier systems
Proceedings of the 12th national conference on artificial intelligence, vol. 2, AAAI Press/The MIT Press (1994), pp. 1335-1340
Weng et al., 1992
J. Weng, N. Ahuja, T.S. Huang
Cresceptron: a self-organizing neural network which grows adaptively
International joint conference on neural networks, vol. 1, IEEE (1992), pp. 576-581
Weng et al., 1997
J.J. Weng, N. Ahuja, T.S. Huang
Learning recognition and segmentation using the cresceptron
International Journal of Computer Vision, 25 (2) (1997), pp. 109-143
Werbos, 1974
P.J. Werbos
Beyond regression: new tools for prediction and analysis in the behavioral sciences
(Ph.D. thesis)
Harvard University (1974)
Werbos, 1981
Werbos, P. J. (1981). Applications of advances in nonlinear sensitivity analysis. In Proceedings of the 10th IFIP conference, 31.8-4.9, NYC (pp. 762?770).
Werbos, 1987
P.J. Werbos
Building and understanding adaptive systems: A statistical/numerical approach to factory automation and brain research
IEEE Transactions on Systems, Man and Cybernetics, 17 (1987)
Werbos, 1988
P.J. Werbos
Generalization of backpropagation with application to a recurrent gas market model
Neural Networks, 1 (1988)
Werbos, 1989a
Werbos, P. J. (1989a). Backpropagation and neurocontrol: A review and prospectus. In IEEE/INNS International joint conference on neural networks, vol. 1 (pp. 209?216).
Werbos, 1989b
Werbos, P. J. (1989b). Neural networks for control and system identification. In Proceedings of IEEE/CDC Tampa.
Werbos, 1992
P.J. Werbos
Neural networks, system identification, and control in the chemical industries
D.A. White, D.A. Sofge (Eds.), Handbook of intelligent control: neural, fuzzy, and adaptive approaches, Thomson Learning (1992), pp. 283-356
Werbos, 2006
P.J. Werbos
Backwards differentiation in AD and neural nets: Past links and new opportunities
Automatic differentiation: applications, theory, and implementations, Springer (2006), pp. 15-34
West and Saad, 1995
A.H.L. West, D. Saad
Adaptive back-propagation in on-line learning of multilayer networks
D.S. Touretzky, M. Mozer, M.E. Hasselmo (Eds.), NIPS, MIT Press (1995), pp. 323-329
White, 1989
H. White
Learning in artificial neural networks: A statistical perspective
Neural Computation, 1 (4) (1989), pp. 425-464
Whitehead, 1992
S. Whitehead
Reinforcement learning for the adaptive control of perception and action
(Ph.D. thesis)
University of Rochester (1992)
Whiteson, 2012
S. Whiteson
Evolutionary computation for reinforcement learning
M. Wiering, M. van Otterlo (Eds.), Reinforcement learning, Springer, Berlin, Germany (2012), pp. 325-355
Whiteson et al., 2005
S. Whiteson, N. Kohl, R. Miikkulainen, P. Stone
Evolving keepaway soccer players through task decomposition
Machine Learning, 59 (1) (2005), pp. 5-30
Whiteson and Stone, 2006
S. Whiteson, P. Stone
Evolutionary function approximation for reinforcement learning
Journal of Machine Learning Research, 7 (2006), pp. 877-917
Widrow and Hoff, 1962
B. Widrow, M. Hoff
Associative storage and retrieval of digital information in networks of adaptive neurons
Biological Prototypes and Synthetic Systems, 1 (1962), p. 160
Widrow et al., 1994
B. Widrow, D.E. Rumelhart, M.A. Lehr
Neural networks: Applications in industry, business and science
Communications of the ACM, 37 (3) (1994), pp. 93-105
Wieland, 1991
A.P. Wieland
Evolving neural network controllers for unstable systems
International joint conference on neural networks, vol. 2, IEEE (1991), pp. 667-673
Wiering and Schmidhuber, 1996
M. Wiering, J. Schmidhuber
Solving POMDPs with Levin search and EIRA
L. Saitta (Ed.), Machine learning: proceedings of the thirteenth international conference, Morgan Kaufmann Publishers, San Francisco, CA (1996), pp. 534-542
Wiering and Schmidhuber, 1998a
M. Wiering, J. Schmidhuber
HQ-learning
Adaptive Behavior, 6 (2) (1998), pp. 219-246
Wiering and Schmidhuber, 1998b
M.A. Wiering, J. Schmidhuber
Fast online Q()
Machine Learning, 33 (1) (1998), pp. 105-116
Wiering and van Otterlo, 2012
M. Wiering, M. van Otterlo
Reinforcement learning
Springer (2012)
Wierstra et al., 2010
D. Wierstra, A. Foerster, J. Peters, J. Schmidhuber
Recurrent policy gradients
Logic Journal of IGPL, 18 (2) (2010), pp. 620-634
Wierstra et al., 2008
Wierstra, D., Schaul, T., Peters, J., & Schmidhuber, J. (2008). Natural evolution strategies. In Congress of evolutionary computation.
Wiesel and Hubel, 1959
D.H. Wiesel, T.N. Hubel
Receptive fields of single neurones in the cat¡¯s striate cortex
Journal of Physiology, 148 (1959), pp. 574-591
Wiles and Elman, 1995
J. Wiles, J. Elman
Learning to count without a counter: A case study of dynamics and activation landscapes in recurrent networks
Proceedings of the seventeenth annual conference of the cognitive science society, Cambridge, MA, MIT Press (1995), pp. 482-487
Wilkinson, 1965
J.H. Wilkinson (Ed.), The algebraic eigenvalue problem, Oxford University Press, Inc, New York, NY, USA (1965)
Williams, 1986
R.J. Williams
Reinforcement-learning in connectionist networks: A mathematical analysis. Technical report 8605
Institute for Cognitive Science, University of California, San Diego (1986)
Williams, 1988
R.J. Williams
Toward a theory of reinforcement-learning connectionist systems. Technical report NU-CCS-88-3
College of Comp. Sci., Northeastern University, Boston, MA (1988)
Williams, 1989
R.J. Williams
Complexity of exact gradient computation algorithms for recurrent neural networks. Technical report NU-CCS-89-27
Northeastern University, College of Computer Science, Boston (1989)
Williams, 1992a
R.J. Williams
Simple statistical gradient-following algorithms for connectionist reinforcement learning
Machine Learning, 8 (1992), pp. 229-256
Williams, 1992b
R.J. Williams
Training recurrent networks using the extended Kalman filter
International joint conference on neural networks, vol. 4, IEEE (1992), pp. 241-246
Williams and Peng, 1990
R.J. Williams, J. Peng
An efficient gradient-based algorithm for on-line training of recurrent network trajectories
Neural Computation, 4 (1990), pp. 491-501
Williams and Zipser, 1988
R.J. Williams, D. Zipser
A learning algorithm for continually running fully recurrent networks. Technical report ICS report 8805
Univ. of California, San Diego, La Jolla (1988)
Williams and Zipser, 1989a
R.J. Williams, D. Zipser
Experimental analysis of the real-time recurrent learning algorithm
Connection Science, 1 (1) (1989), pp. 87-111
Williams and Zipser, 1989b
R.J. Williams, D. Zipser
A learning algorithm for continually running fully recurrent networks
Neural Computation, 1 (2) (1989), pp. 270-280
Willshaw and von der Malsburg, 1976
D.J. Willshaw, C. von der Malsburg
How patterned neural connections can be set up by self-organization
Proceedings of the Royal Society of London. Series B, 194 (1976), pp. 431-445
Windisch, 2005
D. Windisch
Loading deep networks is hard: The pyramidal case
Neural Computation, 17 (2) (2005), pp. 487-502
Wiskott and Sejnowski, 2002
L. Wiskott, T. Sejnowski
Slow feature analysis: Unsupervised learning of invariances
Neural Computation, 14 (4) (2002), pp. 715-770
Witczak et al., 2006
M. Witczak, J. Korbicz, M. Mrugalski, R.J. Patton
A GMDH neural network-based approach to robust fault diagnosis: Application to the DAMADICS benchmark problem
Control Engineering Practice, 14 (6) (2006), pp. 671-683
ArticleDownload PDF
Wollmer et al., 2011
M. Wollmer, C. Blaschke, T. Schindl, B. Schuller, B. Farber, S. Mayer, et al.
On-line driver distraction detection using long short-term memory
IEEE Transactions on Intelligent Transportation Systems (TITS), 12 (2) (2011), pp. 574-582
Wollmer et al., 2013
M. Wollmer, B. Schuller, G. Rigoll
Keyword spotting exploiting long short-term memory
Speech Communication, 55 (2) (2013), pp. 252-265
ArticleDownload PDF
Wolpert, 1992
D.H. Wolpert
Stacked generalization
Neural Networks, 5 (2) (1992), pp. 241-259
ArticleDownload PDF
Wolpert, 1994
D.H. Wolpert
Bayesian backpropagation over i-o functions rather than weights
J.D. Cowan, G. Tesauro, J. Alspector (Eds.), Advances in neural information processing systems (NIPS), vol. 6, Morgan Kaufmann (1994), pp. 200-207
Wu and Baldi, 2008
L. Wu, P. Baldi
Learning to play go using recursive neural networks
Neural Networks, 21 (9) (2008), pp. 1392-1400
ArticleDownload PDF
Wu and Shao, 2014
Wu, D., & Shao, L. (2014). Leveraging hierarchical parametric networks for skeletal joints based action segmentation and recognition. In Proc. conference on computer vision and pattern recognition.
Wyatte et al., 2012
D. Wyatte, T. Curran, R. O¡¯Reilly
The limits of feedforward vision: Recurrent processing promotes robust object recognition when objects are degraded
Journal of Cognitive Neuroscience, 24 (11) (2012), pp. 2248-2261
Wysoski et al., 2010
S.G. Wysoski, L. Benuskova, N. Kasabov
Evolving spiking neural networks for audiovisual information processing
Neural Networks, 23 (7) (2010), pp. 819-835
ArticleDownload PDF
Yamauchi and Beer, 1994
B.M. Yamauchi, R.D. Beer
Sequential behavior and learning in evolved dynamical neural networks
Adaptive Behavior, 2 (3) (1994), pp. 219-246
Yamins et al., 2013
D. Yamins, H. Hong, C. Cadieu, J.J. DiCarlo
Hierarchical modular optimization of convolutional networks achieves representations similar to macaque IT and human ventral stream
Advances in neural information processing systems (NIPS) (2013), pp. 1-9
Yang et al., 2009
Yang, M., Ji, S., Xu, W., Wang, J., Lv, F., & Yu, K., et al. (2009). Detecting human actions in surveillance videos. In TREC video retrieval evaluation workshop.
Yao, 1993
X. Yao
A review of evolutionary artificial neural networks
International Journal of Intelligent Systems, 4 (1993), pp. 203-222
Yin et al., 2012
J. Yin, Y. Meng, Y. Jin
A developmental approach to structural self-organization in reservoir computing
IEEE Transactions on Autonomous Mental Development, 4 (4) (2012), pp. 273-289
Yin et al., 2013
Yin, F., Wang, Q.-F., Zhang, X.-Y., & Liu, C.-L. (2013). ICDAR 2013 Chinese handwriting recognition competition. In 12th international conference on document analysis and recognition (pp. 1464?1470).
Young et al., 2014
S. Young, A. Davis, A. Mishtal, I. Arel
Hierarchical spatiotemporal feature extraction using recurrent online clustering
Pattern Recognition Letters, 37 (2014), pp. 115-123
ArticleDownload PDF
Yu et al., 1995
X.-H. Yu, G.-A. Chen, S.-X. Cheng
Dynamic learning rate optimization of the backpropagation algorithm
IEEE Transactions on Neural Networks, 6 (3) (1995), pp. 669-677
Zamora-Martinez et al., 2014
F. Zamora-Martinez, V. Frinken, S. Espana-Boquera, M. Castro-Bleda, A. Fischer, H. Bunke
Neural network language models for off-line handwriting recognition
Pattern Recognition, 47 (4) (2014), pp. 1642-1652
ArticleDownload PDF
Zeiler, 2012
Zeiler, M. D. (2012). ADADELTA: an adaptive learning rate method. CoRR, abs/1212.5701.
Zeiler and Fergus, 2013
M.D. Zeiler, R. Fergus
Visualizing and understanding convolutional networks. Technical report
NYU (2013)
arXiv:1311.2901 [cs.CV]
Zemel, 1993
R.S. Zemel
A minimum description length framework for unsupervised learning
(Ph.D. thesis)
University of Toronto (1993)
Zemel and Hinton, 1994
R.S. Zemel, G.E. Hinton
Developing population codes by minimizing description length
J.D. Cowan, G. Tesauro, J. Alspector (Eds.), Advances in neural information processing systems vol. 6, Morgan Kaufmann (1994), pp. 11-18
Zeng et al., 1994
Z. Zeng, R. Goodman, P. Smyth
Discrete recurrent neural networks for grammatical inference
IEEE Transactions on Neural Networks, 5 (2) (1994)
Zimmermann et al., 2012
H.-G. Zimmermann, C. Tietz, R. Grothmann
Forecasting with recurrent neural networks: 12 tricks
G. Montavon, G.B. Orr, K.-R. Muller (Eds.), Neural networks: tricks of the trade (2nd ed.), Lecture notes in computer science, Vol. 7700, Springer (2012), pp. 687-707
Zipser et al., 1993
D. Zipser, B. Kehoe, G. Littlewort, J. Fuster
A spiking network model of short-term active memory
The Journal of Neuroscience, 13 (8) (1993), pp. 3406-3420
1
An alternative would be to count only modifiable links when measuring depth. In many typical NN applications this would not make a difference, but in some it would, e.g., Section  6.1.

2
It should be mentioned, however, that LSTM RNNs already performed simultaneous segmentation and recognition when they became the first recurrent Deep Learners to win official international pattern recognition contests?see Section  5.17.

Copyright ¨Ï 2014 Published by Elsevier Ltd.

Recommended articles
A survey of deep neural network architectures and their applications
Neurocomputing, Volume 234, 2017, pp. 11-26
Purchase PDFView details
Trends in extreme learning machines: A review
Neural Networks, Volume 61, 2015, pp. 32-48
Purchase PDFView details
An efficient sampling algorithm with adaptations for Bayesian variable selection
Neural Networks, Volume 61, 2015, pp. 22-31
Purchase PDFView details
12Next

Citing articles (1752)

Article Metrics
Captures
Readers: 1998
Exports-Saves: 24
Mentions
Blog Mentions: 7
News Mentions: 1
Q&A Site Mentions: 1
References: 14
Social Media
Shares, Likes & Comments: 113
Tweets: 30
Citations
Citation Indexes: 1752
